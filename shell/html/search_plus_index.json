{"yi-qie-jie-shi-wen-jian.html":{"url":"yi-qie-jie-shi-wen-jian.html","title":"文件管理系统","keywords":"","body":"在linux环境下一切皆是文件，任何资源都以文件的形式存在，Liunx采用树形的文件-管理系统，而不是采用分区管理系统，分区在Linux树文件系统中和其他设备一样都只是一个文件。要使用一个分区必须把它加载到文件系统中 如：传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 lso列出当前系统上所有进程打开文件的工具 -一切皆是文件! "},"yi-qie-jie-shi-wen-jian/gua-zai.html":{"url":"yi-qie-jie-shi-wen-jian/gua-zai.html","title":"挂载","keywords":"","body":""},"kai-ji-gua-zai-mount-etcfstab-4e0e-etc-rc-d-rc-local-qu-bie.html":{"url":"kai-ji-gua-zai-mount-etcfstab-4e0e-etc-rc-d-rc-local-qu-bie.html","title":"开机挂载mount etc/fstab与/etc/rc.d/rc.local区别 ","keywords":"","body":"开机挂载mount etc/fstab与/etc/rc.d/rc.local区别是如果你又程序依赖于NFS的话还是的放到fstab比较好。程序启动先加载/etc/fastab文件。 某些时候当Linux系统下划分了新的分区后，需要将这些分区设置为开机自动挂载，否则，Linux是无法使用新建的分区的。 /etc/fstab 文件负责配置Linux开机时自动挂载的分区。 放到fstab里面会在程序启动前加载上NFS文件系统，放到rc.local里往往造成程序启动加载时找不到路径 "},"yi-qie-jie-shi-wen-jian/ge-shi.html":{"url":"yi-qie-jie-shi-wen-jian/ge-shi.html","title":"格式","keywords":"","body":"文件系统 ext4 ntfs NFS（Network File System）即网络文件系统，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样 "},"yi-qie-jie-shi-wen-jian/ge-shi/nfs.html":{"url":"yi-qie-jie-shi-wen-jian/ge-shi/nfs.html","title":"NFS","keywords":"","body":"安装: #安装 sudo apt-get install nfs-kernel-server #服务操作 /etc/init.d/nfs-kernel-server restart #服务状态 nfsstat --help #exportfs命令对配置文件exprots操作 #修改-立刻生效 exportfs /etc/exports #卸载所有共享目录 exportfs -au #重新共享所有目录并输出详细信息 exportfs -rv #rpcinfo 查看rpc执行信息，可以用于检测rpc运行情况的工具 #可以查看出RPC开启的端口所提供的程序有哪些 rpcinfo -p #查看 RPC 服务的注册状况 rpcinfo -p localhost #showmount #显示已经于客户端连接上的目录信息 showmount -a #-e IP或者hostname 显示此IP地址分享出来的nfs目录 showmount -e 127.0.0.1 #显示其他服务器发布注册服务 sudo showmount -e 192.168.1.* 配置文件/etc/exports 在Ubuntu中/etc/exports是nfs服务器的全局配置文件,配置文件中一行即为一条配置项，用于指明网络中“哪些客户端”共享“哪些目录资源”。将创建的共享目录添加到其中,如下: # /etc/exports: the access control list .... # Example for NFSv4: # /srv/nfs4 gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check) # /srv/nfs4/homes gss/krb5i(rw,sync,no_subtree_check) # 共享目录 客服端ip(全部:* 限定网段 xxx.xxx.x.* 具体 xxx.xxx.xxx.xxx) (权限,参数...) /home/baihui/share/nfs 192.168.1.*(rw,sync,no_subtree_check) 常用参数： 访问权限选项 设置输出目录只读：ro 设置输出目录读写：rw 用户映射选项(客服端用户映射服务端账号) all_squash 将远程访问的所有普通用户及所属组都映射为匿名用户或用户组（nfsnobody） no_all_squash 与all_squash取反（默认设置） root_squash 将root用户及所属组都映射为匿名用户或用户组（默认设置） no_root_squash 与rootsquash取反 anonuid=xxx 将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用（UID=xxx） anongid=xxx 将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户（GID=xxx） 其它选项 secure 限制客户端只能从小于1024的tcp/ip端口连接nfs服务器（默认设置） insecure 允许客户端从大于1024的tcp/ip端口连接服务器 sync 将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性； async 将数据先保存在内存缓冲区中，必要时才写入磁盘 wdelay 检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认设置） no_wdelay 若有写操作则立即执行，应与sync配合使用 subtree 若输出目录是一个子目录，则nfs服务器将检查其父目录的权限(默认设置) no_subtree 即使输出目录是一个子目录，nfs服务器也不检查其父目录的权限，这样可以提高效率 sync和async sync适用在通信比较频繁且实时性比较高的场合影响性能。 async当涉及到很多零碎文件操作时，选用async性能更高。 #客户端 sudo apt install nfs-common #显示6服务发布的nfs目录 showmount -e 192.168.1.6 自动挂载网上提供了三种方法： 开机自动挂载：/etc/fstab（不推荐） #server_IP:/remote_dir /local_dir nfs defaults 1 1 192.168.56.101:/home/shareStoreDir /home/shareStoreDir nfs defaults 0 0 第1个1表示备份文件系统， 第2个1表示从/分区的顺序开始fsck磁盘检测，0表示不检测。 这种方法不推荐，尝试过程中发现开机很慢，而且开机后并没有挂载成功。后查找原因是开机时,系统还没有完全完成所有服务的启动,包括网络服务:network。在网络无法连入时试图mount NFS当然会失败。 /etc/rc.d/rc.local 在/etc/rc.d/rc.local文件中添加记录（不推荐）mount -t nfs -o nolock hostname(orIP):/directory /mnt 还是会遇到上面的问题，网友提供解决方法可以休眠几秒后尝试，命令修改为： sleep 5; mount -t nfs xx.xx.xx.xx:/home /mnt/nfs 自动挂载autofs（推荐） 没有安装autofs可以先进行安装 "},"start.html":{"url":"start.html","title":"start","keywords":"","body":" graph TB; 通电--自检-->BIOS; BIOS--启动设备-->CMOS; CMOS--读取设备0柱面0磁头1扇区-->主引导扇区; 主引导扇区--第一个引导装载程序-->MBR; MBR-->分区表; 分区表--第二个引导装载程序-->grup; grup--控制权移-->操作系统; 操作系统--boot目录内核文件-->内核; 内核--第一个进程-->sbin/init; sbin/init--用户等级-->启动内核模块; "},"mbr.html":{"url":"mbr.html","title":"MBR","keywords":"","body":"主引导记录（MBR，Main Boot Record）是位于磁盘最前边的一段引导代码(硬盘0柱面、0磁头、1扇区)。它负责操作系统(DOS/gurp)对磁盘进行读写时分区合法性的判别、分区引导信息的定位，它由磁盘操作系统(DOS)在对硬盘进行初始化时产生的 包含MBR引导代码的扇区称为主引导扇区。因这一扇区中，引导代码占有绝大部分的空间，故而将习惯将该扇区称为MBR扇区（简称MBR）。由于这一扇区承担有不同于磁盘上其他普通存储空间的特殊管理职能，作为管理整个磁盘空间的一个特殊空间，它不属于磁盘上的任何分区，因而分区空间内的格式化命令不能清除主引导记录的任何信息。 主引导扇区由三个部分组成(共占用512个字节)： 主引导程序（MBR）（占446个字节）可在fdisk程序中找到，它用于硬盘启动时将系统控制转给用户指定的并在分区表中登记了的某个操作系统。 磁盘分区表负责说明磁盘上的分区情况其大小64字节，最大可以由四个分区表项构成（每个16个字节）。 Windows系统默认情况下，一般都是只划分一个主分区给系统，剩余的部分全部划入扩展分区。这里有下面几点需要注意： 在MBR分区表中最多4个主分区或者3个主分区+1个扩展分区，也就是说扩展分区只能有一个，然后可以再细分为多个逻辑分区。 在Linux系统中，硬盘分区命名为sda1－sda4或者hda1－hda4（其中a表示硬盘编号可能是a、b、c等等）。在MBR硬盘中，分区号1－4是主分区（或者扩展分区），逻辑分区号只能从5开始。 结束标志（占2个字节） 其值为AA55，存储时低位在前，高位在后，即看上去是55AA（十六进制） 如下： #备份主引导记录 sudo dd if=/dev/sda of=/home/baihui/mbr.bak bs=512 count=1 #查看主引导记录内容 od -x mbr.bak 0000000 0000 0000 0000 0000 0000 0000 0000 0000 * 0000700 0001 feee ffff 0001 0000 c2af 0ee7 0000 0000720 0000 0000 0000 0000 0000 0000 0000 0000 * 0000760 0000 0000 0000 0000 0000 0000 0000 aa55 0001000 硬盘的引导记录（MBR）是不属于任何一个操作系统，也不能用操作系统提供的磁盘操作命令来读取它。但我们可以用ROM-BIOS中提供的INT13H的2号功能来读出该扇区的内容 "},"grub.html":{"url":"grub.html","title":"grub","keywords":"","body":"Boot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。 Boot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。 我们以Grub为例来讲解吧，毕竟用lilo和spfdisk的人并不多。 系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。 /boot/grub/grub.cnf export linux_gfx_mode menuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-322958ca-8e53-4998-bb4d-e3b356cdf093' { recordfail load_video gfxmode $linux_gfx_mode insmod gzio if [ x$grub_platform = xxen ]; then insmod xzio; insmod lzopio; fi insmod part_gpt insmod ext2 set root='hd0,gpt3' if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,gpt3 --hint-efi=hd0,gpt3 --hint-baremetal=ahci0,gpt3 322958ca-8e53-4998-bb4d-e3b356cdf093 else search --no-floppy --fs-uuid --set=root 322958ca-8e53-4998-bb4d-e3b356cdf093 fi linux /boot/vmlinuz-4.15.0-46-generic root=UUID=322958ca-8e53-4998-bb4d-e3b356cdf093 ro quiet splash $vt_handoff initrd /boot/initrd.img-4.15.0-46-generic } 内核文件vmlinuz /boot/vmlinuz-4.15.0-46-generic 启动方式initrd /boot/initrd.img-4.15.0-46-generic "},"int.html":{"url":"int.html","title":"int","keywords":"","body":"用户层init依据inittab文件来设定运行等级,内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。 其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。Linux的运行等级设定如下： 0：关机 1：单用户模式 2：无网络支持的多用户模式 3：有网络支持的多用户模式 4：保留，未使用 5：有网络支持有X-Window支持的多用户模式 6：重新引导系统，即重启 "},"vmlinuzhe-initrd-img.html":{"url":"vmlinuzhe-initrd-img.html","title":"vmlinuz和initrd.img","keywords":"","body":"vmlinuz 是Linux内核的镜像文件,可以被引导程序加载,从而启动Linux系统。 initrd 是一种启动Linux系统的方式 当前流行的Linux版本一般都采用模块化的内核,这种方式可以在不重新编译构建内核的情形下增加功能模块，但是如果你的Linux的root文件系统所在设备的驱动是一个模块(没有编译进内核映象),就不能被引导程序(例如loadlin)直接加载这时会用到initrd方式来启动你的Linux系统 这种方式包括两个阶段: 　　1)在一个RAM disk上建立一个临时的root文件系统,在这个RAM disk上包含着你需要的驱动模块 　　2)载入所需驱动模块,挂载实际的root文件系统 ,启动Linux 　　而initrd.img就是RAM disk的映象 　　在安装Linux系统之前,由于Linux的root文件系统还不存在,同样会用到initrd方式,这时对于loadlin就是这样的情形 　　C:> loadlin autoboot\\vmlinuz initrd=autoboot\\initrd.img 这时我们要指定的是initrd镜像文件的位置而不再是root文件系统的位置了。 "},"nei-he-he-nei-he-mo-kuai.html":{"url":"nei-he-he-nei-he-mo-kuai.html","title":"内核和内核模块","keywords":"","body":""},"she-zhi-kai-ji-qi-dong-jiao-ben.html":{"url":"she-zhi-kai-ji-qi-dong-jiao-ben.html","title":"设置开机启动脚本","keywords":"","body":""},"she-zhi-kai-ji-qi-dong-jiao-ben/ubunut.html":{"url":"she-zhi-kai-ji-qi-dong-jiao-ben/ubunut.html","title":"ubunut","keywords":"","body":"命令 rc.local脚本是一个ubuntu开机后会自动执行的脚本，可以在该脚本内添加命令行指令。该脚本位于/etc/路径下，需要root权限才能修改。 如: #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will \"exit 0\" on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. ls exit 0 添加开机脚本 /etc/init.d/ sudo mv a.sh /etc/init.d/ sudo chmod 755 a.sh #注册脚本到开机 在这里90表明一个优先级越高表示执行的越晚 sudo update-rc.d a.sh defaults 90 #删除 sudo update-rc.d -f a.sh remove "},"jin-cheng.html":{"url":"jin-cheng.html","title":"进程","keywords":"","body":"通俗的讲程序是一个包含可以执行代码的静态的文件，进程是一个开始执行但是还没有结束的程序的实例，当程序被系统调用到内存以后，系统会给程序分配一定的资源（内存，设备等等）然后进行一系列的复杂操作，使程序变成进程以供系统调用。 进程-分类 系统进程可以执行内存资源分配和进程切换等管理工作，而且该进程的运行不受用户的干预，即使是root用户也不能干预系统进程的运行。 用户进程 通过执行用户程序、应用程序或内核之外的系统程序而产生的进程，此类进程可以在用户的控制下运行或关闭。针对用户进程，又可以分为如下3类： 交互进程 由一个Shell终端其他的进程，在执行过程中，需要与用户进行交互操作，可以运行于前台，也可以运行于后台 批处理进程 该进程是一个进程集合，负责按顺序启动其他的进程。 守护进程 守护进程是一直运行的一种进程，经常在Linux系统时启动，在系统关闭时终止。它们独立于控制终端且周期性地质学某种任务或等待处理某些发生的时间。例，httpd进程，crond进程等。 进程-状态 Linux上进程有5种状态： 运行 正在运行或在运行队列中等待。 中断 休眠中， 受阻， 在等待某个条件的形成或接受到信号。 不可中断 收到信号不唤醒和不可运行， 进程必须等待直到有中断发生。 僵死 进程已终止， 但进程描述符存在， 直到父进程调用wait4()系统调用后释放。 停止 进程收到SIGSTOP， SIGSTP， SIGTIN， SIGTOU信号后停止运行运行。 进程-继承 为了区分各个不同的进程，系统给每一个进程分配了一个ID以便识别。Linux系统中，进程ID（PID）是区分不同进程的唯一标识。PPID表示父进程。所有的进程都是PID为1的init进程的子进程。内核在系统启动的最后阶段启动init进程。 graph TD; 内核--运行完毕-->init进程; init进程-->子进程A; init进程-->子进程B; 子进程B-->子进程C; 子进程B-->子进程D; linkStyle 0 stroke:#333,stroke-width:4px; 进程-线程 线程在Linux中被称为轻量级的进程,进程有独立的内存地址空间，线程没有。线程不能独立存在，线程由进程创建的。 "},"jin-cheng/jin-cheng-de-chuang-jian.html":{"url":"jin-cheng/jin-cheng-de-chuang-jian.html","title":"创建","keywords":"","body":"在Linux中，父进程以分裂的方式来创建子进程，创建一个子进程的系统调用叫做fork() "},"jin-cheng/yun-xing.html":{"url":"jin-cheng/yun-xing.html","title":"运行","keywords":"","body":""},"jin-cheng/ting-zhi.html":{"url":"jin-cheng/ting-zhi.html","title":"停止","keywords":"","body":""},"jin-cheng/jiang-si.html":{"url":"jin-cheng/jiang-si.html","title":"僵死","keywords":"","body":"每个进程在结束后都会处于僵死状态，等待父进程将其释放资源，处于该状态的进程已经结束，但父进程还没有释放其系统资源。由于某种原因，父进程在子进程退出前退出，则所有子进程就变成一个孤儿进程，拖没有相应处理机制，则孤儿进程会一直处于僵死状态，资源无法释放。这种僵死的孤儿进程即僵尸进程。 此时解决方法是在启动进程内找一个进程作为这些孤儿进程的父进程，或者直接让init进程作为它们的父进程，进而释放孤儿进程占用的资源。 "},"./":{"url":"./","title":"Shell","keywords":"","body":"shell本身是一个用C语言编写的程序，它是用户使用Linux的桥梁。Shell既是一种命令语言，又是一种程序设计语言。作为命令语言，它交互式地解释和执行用户输入的命令；作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。 它虽然不是Linux系统核心的一部分，但它调用了系统核心的大部分功能来执行程序、建立文件并以并行的方式协调各个程序的运行。因此，对于用户来说，shell是最重要的实用程序，深入了解和熟练掌握shell的特性极其使用方法，是用好Linux系统的关键。 可以说，shell使用的熟练程度反映了用户对Linux使用的熟练程度。 Shell有两种执行命令的方式： •交互式（Interactive） 解释执行用户的命令，用户输入一条命令，Shell就解释执行一条。 •批处理（Batch） 用户事先写一个Shell脚本（Script），其中有很多条命令，让Shell一次把这些命令执行完，而不必一条一条地敲命令。 Shell脚本和编程语言很相似，也有变量和流程控制语句，但Shell脚本是解释执行的，不需要编译，Shell程序从脚本中一行一行读取并执行这些命令，相当于一个用户把脚本中的命令一行一行敲到Shell提示符下执行。 Shell初学者请注意，在平常应用中，建议您不要用 root 帐号运行 Shell 。作为普通用户，不管您有意还是无意，都无法破坏系统；但如果是 root，那就不同了，只要敲几个字母，就可能导致灾难性后果。 几种常见的Shell 上面提到过Shell是一种脚本语言，那么就必须有解释器来执行这些脚本,Linux上常见的Shell脚本解释器有bash、sh、ash、csh、ksh，习惯上把它们称作一种Shell。我们常说有多少种Shell，其实说的是Shell脚本解释器。 bashbash是Linux系统默认使用的shell。bash由Brian Fox和Chet Ramey共同完成，是BourneAgain Shell的缩写，内部命令一共有40个。Linux使用它作为默认的shell是因为它有诸如以下的特色： 可以使用类似DOS下面的doskey的功能，用方向键查阅和快速输入并修改命令。 自动通过查找匹配的方式给出以某字符串开头的命令。 包含了自身的帮助功能，你只要在提示符下面键入help就可以得到相关的帮助。 sh sh由Steve Bourne开发，是Bourne Shell的缩写，各种UNIX系统都配有sh。 ash ash shell 是由Kenneth Almquist编写的，Linux中占用系统资源最少的一个小shell，它只包含24个内部命令，因而使用起来很不方便。 csh csh 是Linux比较大的内核，它由以William Joy为代表的共计47位作者编成，共有52个内部命令。该shell其实是指向/bin/tcsh这样的一个shell，也就是说，csh其实就是tcsh。 ksh ksh 是Korn shell的缩写，由Eric Gisin编写，共有42条内部命令。该shell最大的优点是几乎和商业发行版的ksh完全兼容，这样就可以在不用花钱购买商业版本的情况下尝试商业版本的性能了。 Shell与编译型语言的差异 大体上，可以将程序设计语言可以分为两类：编译型语言和解释型语言。 编译型语言 很多传统的程序设计语言，例如Fortran、Ada、Pascal、C、C++和Java，都是编译型语言。这类语言需要预先将我们写好的源代码(source code)转换成目标代码(object code)，这个过程被称作“编译”。 运行程序时，直接读取目标代码(object code)。由于编译后的目标代码(object code)非常接近计算机底层，因此执行效率很高，这是编译型语言的优点。 但是，由于编译型语言多半运作于底层，所处理的是字节、整数、浮点数或是其他机器层级的对象，往往实现一个简单的功能需要大量复杂的代码。例如，在C++里，就很难进行“将一个目录里所有的文件复制到另一个目录中”之类的简单操作。 "},"hello.html":{"url":"hello.html","title":"Hello","keywords":"","body":"第一个Shell脚本A扩展名为sh（sh代表shell），扩展名并不影响脚本执行，见名知意就好如： #!/bin/bash echo \"Hello World !\" “#!” 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种Shell。echo命令用于向窗口输出文本 运行Shell脚本有两种方法 作为可执行程序 将上面的代码保存为hello.sh其次使脚本具有执行权限如下: chmod +x ./hello.sh #使脚本具有执行权限 ./hello.sh #执行脚本 \"Hello World ! 写成./hello.sh和hello.sh的区别 直接写hello.sh，shell系统会去PATH中定义的变量/bin, /sbin, /usr/bin，/usr/sbin等目录下查找脚步名称为hello.sh的，而当前脚步存放的目录通常不在PATH里，所以写成hello.sh是会找不到命令的而./hello.sh告诉系统就在当前目录找。 这里的\"系统\"，其实就是shell这个应用程序 作为解释器参数 运行方式是运行解释器，其参数就是shell脚本的文件名,如： /bin/sh hello.sh \"Hello World ! "},"xun-huan-yu-fa.html":{"url":"xun-huan-yu-fa.html","title":"语法","keywords":"","body":"for for id in $( docker ps -q) do echo $( docker stop $id) docker rm $id done if if [ \"$test\"x = \"test\"x ]; then 这里的关键有几点： 1 使用单个等号 2 注意到等号两边各有一个空格：这是unix shell的要求 一、if的基本语法: if [ command ];then 符合该条件执行的语句 elif [ command ];then 符合该条件执行的语句 else 符合该条件执行的语句 fi 二、文件/文件夹(目录)判断 [ -b FILE ] 如果 FILE 存在且是一个块特殊文件则为真。 [ -c FILE ] 如果 FILE 存在且是一个字特殊文件则为真。 [ -d DIR ] 如果 FILE 存在且是一个目录则为真。 [ -e FILE ] 如果 FILE 存在则为真。 [ -f FILE ] 如果 FILE 存在且是一个普通文件则为真。 [ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。 [ -k FILE ] 如果 FILE 存在且已经设置了粘制位则为真。 [ -p FILE ] 如果 FILE 存在且是一个名字管道(F如果O)则为真。 [ -r FILE ] 如果 FILE 存在且是可读的则为真。 [ -s FILE ] 如果 FILE 存在且大小不为0则为真。 [ -t FD ] 如果文件描述符 FD 打开且指向一个终端则为真。 [ -u FILE ] 如果 FILE 存在且设置了SUID (set user ID)则为真。 [ -w FILE ] 如果 FILE存在且是可写的则为真。 [ -x FILE ] 如果 FILE 存在且是可执行的则为真。 [ -O FILE ] 如果 FILE 存在且属有效用户ID则为真。 [ -G FILE ] 如果 FILE 存在且属有效用户组则为真。 [ -L FILE ] 如果 FILE 存在且是一个符号连接则为真。 [ -N FILE ] 如果 FILE 存在 and has been mod如果ied since it was last read则为真。 [ -S FILE ] 如果 FILE 存在且是一个套接字则为真。 [ FILE1 -nt FILE2 ] 如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。 [ FILE1 -ot FILE2 ] 如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。 [ FILE1 -ef FILE2 ] 如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。 三、字符串判断 [ -z STRING ] 如果STRING的长度为零则为真 ，即判断是否为空，空即是真； [ -n STRING ] 如果STRING的长度非零则为真 ，即判断是否为非空，非空即是真； [ STRING1 = STRING2 ] 如果两个字符串相同则为真 ； [ STRING1 != STRING2 ] 如果字符串不相同则为真 ； [ STRING1 ]　 如果字符串不为空则为真,与-n类似 四、数值判断 INT1 -eq INT2 INT1和INT2两数相等为真 ,= INT1 -ne INT2 INT1和INT2两数不等为真 ,<> INT1 -gt INT2 INT1大于INT1为真 ,> INT1 -ge INT2 INT1大于等于INT2为真,>= INT1 -lt INT2 INT1小于INT2为真 , INT1 -le INT2 INT1小于等于INT2为真, 五、复杂逻辑判断 -a 与 -o 或 ! 非 exp1: 如果a>b且a if (( a > b )) && (( a 或者 if [[ $a > $b ]] && [[ $a 或者 if [ $a -gt $b -a $a -lt $c ] exp2:如果a>b或a if (( a > b )) || (( a 或者 if [[ $a > $b ]] || [[ $a 或者 if [ $a -gt $b -o $a -lt $c ] \"||\"和\"&&\"在SHELL里可以用，也就是第一个写成if [ a>b && a "},"guan-dao.html":{"url":"guan-dao.html","title":"管道","keywords":"","body":"管道符号 \"|\" 管道经常用于拼接命令，通过管道可以执行一些复杂的数据处理操作 如：查看当前目录的子目录个数 ls -l | cut -c 1 | grep \"d\" | wc -l 14 等价与分别执行每个命令 #1 先获取当前目录下所有文件 ls -l #2 根据第一条命令的输出内容，当前命令截取每行1字符 cut -c 1 #3 根据第二条命令执行完，传递给它-过滤只包含d的 传递给下一条 grep \"d\" #4 统计 -l 统计行数。 wc -l cut 在给出的字符串中截取地几个字符 -c 1 ：指定截取字符1 第一个字符； echo 'asds' | cut -c 2 s echo 'asds' | cut -c 3 d "},"yan-se.html":{"url":"yan-se.html","title":"颜色","keywords":"","body":"字体颜色 #!/bin/bash #字符颜色显示 #-e:允许echo使用转义 #\\033[:开始位 #\\033[0m:结束位 #\\033等同于\\e echo -e \"\\033[30m黑色字\\033[0m\" echo -e \"\\033[31m红色字\\033[0m\" echo -e \"\\033[32m绿色字\\033[0m\" echo -e \"\\033[33m黄色字\\033[0m\" echo -e \"\\033[34m蓝色字\\033[0m\" echo -e \"\\033[35m紫色字\\033[0m\" echo -e \"\\033[36m天蓝字\\033[0m\" echo -e \"\\033[37m白色字\\033[0m\" 背景颜色 #0:关闭特殊效果 #1:高亮显示 #4:下划线 #5:闪烁 #7:反白显示 #8:隐藏不可见 #特殊效果和颜色用;号相隔,没有顺序 echo -e \"\\033[0;46;30m天蓝底黑字\\033[0m\" echo -e \"\\033[1;46;30m天蓝底黑字\\033[0m\" echo -e \"\\033[4;46;30m天蓝底黑字\\033[0m\" echo -e \"\\033[5;46;30m天蓝底黑字\\033[0m\" echo -e \"\\033[7;46;30m天蓝底黑字\\033[0m\" echo -e \"\\033[8;46;30m天蓝底黑字\\033[0m\" "},"shui-mian-he-deng-dai.html":{"url":"shui-mian-he-deng-dai.html","title":"睡眠和等待","keywords":"","body":"wait 在 shell 中使用 wait 是在等待上一批或上一个脚本执行完（即上一个的进程终止），再执行wait之后的命令。 sleep 或者usleep sleep 0.001 毫秒1秒 sleep 1 睡眠1秒 sleep 1s 睡眠1秒 sleep 1m 睡眠1分 sleep 1h 睡眠1小时 sleep支持的时间单位有秒、分、时，默认的单位是秒。 这两个命令都是在某个命令执行完，休眠片刻，主要是因为有些进程在结束之后需要等几秒钟才可启动，例如，tomcat，mongo等 "},"echo.html":{"url":"echo.html","title":"echo","keywords":"","body":"标准输出123dassadaddas s sadsadsdasadassdsdasdadssadsada "},"zi-fu-chuan.html":{"url":"zi-fu-chuan.html","title":"字符串","keywords":"","body":"符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号，也可以不用引号. 单引号 #单引号 str='this is a string' 单引号字符串的限制： 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的。 单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。 双引号 your_name='runoob' str=\"Hello, I know you are \\\"$your_name\\\"! \\n\" echo -e $str #输出结果为： Hello, I know you are \"runoob\"! 双引号的优点： 双引号里可以有变量 双引号里可以出现转义字符 "},"zi-fu-chuan/jie-qu.html":{"url":"zi-fu-chuan/jie-qu.html","title":"截取","keywords":"","body":"#和## 截取左边运输符(保留右边字符) #!/bin/bash a=\"aaa/baihui/aaa\" echo ${a#*/} #截取第一个‘/’ 左边所有字符 /baihui/aaa #匹配左最后一个字符,删除左边的所有字符 echo ${a##*/} aaa # 匹配左边第一字符 ##匹配左最后一个字符 */ 表示从左边开始删除第一个 / 号及左边的所有字符 % 和 %% 截取右边运算符(保留左边) % 从右边开始匹配出现的第一个字符 %% 从右边开始匹配出现的最后一个字符 使用索引项截取 #从左边第几个字符开始，及保留字符的个数 echo ${var:0:5} #从左边第几个字符开始，一直到结束 echo ${var:7} #从右边第7个字符开始保留7字符中的右3个 echo ${var:0-7:3} "},"quote.html":{"url":"quote.html","title":"引用","keywords":"","body":"引号包括单引号和双引号 单引号又叫称“全引用”或“强引用” 双引号又称“部分引用”或“弱引用” 所有用双引号括起来的字符除了美元符（$）、反斜线（\\）、反引号（`）依然保留其特殊用途外，其余字符都作为普通字符处理；而所有用单引号括起的部分都作为普通字符处理，但是要注意单引号中间不能再出现单引号，否则会Shell无法判断到底哪里是单引号的起止位置。 如： #部分引用 echo \"hell >>>> `uname -a`\" hell >>>> Linux bh-desktop 5.0.0-32-generic #34~18.04.2-Ubuntu SMP Thu Oct 10 10:36:02 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux #强引用 echo 'hell >>>> `uname -a`' hell >>>> `uname -a` 引用变量原型-变量扩展 {} a=123 #引用变量原型 echo \">>> ${a}\" >>> 123 #第一变量 a=\"ls -al\" # $a引用变量原型,原型是命令字符 echo `ls -al` 反引号是命令替换-输出当前目录所有内容 echo `$a` ..... 命令替换-也是一种引用 命令替换就是将命令的标准输出作为值彻底给变量或者作为某个命令的输入 反引号用于命令替换和$()的作用相同 `uname -a` #等价 $(uname -a) "},"bian-liang.html":{"url":"bian-liang.html","title":"变量","keywords":"","body":"变量的声明 #声明一个本地变量字符串类型 string_v=\"aaaaa\" || string_v='aaaaa' #声明一个环境变量 export path_v=value #将一个本地变量重新定义为环境变量 export string_v # 使用$(linux命令）来赋值 string_a=$(ls) #定义一个普通变量 asd=`ls -l` echo $asd ... 变量名和等号之间不能有空格，这可能和你熟悉的所有编程语言都不一样。同时，变量名的命名须遵循如下规则： 中间不能有空格，可以使用下划线（_）。 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 除了显式地赋值，还可以用语句命令给变量赋值 如： for file in `ls /etc` #或 for file in $(ls /etc) # 或者这样 id=$(sudo docker run -d -p 3306:3306 -v /home/baihui/mysqls/3306/conf/:/etc/mysql/mysql.conf.d/ -v /home/baihui/mysqls/3306/mysql:/var/lib/mysql -v /home/baihui/mysqls/3306/log/:/var/log/mysql/ -v /home/baihui/mysqls/sql:/home -e MYSQL_ROOT_PASSWORD=root --restart=always mysql:5.7.20) && sudo docker logs -f $id && echo \"容器ID=${id}\" 赋值的是标准的输出，不是返回状态 使用变量 使用一个定义过的变量，只要在变量名前面加美元符号即可如： your_name=\"qinjx\" echo $your_name echo ${your_name} 注意概念就是使用变量和使用命令是不一样的，使用命令通过 ls -al 或者 \"$(ls -al) 称为对命令的引用 而${your_name} 对变量的引用。\" 变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，比如下面这种情况： for skill in Ada Coffe Action Java; do echo \"I am good at ${skill}Script\" done 如果不给skill变量加花括号，写成echo \"I am good at $skillScript\"，解释器就会把$skillScript当成一个变量（其值为空） 已定义的变量，可以被重新定义，如： your_name=\"tom\" echo $your_name your_name=\"alibaba\" echo $your_name 这样写是合法的，但注意，第二次赋值的时候不能写$your_name=\"alibaba\"，使用变量的时候才加美元符（$）。 "},"path.html":{"url":"path.html","title":"环境变量（全局变量）","keywords":"","body":"linux查看和修改PATH环境变量的方法 查看PATH: echo $PATH 修改PATH： export PATH=/usr/local/baihui/bin:$PATH //配置完后可以通过echo $PATH查看配置结果。 生效方法：立即生效 有效期限：临时改变，只能在当前的终端窗口中有效，当前窗口关闭后就会恢复原有的path配置 用户局限：仅对当前用户 修改方法二： 通过修改.bashrc文件: vim ~/.bashrc //在最后一行添上： export PATH=/usr/local/mongodb/bin:$PATH 生效方法：（有以下两种） 1、关闭当前终端窗口，重新打开一个新终端窗口就能生效 2、输入“source ~/.bashrc”命令，立即生效 有效期限：永久有效 用户局限：仅对当前用户 修改方法三: 通过修改profile文件: vim /etc/profile /export PATH //找到设置PATH的行，添加 export PATH=/usr/local/mongodb/bin:$PATH 生效方法：系统重启 有效期限：永久有效 用户局限：对所有用户 修改方法四: 通过修改environment文件: vim /etc/environment 在PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\"中加入“:/usr/local/mongodb/bin” 生效方法：系统重启 有效期限：永久有效 用户局限：对所有用户 "},"hou-tai-jin-cheng.html":{"url":"hou-tai-jin-cheng.html","title":"后台任务","keywords":"","body":"jobs jobs列出当前shell环境中已启动的任务状态，若未指定jobsid，则显示所有活动的任务状态信息。 \"&\" 后台运行命令 # & 在命令最后，可以把命令放到后台执行 tar -zxvf aaa.tar.gz & ./a.sh & ctrl + z前台任务转后台(暂停) #将一个正在前台执行的命令放到后台，并且暂停 fg将后台中的命令调至前台继续运行 ./x220.sh & jobs [1] + running ./x220.sh fg %1 bg将一个在后台暂停的命令，变成继续执行 如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) 如果后台中有多个命令，可以用 fg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) 用“&”把进程放入后台以后 ls& cd& 如果需要了解进程的执行情况，可以使用wait函数。默认情况下wait会等待任意子进程结束但是不会返回子进程的返回值。而以子进程的pid作为参数调用wait时，wait便能够返回该子进程的退出状态了。 具体操作如 我们用“&”把进程放入后台以后，如果需要了解进程的执行情况，可以使用wait函数。默认情况下wait会等待任意子进程结束但是不会返回子进程的返回值。而以子进程的pid作为参数调用wait时，wait便能够返回该子进程的退出状态了。 具体操作如下： #!/bin/bash dir=`dirname $0` $dir/test01.sh & $dir/test02.sh & echo '' > $dir/tmp.log for pid in $(jobs -p) do wait $pid status=$? if [ $status != 0 ];then echo \"$pid status is $status have some error!\" >> $dir/tmp.log else echo \"$pid status is $status success!\" >> $dir/tmp.log fi done 这里我们借助了“jobs -p“来获得所有后台进程的pid。 "},"chuan-di-can-shu.html":{"url":"chuan-di-can-shu.html","title":"传递参数","keywords":"","body":""},"chuan-di-can-shu/gei-jiao-ben-chuan-di-can-shu.html":{"url":"chuan-di-can-shu/gei-jiao-ben-chuan-di-can-shu.html","title":"给脚本传递参数","keywords":"","body":"在执行Shell 脚本时可以向脚本传递参数。脚本内获取参数的格式为： $n。（n 代表一个数字，0为所执行的shell脚本名称，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推……） #!/bin/bash echo \"Shell 输出脚本名称及参数\"; echo \"执行的脚本名：$0\"; echo \"第一个参数为：$1\"; echo \"第二个参数为：$2\"; echo \"第三个参数为：$3\"; $ ./test.sh 1 2 3 Shell 传递参数实例！ 执行的文件名：./test.sh 第一个参数为：1 第二个参数为：2 第三个参数为：3 在脚本内通过如下变量名获取不同的信息 变量名 $# 获取传递到脚本内的参数数量，如 ./test.sh 1 2 3 4 $#=5 $* 将所有参数转换成一个字符串变量 $$ 获取运行当前脚本的进程ID $! 获取后天运行的最后一个ID $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数,如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误 命令退出状态 和标准输出不一样 echo 'aaaaa' 标准输出 return 0 退出状态 "},"chuan-di-can-shu/jie-shou-biao-zhun-de-shu-5165-jian-pan.html":{"url":"chuan-di-can-shu/jie-shou-biao-zhun-de-shu-5165-jian-pan.html","title":"接收标准的输入-键盘","keywords":"","body":"read #!/bin/bash #提示“请输入姓名”并等待30秒，把用户的输入保存入变量name中 read -t 30 -p \"请输入用户名称:\" name echo -e \"\\n\" echo \"用户名为:$name\" #提示“请输入密码”并等待30秒，把用户的输入保存入变量age中，输入内容隐藏 read -t 30 -s -p \"请输入用户密码:\" age echo -e \"\\n\" echo \"用户密码为:$age\" #提示“请输入性别”并等待30秒，把用户的输入保存入变量sex中，只接受一个字符输入 read -t 30 -n 1 -p \"请输入用户性别:\" sex echo -e \"\\n\" echo \"性别为$sex\" "},"yun-xing-jiao-ben.html":{"url":"yun-xing-jiao-ben.html","title":"运行脚本","keywords":"","body":"以其他身份或者shell环境执行 #切换root执行一条命令 su - root -c your_command #或者 #切换用户环境，执行一个shell文件 su - root -s /bin/bash your_shell.sh "},"wen-ben-fen-xi.html":{"url":"wen-ben-fen-xi.html","title":"文本分析","keywords":"","body":"AWK是一个优良的文本处理工具，Linux及Unix环境中现有的功能最强大的数据处理引擎之一。 分析访问日志 日志格式: '$remote_addr - $remote_user [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" \"$http_user_agent\" \"$http_x_forwarded_for\"' #统计访问IP次数 awk '{a[$1]++}END{for(v in a)print v,a[v]}' access.log #统计访问访问大于100次的IP awk '{a[$1]++}END{for(v ina){if(a[v]>100)print v,a[v]}}' access.log 时间段匹配 [root@centos-1 ~]# cat c 10:01 10:02 10:03 10:05 10:06 10:07 12:01 11:01 #awk的时间匹配是不受时间顺序的影响 [root@centos-1 ~]# awk '$1>=\"10:05\" && $1 "},"wen-ben-fen-xi/awk.html":{"url":"wen-ben-fen-xi/awk.html","title":"awk","keywords":"","body":"awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 如：查询5条最新登录信息，只显示用户名或者其他信息 :~$ last -n 5 baihui pts/1 192.168.1.6 Fri Apr 19 06:53 still logged in baihui pts/0 192.168.1.6 Thu Apr 18 22:26 - 00:21 (01:55) #awk 默认以空格将每行(\\n) 数据进行分割 9块 {print $1} 输出分割后的第一项 last -n 5 | awk '{print $1}' baihui baihui #输出第2项 last -n 5 | awk '{print $2}' pts/1 pts/0 #输出第7项 last -n 5 | awk '{print $7}' 06:53 22:26 2019 awk工作流程是这样的： 读入有'\\n'换行符分割的一条记录，然后将记录按指定的分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是\"空白键\" 或 \"[tab]键\",所以$1表示登录用户，$3表示登录用户ip,以此类推 命令格式：awk [-F field-separator] 'commands' input-file(s) commands 是真正awk命令 [-F域分隔符]是可选的 默认空格 input-file(s) 是待处理的文件 awk提供了内置变量 awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量 变量 说明 ARGC 命令行参数个数 ARGV 命令行参数排列 ENVIRON 支持队列中系统环境变量的使用 FILENAME awk浏览的文件名 FNR 浏览文件的记录数 FS 设置输入域分隔符，等价于命令行 -F选项 NF 浏览记录的域的个数 NR 已读的记录数 OFS 输出域分隔符 ORS 输出记录分隔符 RS 控制记录分隔符 last -n 5 | awk '{print \"记录行数:\" NR ,$1 }' 记录行数:1 baihui 记录行数:2 baihui 记录行数:3 baihui 记录行数:4 baihui 记录行数:5 baihui 记录行数:6 记录行数:7 wtmp #输出几项 ps -aux|grep tomcat | awk '{print $2 ,$12 }' "},"grep.html":{"url":"grep.html","title":"grep","keywords":"","body":"Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。 主要参数 -a或--text 不要忽略二进制的数据。 -A或--after-context= 除了显示符合范本样式的那一列之外，并显示该列之后的内容。 -b或--byte-offset 在显示符合范本样式的那一列之前，标示出该列第一个字符的位编号。 -B或--before-context= 除了显示符合范本样式的那一列之外，并显示该列之前的内容。 -c或--count 计算符合范本样式的列数。 -C或--context=或- 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。 -d或--directories= 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e或--regexp= 指定字符串做为查找文件内容的范本样式。 -E或--extended-regexp 将范本样式为延伸的普通表示法来使用。 -f或--file= 指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。 -F或--fixed-regexp 将范本样式视为固定字符串的列表。 -G或--basic-regexp 将范本样式视为普通的表示法来使用。 -h或--no-filename 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。 -H或--with-filename 在显示符合范本样式的那一列之前，表示该列所属的文件名称。 -i或--ignore-case 忽略字符大小写的差别。 -l或--file-with-matches 列出文件内容符合指定的范本样式的文件名称。 -L或--files-without-match 列出文件内容不符合指定的范本样式的文件名称。 -n或--line-number 在显示符合范本样式的那一列之前，标示出该列的列数编号。 -q或--quiet或--silent 不显示任何信息。 -r或--recursive 此参数的效果和指定“-d recurse”参数相同。 -s或--no-messages 不显示错误信息。 -v或--revert-match 反转查找。 -V或--version 显示版本信息。 -w或--word-regexp 只显示全字符合的列。 -x或--line-regexp 只显示全列符合的列。 -y 此参数的效果和指定“-i”参数相同。 --help 在线帮助。 pattern正则表达式主要参数： \\： 忽略正则表达式中特殊字符的原有含义。 ^：匹配正则表达式的开始行。 $: 匹配正则表达式的结束行。 \\：到匹配正则表达式的行结束。 [ ]：单个字符，如[A]即A符合要求 。 [ - ]：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。 。：所有的单个字符。 * ：有字符，长度可以为0。 4.grep命令使用简单实例 $ grep ‘test’ d* 显示所有以d开头的文件中包含 test的行。 $ grep ‘test’ aa bb cc 显示在aa，bb，cc文件中匹配test的行。 $ grep ‘[a-z]\\{5\\}’ aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。 $ grep ‘w\\(es\\)t.*\\1′ aa 如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符(.*)，这些字符后面紧跟着 另外一个es(\\1)，找到就显示该行。如果用egrep或grep -E，就不用”\\”号进行转义，直接写成’w(es)t.*\\1′就可以了。 5.grep命令使用复杂实例 假设您正在’/usr/src/Linux/Doc’目录下搜索带字符 串’magic’的文件： $ grep magic /usr/src/Linux/Doc/* sysrq.txt:* How do I enable the magic SysRQ key? sysrq.txt:* How do I use the magic SysRQ key? 其中文件’sysrp.txt’包含该字符串，讨论的是 SysRQ 的功能。 默认情况下，’grep’只搜索当前目录。如果 此目录下有许多子目录，’grep’会以如下形式列出： grep: sound: Is a directory 这可能会使’grep’ 的输出难于阅读。这里有两种解决的办法： 明确要求搜索子目录：grep -r 或忽略子目录：grep -d skip 如果有很多 输出时，您可以通过管道将其转到’less’上阅读： $ grep magic /usr/src/Linux/Documentation/* | less 这样，您就可以更方便地阅读。 有一点要注意，您必需提供一个文件过滤方式(搜索全部文件的话用 *)。如果您忘了，’grep’会一直等着，直到该程序被中断。如果您遇到了这样的情况，按 ，然后再试。 下面还有一些有意思的命令行参数： grep -i pattern files ：不区分大小写地搜索。默认情况区分大小写， grep -l pattern files ：只列出匹配的文件名， grep -L pattern files ：列出不匹配的文件名， grep -w pattern files ：只匹配整个单词，而不是字符串的一部分(如匹配’magic’，而不是’magical’)， grep -C number pattern files ：匹配的上下文分别显示[number]行， grep pattern1 | pattern2 files ：显示匹配 pattern1 或 pattern2 的行， grep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。 grep -n pattern files 即可显示行号信息 grep -c pattern files 即可查找总行数 这里还有些用于搜索的特殊符号： \\ 分别标注单词的开始与结尾。 例如： grep man * 会匹配 ‘Batman’、’manic’、’man’等， grep ‘\\’ 只匹配’man’，而不是’Batman’或’manic’等其他的字符串。 ‘^’：指匹配的字符串在行首， ‘$’：指匹配的字符串在行 尾， "},"grep/or-and-andand.html":{"url":"grep/or-and-andand.html","title":"or and &&","keywords":"","body":"在grep中，我们有相当于OR和NOT运算符的选项，但没有AND运算符。但是，我们可以使用模式来模拟AND。在本文的例子将有助于理解如何使用grep命令的OR, AND和NOT运算进行文本的搜索。 本文将使用下面的employee.txt文件作为例子讲解： $ cat employee.txt 100 Thomas Manager Sales $5,000 200 Jason Developer Technology $5,500 300 Raj Sysadmin Technology $7,000 400 Nisha Manager Marketing $9,500 500 Randy Manager Sales $6,000 Grep OR操作符 可以使用下面提供的4种方法来实现grep OR功能。 使用“|” 如果使用不带任何选项的grep命令，则需要使用\"|\"来分隔条件OR的多个模式。 grep 'pattern1|pattern2' filename 例如，grep来自employee.txt文件的Tech或Sales。如果分隔符|前没有反斜杠，则以下操作无效。 [jinguang1@localhost ~]$ grep \"Tech|Sales\" employee.txt [jinguang1@localhost ~]$ grep \"Tech|Sales\" employee.txt 100 Thomas Manager Sales $5,000 200 Jason Developer Technology $5,500 300 Raj Sysadmin Technology $7,000 500 Randy Manager Sales $6,000 使用-E选项 grep -E选项用于扩展正则表达式。如果使用带-E选项的grep命令，则只需使用|为条件OR来分隔多个模式。 grep -E 'pattern1|pattern2' filename 例如，grep来自employee.txt文件的Tech或Sales。仅使用“|”来作为多个模式。 [jinguang1@localhost ~]$ grep -E \"Tech|Sales\" employee.txt 100 Thomas Manager Sales $5,000 200 Jason Developer Technology $5,500 300 Raj Sysadmin Technology $7,000 500 Randy Manager Sales $6,000 使用egrep egrep和grep -E功能完全相同。 egrep 'pattern1|pattern2' filename 例如，grep来自employee.txt文件的Tech或Sales。仅使用“|”来作为多个模式。 [jinguang1@localhost ~]$ egrep \"Tech|Sales\" employee.txt 100 Thomas Manager Sales $5,000 200 Jason Developer Technology $5,500 300 Raj Sysadmin Technology $7,000 500 Randy Manager Sales $6,000 使用grep -e 使用grep -e选项，你仅能使用一个参数。如果要使用多个模式，则需要在命令中提供多个-e选项。 grep -e pattern1 -e pattern2 filename 例如，grep来自employee.txt文件的Tech或Sales。使用多个-e选项来支持多个OR模式。 [jinguang1@localhost ~]$ grep -e Tech -e Sales employee.txt 100 Thomas Manager Sales $5,000 200 Jason Developer Technology $5,500 300 Raj Sysadmin Technology $7,000 500 Randy Manager Sales $6,000 Grep AND 使用-E \"pattern1.*pattern2\" grep中并没有AND操作符，但你可以使用-E选项来模拟。 grep -E 'pattern1.pattern2' filename grep -E 'pattern1.pattern2|pattern2.*pattern1' filename 下面的例子将grep所有同时包含“Dev”和\"Tech\"的行，并且保持包含字符串的相应顺序。 [jinguang1@localhost ~]$ grep -E \"Dev.*Tech\" employee.txt 200 Jason Developer Technology $5,500 下面的例子将grep所有包含“Manager\"和\"Sales\"的行，且这个字符串可以以任意顺序出现。 [jinguang1@localhost ~]$ grep -E \"Manager.Sales|Sales.Manager\" employee.txt 100 Thomas Manager Sales $5,000 500 Randy Manager Sales $6,000 使用多个grep命令 可以使用管道来连接多个grep命令来模拟AND操作符。 grep -E 'pattern1' filename | grep -E 'pattern2' 下面的例子将grep所有包含“Manager\"和\"Sales\"的行，且这个字符串可以以任意顺序出现。 [jinguang1@localhost ~]$ grep Manager employee.txt | grep Sales 100 Thomas Manager Sales $5,000 500 Randy Manager Sales $6,000 Grep NOT 使用grep -v选项可以模拟NOT操作符。-v选项为相反匹配设计，它可以match所有不包含指定模式的行。 grep -v 'pattern1' filename 下面的例子中将显示所有不包含“Sales”关键字的行。 [jinguang1@localhost ~]$ grep -v Sales employee.txt 200 Jason Developer Technology $5,500 300 Raj Sysadmin Technology $7,000 400 Nisha Manager Marketing $9,500 下面的例子中将显示所有的Manager和Developer，但忽略Sales。 [jinguang1@localhost ~]$ grep -E \"Manager|Developer\" employee.txt | grep -v Sales 200 Jason Developer Technology $5,500 作者：刘近光 来源：CSDN 原文：https://blog.csdn.net/jinguangliu/article/details/81129426 版权声明：本文为博主原创文章，转载请附上博文链接！ "},"shu-ju-lei-xing-pan-duan.html":{"url":"shu-ju-lei-xing-pan-duan.html","title":"数据类型判断","keywords":"","body":"文件类型判断 类型 说明 -e 判断对象是否存在 -d 判断对象是否存在，并且为目录 -f 判断对象是否存在，并且为常规文件 -L 判断对象是否存在，并且为符号链接 -h 判断对象是否存在，并且为软链接 -s 判断对象是否存在，并且长度不为0 -r 判断对象是否存在，并且可读 -w 判断对象是否存在，并且可写 -x 判断对象是否存在，并且可执行 -O 判断对象是否存在，并且属于当前用户 -G 判断对象是否存在，并且属于当前用户组 -nt 判断file1是否比file2新 [ \"/data/file1\" -nt \"/data/file2\" ] -ot 判断file1是否比file2旧 [ \"/data/file1\" -ot \"/data/file2\" ] #文件存在则删除 if [ ! -f \"/data/filename\" ];then echo \"文件不存在\" else rm -f /data/filename fi #判断文件夹是否存在 if [ -d \"/data/\" ];then echo \"文件夹存在\" else echo \"文件夹不存在\" fi "},"returnyu-exit-qu-bie.html":{"url":"returnyu-exit-qu-bie.html","title":"return与exit区别","keywords":"","body":"exit 是用来结束一个程序的执行的，而return只是用来从一个函数中返回 exit 0 表示正常退出执行程序,其他自定义 "},"redirect.html":{"url":"redirect.html","title":"重定向","keywords":"","body":"重定向-就是将原本应该从标准输入设备（键盘）输入的数据，改由其他文件或设备输入；或将原本应该输出到标准输出设备（显示器）的内容，改而输出到其他文件或设备上 IO重定向包括如下 标准输出重定向到文件中:>和>> #当前目录`ls-l`覆盖输出到文件中 ls-l>aaa.txt #追加输出 ls-l>>aaa.txt 标识输出重定向:>& 将一个标识的输出重定向到另一个表示的 标准输入重定向: 标准输入重定向可以将原本应由从标准输入设备中读取的内容转由文件内容输入，也就是将文件内容写入标准输入中。 echo `cat aaa.txt` 总用量 356 #将文本内容重定向到cat，cat在标准的输出 cat 管道: | 管道就是将一个命令的输出作为另一个命令的输入。 "},"exec.html":{"url":"exec.html","title":"exec","keywords":"","body":"exec是Shell的内建命令，执行这个命令时系统不会启动新的Shell，而是用要被执行的命令替换当前的Shell进程。 在一个Shell窗口中执行exec ls 则在列出当前目录后该Shell进程将会主动退出 #在运行完命令后当前shell进程会退出-也就会关闭窗口 exec ls # 等待5秒 退出 exec sleep 5 # 如使用远程登录ssh exec ssh baihiu@192.168.1.0 exit #当远程执行exit退出了，表示当前命令执行完成，所以当前shell进程也退出 "},"networkfilesystem.html":{"url":"networkfilesystem.html","title":"网络","keywords":"","body":"协议 NFS的本质是文件系统。主要在Unix系列操作系统上使用，基于TCP/IP协议层，可以将远程的计算机磁盘挂载到本地，像本地磁盘一样操作。 samba是Unix系统下实现的 Windows文件共享协议-CIFS，由于Windows共享是基于NetBios协议，是基于Ethernet的广播协议，在没有透明网桥的情况下（如VPN）是不能跨网段使用的。它主要用于unix和windows系统进行文件和打印机共享，也可以通过samba套件中的程序挂载到本地使用。 FTP的目的是在Internet上共享文件而发明的一种协议，基于TCP/IP。世界上绝大多数系统都会有支持FTP的工具存在，通用性很强。目前少有人把VPS修改成支持FTP组件的形式，主要是因为FTP一开始就不是为了文件系统而设计的。 三种协议虽然都可以支持文件共享，但是其功能点和侧重点上面各有所不同，协议格式不同。Authentication（鉴定）也就是你说的登陆方式也会随着协议的内容也有所不同。标准的FTP协议的登陆密码是用明文传输的，没有加密，这会有很大的安全隐患，目前有FTPs(FTP on SSL/TLS)和sFTP(SSH FTP)等基于通信层进行加密的FTP协议，这样会有更好的安全性。NFS的鉴定机制是基于IP地址的，没有密码这种东西。是控制本地映射的用户权限来控制访问者的权限。 "},"networkfilesystem/tcp.html":{"url":"networkfilesystem/tcp.html","title":"TCP/IP协议族","keywords":"","body":"TCP/IP是一类协议也被称为协议簇，它是一套支持网络通信的协议集合，TCP/IP协议定义了网络通信过程，更重要的是，定义了数据单元的格式和内容，以便接收计算机能够正确解释接收到的消息。TCP/IP及其相关的协议构成了一套在TCP/IP网络中如何处理、传输和接收数据的完整系统，相关协议的系统 网络协议就是一套通用规则，用来帮助定义复杂数据传输的过程。 graph LR; subgraph 局域网 客服端A--192.168.1.8:8081-->服务器B 客服端A--www.baidu.com-->源路由器 end 源路由器--互联网-->电信服务商 电信服务商--目标-->目标路由器 目标路由器--局域网IP-->服务器D 服务器D--端口-->服务程序 TCP/IP是一类协议分以下几点： 逻辑编址 在LAN中低层的与硬件相关的协议使用适配器的物理地址(MAC)在物理网络中传输数据,每台计算机的网络适配器监听局域网络中的每一个传输，以确定消息是否是发送到它的物理地址,但是在互联网中物理地址模式不能有效地发挥作用，需要换成路由式网络中，一种细分网络到更小的子网的逻辑编址方法，也就是ip地址 在TCP/IP中，逻辑地址与具体硬件的物理地址之间的转换是使用地址解析协议（AddressResolutionProtocol，ARP）和逆向地址解析协议（ReverseARP，RARP）实现的 路由选择 路由器是一种特殊的设备，能够读取逻辑地址信息，并将数据通过网络直接传送到它的目的地 在局域网中，数据传输到另一台计算机或设备时，不用经过路由器，因此不会给大型网络的传输线路带来负担,如果数据要传送到子网以外的计算机上，路由器将负责转发数据 名称解析 TCP/IP同时提供了IP地址的另外一种结构，它以字母数字命名，可以方便用户的使用。这种结构称为域名或域名系统。域名到IP地址的映射称为名称解析。 域名服务器的专用计算机中存储了用于显示域名和IP地址转换方式的表。 错误控制和流量控制 TCP/IP协议簇提供了确保数据在网络中可靠传送的特性,包括检查数据的传输错误（确保到达的数据与发送的数据一致）和确认成功接收到网络信息 应用支持 TCP/IP协议提供了判断接收到的数据包属于哪个应用程序。 通过tcp系统的逻辑通道实现从网络到应用程序的接口被称为端口。每个端口有一个用于识别该端口的数字。可以把端口想象为计算机中的逻辑管道，数据通过这些管道实现在应用程序和协议软件之间的传输 graph LR; subgraph TCP/IP MAC--地址解析协议-->源IP地址 源IP地址--理由选择-->目标ID 源IP地址--错误控制和流量控制-->目标ID 目标ID--端口-->服务程序 end "},"networkfilesystem/tcp/tcp.html":{"url":"networkfilesystem/tcp/tcp.html","title":"TCP协议","keywords":"","body":"TCP状态 TCP协议规定，对于已经建立的连接，网络双方要进行四次握手才能成功断开连接，如果缺少了其中某个步骤，将会使连接处于假死状态，连接本身占用的资源不 会被释放。 网络服务器程序要同时管理大量连接，所以很有必要保证无用连接完全断开，否则大量僵死的连接会浪费许多服务器资源. 在众多TCP状态中，最值得 注意的状态有两个：CLOSE_WAIT和TIME_WAIT LISTENING状态 FTP服务启动后首先处于侦听（LISTENING）状态。 ESTABLISHED状态 ESTABLISHED的意思是建立连接。表示两台机器正在通信。 CLOSE_WAIT 对方主动关闭连接或者网络异常导致连接中断，这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭 TIME_WAIT 我方主动调用close()断开连接，收到对方确认后状态变为TIME_WAIT。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分 段最大生存期)，以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放，所以作为服务器，在可能的情 况下，尽量不要主动断开连接，以减少TIME_WAIT状态造成的资源浪费。 目前有一种避免TIME_WAIT资源浪费的方法，就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的，在某些情况下这个操作可能会带来错误。 SYN_SENT状态 　 　SYN_SENT状态表示请求连接，当你要访问其它的计算机的服务时首先要发个同步信号给该端口，此时状态为SYN_SENT，如果连接成功了就变为ESTABLISHED 此时SYN_SENT状态非常短暂。但如果发现SYN_SENT非常多且在向不同的机器发出，那你的机器可能中了冲击波或震荡波 之类的病毒了。这类病毒为了感染别的计算机，它就要扫描别的计算机，在扫描的过程中对每个要扫描的计算机都要发出了同步请求，这也是出现许多 SYN_SENT的原因。 "},"networkfilesystem/tcp/tcp/tcpxie-yi.html":{"url":"networkfilesystem/tcp/tcp/tcpxie-yi.html","title":"TCP协议","keywords":"","body":"TCP协议提供可靠的连接服务,采用三次握手建立一个连接,四次断开一个连接 SYN_SEND 第一次握手 建立连接时,客户端发送syn包(syn=j)到服务器,并进入SYN_SEND状态,等待服务器确认. SYN：同步序列编号(Synchronize Sequence Numbers) 第二次握手 服务器收到syn包,必须确认客户的SYN（ack=j+1）,同时自己也发送一个SYN包（syn=k）,即SYN+ACK包,此时服务器进入SYN_RECV状态 第三次握手 客户端收到服务器的SYN＋ACK包,向服务器发送确认包ACK(ack=k+1),此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手 sequenceDiagram participant 客服端 participant 服务端 客服端 ->> 服务端: 发送syn包(syn=k) 服务端 ->> 客服端: ack=k+1,syn=s alt 客服端确认(k-1 == ack) 客服端->>服务端: 客服端发送ack=s+1 alt 服务端确认(s-1 == ack) Note right of 客服端:双方进入ESTABLISHED状态 else 服务端-x客服端: ack确认包失败,连接断开 end else ack!=k-1 客服端-x服务端: ack确认包失败,连接断开 end TCP协议定义的3次握手断开连接规定,发起socket主动关闭的一方 socket将进入TIME_WAIT状态. TIME_WAIT状态将持续2个MSL(Max Segment Lifetime),在Windows下默认为4分钟,即240秒,TIME_WAIT状态下的socket不能被回收使用. 具体现象是对于一个处理大量短连接的服务器,如果是由服务器主动关闭客户端的连接,将导致服务器端存在大量的处于TIME_WAIT状态的socket, 甚至比处于Established状态下的socket多的多,严重影响服务器的处理能力,甚至耗尽可用的socket,停止服务. TIME_WAIT是TCP协议用以保证被重新分配的socket不会受到之前残留的延迟重发报文影响的机制,是必要的逻辑保证. "},"networkfilesystem/tcp/icmp.html":{"url":"networkfilesystem/tcp/icmp.html","title":"ICMP协议","keywords":"","body":"在IP通信经常有数据包到达不了对方的情况或者达了对方但是由于搞错了端口号 这时ICMP报文就起到作用,ICMP协议大致分成两种功能差错通知和信息查询。 制定万维网规格的IETF 在1981 年将RFC7922作为ICMP 的基本规格整理出来了。那个RFC792 的开头部分里写着“ICMP 是IP 的不可缺少的部分，所有的IP 软件必须实现ICMP协议。也是ICMP 是为了分担IP 一部分功能而被制定出来的 ICMP的作用 错误通知 客服端发送的IP数据包被接收设备接收过程中发生了错误。由接收端发送icmp错误消息到客服端。 信息查询 由送信方向接收端询问信息时被使用,被询问内容的种类非常丰富他们有目标IP地址的机器是否存在这种基本确认，调查自己网络的子网掩码，取得对方机器的时间信息等. ICMP协议在IP协议的上层工作,所以ICMP的报文是放在IP数据包的数据部分里来互相交流的 ICMP数据格式: 类型 代码 选项数据 所有ICMP用来交流错误通知和信息询问的报文都是由类型和代码的组合来表示的。 RFC 定义了15种类型。“报文不可到达”这样的错误通知和“回送请求”这样的信息查询是由类型字段来区分的。ICMP报文由类型来表达它的大概意义，需要传递细小的信息时由代码来分类。进一步，需要向对方传送数据的时候，用7）选项数据字段来放置 "},"networkfilesystem/tcp/icmp/mtutan-suo.html":{"url":"networkfilesystem/tcp/icmp/mtutan-suo.html","title":"MTU探索","keywords":"","body":"所谓路径MTU探索是探索与通信对方之间不用分片IP数据包，就能交流的MTU大小的功能。 MTU大小是指计算机一次能够送出去的数据的最大长度IP数据包，基本上由网路的种类来决定. 以太网的话通常是1500 字节，使用PPPoE 的ADSL 通常是1492 字节,也就是一个IP数据包最大1500或者1492字节 路径MTU 探索的原理本身是非常简单的 首先，Windows 向通信对方送IP 数据包时，先设置IP 首部的分片禁止标志然后再送。这是路径MTU 探索的基本。 假如，Windows 将大于1000 字节的数据包送了出去，通信路径上有MTU 从1500 字节变成1000 字节的地方。因此，那个路由器将不允许超过1000 字节的数据包通过，而进入MTU 是1000 字节的网路。路由器尝试着将IP 数据包分片。但是因为数据包的分片禁止标志是有效的，所以不能分片。该路由器就将该IP 数据包丢弃，并用ICMP 通知送信方“想分片，但不能分片”。这时路由器发送的ICMP的类型字段是3，代码字段为4。这是“需要分片但不能分片，不能送至终点”的意思。而且，大多数路由器将在数据选项部里填入不分片就能通过的MTU 大小。Windows 收到该ICMP 报文后就知道了不分片就能够传送的数据大小，并暂时将MTU 大小更换掉，然后继续通信。 "},"networkfilesystem/tcp/icmp/gai-bian-lu-you.html":{"url":"networkfilesystem/tcp/icmp/gai-bian-lu-you.html","title":"改变路由","keywords":"","body":"改变路由是指路由器向送信方计算机指示路径改变这个功能。计算机根据自己的路由信息(路由表)来决定传送目标。不知道发给谁好的时候，就将数据包发给设为默认网关的路由器。被指定为默认网关的路由器接收到数据包，发现将数据包发给局域网内的其它路由器会比较快的时候，将这一信息通过ICMP 通知发送方。这时使用的是，类型是5，代码是1 的ICMP 改变路由报文。在选项数据部分里写着应该发送给的路由器IP 地址。Windows 收到这个报文后，重写自己的路由表，与对方的通信将在一段时间里经由被指定的路由器来实行。 "},"networkfilesystem/tcp/icmp/yuan-dian-yi-zhi.html":{"url":"networkfilesystem/tcp/icmp/yuan-dian-yi-zhi.html","title":"源点抑制","keywords":"","body":"数据包集中到达某一路由器后，数据包因为来不及被处理，有可能被丢弃的情况。这时候，向送信方发送的是ICMP 源点抑制报文，用来使送行方减慢发送速度 "},"networkfilesystem/tcp/icmp/pingming-ling.html":{"url":"networkfilesystem/tcp/icmp/pingming-ling.html","title":"ping命令","keywords":"","body":"ping 命令用来在IP 层次上调查与指定机器是否连通，调查数据包往复需要多少时间。为了实现这个功能，ping 命令使用了两个ICMP 报文 1.向目标服务器发送回送请求 首先，向目标服务器发出回送请求（类型是8，代码是0）报文（同2）。在这个回送请求报文里，除了类型和代码字段，还被追加了标识符和序号字段。标识符和序号字段分别是16 位的字段。ping 命令在发送回送请求报文时，在这两个字段里填入任意的值。对于标识符，应用程序执行期间送出的所有报文里填入相同的值。对于序号，每送出一个报文数值就增加1。而且，回送请求的选项数据部分用来装任意数据。这个任意数据用来调整ping 的交流数据包的大小。 2.鹦鹉学舌一样返回回送回答 计算机送出的回送请求到达目标服务器后，服务器回答这一请求，向送信方发送回送请求（类型是0，代码是0）（同3）。这个ICMP 回送回答报文在IP 层来看，与被送来的回送请求报文基本上一样。不同的只是，源和目标IP 地址字段被交换了，类型字段里填入了表示回送回答的0。也就是，从送信方来看，自己送出的ICMP 报文从目标服务器那里象鹦鹉学舌那样原样返回了。 送信方的计算机可以通过收到回送回答报文，来确认目标服务器在工作着。进一步，记住发送回送请求报文的时间，与接收到回送回答报文的时间一比较，就能计算出报文一去一回往复所需要的时间（同4）。但是，收到的回送回答报文里写的只是类型和代码的话，发送方计算机将无法判断它是否是自己发出去请求的回答。因此，前面说到的标识符和序号字段就有它的意义了。将这两个值与回送回答报文中的相同字段值一比较，送行方计算机就能够简单地检测回送回答是否正确了。执行ping 命令而调查的结果没什么问题的话，就将目标服务器的IP 地址，数据大小，往复花费的时间打印到屏幕上。 3.用ping 命令不能确定与对方连通的原因大致有三个 1）目标服务器不存在；2)花在数据包交流上的时间太长ping 命令认为超时；3）目标服务器不回答ping 命令。如果是原因2），通过ping 命令的选项来延长到超时的等待时间，就能正确显示结果了。如果原因是1）或3）的话，仅凭ping 命令的结果就不能判断是哪方了。正如这样，ping 命令不一定一定能判断对方是否存在。 "},"networkfilesystem/tcp/icmp/duan-kou-sao-miao.html":{"url":"networkfilesystem/tcp/icmp/duan-kou-sao-miao.html","title":"端口扫描","keywords":"","body":"所谓的端口扫描就是检查服务器不需要的端口是否开着。服务器管理者用来检查有没有安全上有问题的漏洞开着。不是象ping 和traceroute 那样是操作系统自带的工具，需要利用网络工具才行。 端口扫描大致分为“UDP 的端口扫描”和“TCP 的端口扫描”两种。这里面，与ICMP 相关的是UDP一边。使用TCP 的通信，通信之前必定要先遵循三向握手的程序。因此，只要边错开端口号边尝试TCP连接就能调查端口的开闭。不特别需要ICMP。与此相对，UDP 没有这样的连接程序。因此，调查端口是否打开需要想点办法。这样，被使用的是ICMP。根据ICMP 规格，UDP 数据包到达不存在的端口时，服务器需要返回ICMP 的“终点不可达”之一的“端口不可达”报文。 具体来说，向希望调查的服务器发送端口号被适当指定了的UDP 数据包。这样，目标端口没开着的话，服务器就返回ICMP 端口不可达报文。返回的ICMP 数据包的选项数据字段里放入着，送信方送出的UDP 数据包的IP 首部与UDP 首部的头8 个字节。送信方通过这个信息来辨别该错误通知是针对哪个UDP 数据包的，并判断端口是否打开着。 UDP 端口扫描一边一个一个错开端口号，一边持续着这个通信。这样，就知道了哪个端口是“好象开着的”了。但是，UDP 端口扫描与TCP 端口扫描有很大区别的地方。那就是，即使ICMP 端口不可达报文没有返回，也不能断定端口开着。端口扫描除了被管理员用来检查服务器上是否有开着的漏洞，作为黑客非法访问的事先调查，对服务器实施的情况也是很多的。需要非常小心地来使用。 "},"networkfilesystem/tcp/icmp/an-quan.html":{"url":"networkfilesystem/tcp/icmp/an-quan.html","title":"安全","keywords":"","body":"为什么停止方便的ICMP？ 为什么有停止ICMP 使用的设定项目呢？理由只有一个，那就是确保安全。虽然ICMP 是非常便利的协议，但黑客在尝试非法访问的时候会被恶意利用。由于ICMP 被恶意使用而遭受损害的用户正在不断增加之中，因此有了限制ICMP 使用的意见。 ICMP数据包攻击 那么实际上，ICMP 被怎样恶意使用的呢？想考虑安全相关问题，不知道这个就开不了头。看两个典型的恶意使用例子吧。 作为恶意使用ICMP 的最有代表性的例子，也就是所谓的 “ping 洪水”的攻击。它利用ping 的原理，向目标服务器发送大量的ICMP 回送请求。这是黑客向特定的机器连续发送大量的ICMP 回送请求报文。目标机器回答到达的ICMP 回送请求已经用尽全力了，原来的通信处理就变得很不稳定了。进一步，目标机器连接的网络也可能由于大量的ICMP 数据包而陷入不可使用的状态。 与ping 洪水相似，以更加恶劣的使用方法而闻名的是称为“smurf”的攻击手法。smurf 同样，黑客恶意的使用ICMP 回送请求报文。这一点同ping 洪水是相同的。不过在smurf，对ICMP 回送请求实施了一些加工。源IP 地址被伪装成攻击对象服务器的地址，目标地址也不是攻击对象服务器的地址，而是成为中转台的网络的广播地址。来具体看一下smurf 攻击的流程吧！ 黑客发送伪装了的ICMP 回送请求后，到达在作为踏板的网络的入口处的路由器。这样，路由器将回送请求转发给网内所有的计算机（同2）。假如有100 台计算机，回送请求将到达100 台所有的计算机。收到回送请求的计算机对此作出反应，送出回送回答报文（同3）。这样，黑客送出的一个ICMP回送请求报文，一下子增加到了100 倍。这样增加的ICMP 回送回答报文面向的不是黑客的计算机，而是伪装成回送请求的源IP 地址的攻击对象服务器。变成到达了，从几百台计算机发出的巨大数量的ICMP 回送回答。smurf 与ping 洪水攻击不同，因为到达服务器的是ICMP 回送回答，服务器不用返回回答。但是为了处理大量的ICMP，服务器承受了大量的负载。网路被撑爆了也是一样的（同4）。 除此之外，还有很多各种各样ICMP 被恶意使用的例子。例如，通知错误或询问信息本身，也有被黑客用来传递谎言的可能性。同用信鸽来扩展谎言的传播，通过传递与事实不同的信息来使人判断错误是一样的。而且，反过来也有传递错误信息而变成问题的例子。例如，在实现篇里看到的端口扫描，黑客就可以利用它来进行攻击对象的调查。进一步，推翻了“ICMP 是用来控制IP 的”这一常识的恶意使用方法也登场了。就是将ICMP 的选项数据部分作为信息搬运工的手法。黑客将这种工具隐藏在服务器里，从外部控制服务器，将用户的个人信息和重要的情报偷盗出来。如上，仅从安全的方面来说，ICMP 是有百害而无一利的。 阻止ICMP后将陷入困境 “那阻止所有的ICMP 不就行了吗！”可能有读者会这样认为。不过那就太轻率了。ICMP 作为支持IP的协议是需要的，所以被制作了。即使没有，也不是说IP 通信本身就完全不行了，实际上会出现几个难办的情况。它的典型例子就是称为“黑洞路由器”的问题。所谓黑洞路由器，就是通信路径上的IP 数据包不留痕迹的消失了的现象。原因是，实现篇里说明的路径MTU 探索功能不起作用了。 假设通信路径上有因为MTU 大小不同而需要分片的路由器。而且，计算机和路由器之间，为了安全上的原因，设置了阻止ICMP 报文通过的防火墙。这种情况下，计算机实行路径MTU 探索将会怎么样呢？ 1.不能调整数据包长度如果是传送路径上不需要分片大小的IP 数据包，它将会毫无问题地到达对方。另一方面，数据包的长度是需要分片的时候，发送就会有问题。正如实现篇看到的，这样的数据包到达连接在不同大小MTU 的网络的路由器后，路由器将用ICMP 终点不可达报文来通知发送方。本来的处理是，送信方接收到该ICMP 报文，根据路径MTU 探索处理调整MTU 大小后继续通信。但是，这次的例子，ICMP 报文被路经中的防火墙隔断了。路径MTU 探索功能不起作用，MTU 的大小也就不能调整了。 2.不知道原理就不可能理解最近从局域网的计算机通过ADSL 服务访问万维网时，经常看到这个黑洞路由器现象。ADSL 线路的MTU 大小，宽带路由器的设定，Windows 的路径MTU 探索功之间互相关联引起了这个现象。糟糕的是，即使有黑洞路由器，也不是完全不能通信这一点。不管怎么样说，被吸进去的只是长度是需要分片的IP 数据包。也就是，考虑一下WEB 访问，连接WEB 服务器时是没有问题的，以文字为主体的页面也大都能被显示，但是含有比较大图像的页面不能被显示。黑洞路由器就由这种复杂奇怪的现象表现出来了。如果不知道路径MTU 探索和黑洞路由器的原理的话，碰到这种现象，可能连猜想原因都很困难了。 3.即使阻止了客户端也没问题如最初所见，在现实的万维网上，如果事先使所有的ICMP 功能有效的话，就会给了黑客各种各样的机会，安全上就会有问题了。另一方面，如果一个一个阻止了的话，不仅非常不方便，而且还会发生黑洞路由器等问题。那么，如何充分运用ICMP 才行呢？客户端，服务器，还有路由器，从各个方面来看一下。首先从客户端开始。最近的宽带路由器和个人防火墙，通过设置来阻止ICMP 的很多。但是，初期设置是千差万别的。阻止全部ICMP 的也有，反过来的也有。其中，只允许ping 命令等一部分ICMP 报文通过的也有。原来，对于安全的考虑方法是根据环境的不同而变化巨大的，并不是一定要这样才行的。但是，最近的倾向是，使连在万维网上的个人计算机不应答没有必要的ICMP 报文。例如Windows XP 的情况下，使用操作系统自带的个人防火墙的话，默认是将外部来的所有ICMP 报文隔断。那么路由器怎么样呢？万维网中的路由器，不小心阻断了ICMP 的话，会发生黑洞路由器等问题。还有，大量的数据包涌过来的时候，如果不发送ICMP 源点抑制报文，处理速度就会跟不上。路由器的话，这样的情况以外，再加上考虑周围网络环境的基础上，再来判断是否阻断不需要的或者可能造成攻击的ICMP数据包比较好吧。服务器就比较难判断了。例如，不让它回应ping 命令的话，连不上服务器的时候，就缺少了调查的有效手段。但是，有受到ping 洪水攻击的可能性也是事实。这些只能由管理者来判断了。 "},"networkfilesystem/tcp/udp.html":{"url":"networkfilesystem/tcp/udp.html","title":"UDP协议","keywords":"","body":""},"networkfilesystem/http.html":{"url":"networkfilesystem/http.html","title":"HTTP协议","keywords":"","body":" HTTP属于应用层协议(一次HTTP操作称为一个事务)： 短连接 在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。 长连接 但从 HTTP/1.1起，默认使用长连接，用以保持连接特性 Connection:keep-alive Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache,Tomcat）中设定这个时间 其工作过程可分为四步 首先客户机与服务器需要建立连接。只要单击某个超级链接，HTTP的工作开始。 通过(TCP/IP协议)建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可能的内容。 服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。 客户端接收服务器所返回的信息通过浏览器显示在用户的显示屏上，然后客户机与服务器断开连接 "},"networkfilesystem/tcp/ipxie-yi.html":{"url":"networkfilesystem/tcp/ipxie-yi.html","title":"IP协议","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing.html","title":"TCP/IP协议分层","keywords":"","body":"TCP/IP协议族里重要的一点就是把包含的协议进行分层,分别分为以下4层 网络访问层 定义了与网络硬件交互和访问传输介质的过程 网际层 传输层 应用层 graph LR; 应用层 --> 传输层 传输层 --> 网际层 网际层 --> 网络访问层 网络访问层-->网际层 网际层-->传输层 传输层-->应用层 "},"networkfilesystem/isoqi-ceng-mo-xing/frame.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/frame.html","title":"frame","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/bitliu.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/bitliu.html","title":"bit流","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/shu-ju-530528-packet.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/shu-ju-530528-packet.html","title":"数据包","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/shu-ju-duan.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/shu-ju-duan.html","title":"数据段","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/wang-luo-fang-wen-ceng.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/wang-luo-fang-wen-ceng.html","title":"网络访问层","keywords":"","body":"TCP/IP协议栈的最底层是网络访问层也是最不统一的TCP/IP层，定义了与网络硬件交互和访问传输介质的过程，它接收来自网际层ip报转换成帧传递给网络硬件 该层主要是在一个网段（比如一个以太局域网）上的计算机之间提供的物理地址进行通信 该层主要包括两部分： 物理寻址 网络访问层需要把逻辑IP地址（通过协议软件来配置）与网络适配器的固定物理地址相关联 经过局域网传递的数据帧必须使用这个物理地址来标识源适配器和目的适配器， TCP/IP使用地址解析协议（ARP）和逆向地址解析协议（RARP）把IP地址关联到网络适配器的物理地址 数据报转换以及发送 根据需要把网际层的数据分解为较小的块。 把块打包成帧。每一帧都包含数据及其他信息 如下： 前导码：表示帧起始的一系列比特。 目标地址：物理地址（MAC）。 源地址：物理地址（MAC）。 长度：两个字节，表示数据段的长度。 数据：帧中传输的数据。 帧校验序列（FCS）。 FCS是检验数据传输的常见方式。发送方计算帧的循环冗余码校验（CRC）值，把这个值写到帧里FCS。接收方计算机重新计算CRC，与FCS字段的值进行比较，如果两个值不相同，就表示传输过程中发生了数据丢失或改变，这时就需要重新传输这一帧。 把数据帧传递给物理层的底层组件，后者把帧转换为比特流，并且通过传输介质发送出去 以太网上其他网络适配器接收到这个帧，检查其中的目的地址。如果目的地址与网络适配器的地址MAC相匹配，适配器软件就会处理接收到的帧，把数据传递给协议栈中较高的层。 网络访问层以上的协议层不必关心硬件设计的问题。TCP/IP协议栈的设计保证了与硬件交互相关的细节都发生在网络访问层，使得TCP/IP能够工作于多种不同的传输介质。 "},"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng.html","title":"网际层","keywords":"","body":"网际层提供的协议负责局域网网段之外的传递，之内由网络访问层负责通讯，其中重要的协议包括IP、ARP和ICMP ip寻址与发送解决方案 该层隐藏了物理地址，以一种逻辑化、层次化的寻址方案对网络进行组织。这种逻辑寻址方案由网际层的IP协议维护，IP协议提供了一种分层的、与硬件无关的寻址系统，在由地址解析协议（ARP把IP地址映射到物理地址） sequenceDiagram participant a as ip协议 participant b as arp协议 participant c as 网关 activate a activate b alt 路由表是否已缓存？ a->>b:ip地址 b->>a: 返回IP对应的MAC地址 else b->>: ARP请求帧广播局域网 end deactivate b deactivate a "},"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng/ipxie-yi.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng/ipxie-yi.html","title":"IP协议","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng/arpxie-yi.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng/arpxie-yi.html","title":"ARP协议","keywords":"","body":"地址解析协议 是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。 #查看路由表 arp -a ? (192.168.1.1) at b0:7f:b9:25:b5:3c on en0 ifscope [ethernet] ? (192.168.1.9) at 60:2:b4:17:68:d on en0 ifscope [ethernet] ? (224.0.0.251) at 1:0:5e:0:0:fb on en0 ifscope permanent [ethernet] ? (239.255.255.250) at 1:0:5e:7f:ff:fa on en0 ifscope permanent [ethernet] #指定IP广播 sudo arping -c 100 192.168.1.5 IP的广播有三种： 本地广播也叫直播 255.255.255.255 ，不跨路由器。本地广播地址，TCP/IP协议规定32比特全为1的IP地址（255.255.255.255）用于本网广播 172.16.33.255叫子网广播，广播给172.16.33.0这个子网，可以跨路由器。 172.16.255.255叫全子网广播，广播给172.16.0.0这个主网，可以跨路由器。 路由器是三层设备，可以隔离广播，但并不是所有广播都隔离。 只有本地广播路由器才不转发，对于子网广播和全子网广播，路由器是转发的。为什么呢？我们来看255.255.255.255的广播，在MAC的封装中，对应的目的MAC是广播，而子网广播和全子网广播，对应的目的MAC是单播，所以路由器会转发。所以路由器隔离的广播是目的MAC为全1的广播，对于目的MAC是单播的上层广播，路由器是不能隔离的。 "},"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng/icmpxie-yi.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/wang-ji-ceng/icmpxie-yi.html","title":"ICMP协议","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/chuan-shu-ceng.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/chuan-shu-ceng.html","title":"传输层","keywords":"","body":""},"networkfilesystem/isoqi-ceng-mo-xing/ying-yong-ceng.html":{"url":"networkfilesystem/isoqi-ceng-mo-xing/ying-yong-ceng.html","title":"应用层","keywords":"","body":""},"networkfilesystem/osimo-xing.html":{"url":"networkfilesystem/osimo-xing.html","title":"OSI模型","keywords":"","body":"OSI模型（Open System Interconnection Model）是一个由ISO提出得到概念模型，试图提供一个使各种不同的的计算机和网络在世界范围内实现互联的标准框架 OSI参考模型采用分层结构 物理层 物理层（Physical Layer）确保原始的数据可在各种物理媒体上传输。在这一层上面规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性，为上层协议提供了一个传输数据的物理媒体。这一层传输的是bit流。 数据链路层 在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控 制、数据的检错、重发等。这一层中将bit流封装成frame帧 网络层 网络层（Network Layer）负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能。在这一层，数据的单位称为数据包 传输层 传输层是第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。在这一层，数据的单位称为数据段（segment） 会话层 这一层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步，访问验证和会话管理在内的建立和维护应用之间通信的机制。如服务器验证用户登录便是由会话层完成的。使通信会话在通信失效时从校验点继续恢复通信 表示层 这一层主要解决用户信息的语法表示问题。它将欲交换的数据从适合于某一用户的抽象语法，转换为适合于OSI系统内部使用的传送语法。即提供格式化的表示和转换数据服务。数据的压缩和解压缩， 加密和解密等工作都由表示层负责 应用层 这一层为操作系统或网络应用程序提供访问网络服务的接口 graph LR; 物理层--比特流-->数据链路层; 数据链路层--frame 帧-->网络层; 网络层--数据包-->传输层; 传输层--Segment-->会话层; 会话层--报文-->表示层; 表示层--报文-->应用层; 各层传输协议、传输单元、主要功能性设备比较 名称 传输协议 传输单元 主要功能设备/接口 物理层 IEEE 802.1A、IEEE 802.2 bit-flow 比特流 光纤、双绞线、中继器和集线器 & RJ-45(网线接口) 数据链路层 ARP、MAC、 FDDI、Ethernet、Arpanet、PPP、PDN frame 帧 网桥、二层交换机 网络层 IP、ICMP、ARP、RARP 数据包（packet） 路由器、三层交换机 传输层 TCP、UDP Segment/Datagram 四层交换机 会话层 SMTP、DNS 报文 QoS 表示层 Telnet、SNMP 报文 – 应用层 FTP、TFTP、Telnet、HTTP、DNS 报文 – # "},"virtualnetwork.html":{"url":"virtualnetwork.html","title":"虚拟网络基础","keywords":"","body":" namespace namespace是Linux虚拟网络的一个重要概念，传统的Linux的许多资源是全局的，如果进程id资源。而namespace的目的首先就是讲这些资源做资源隔离。Linux可以在一个Host内创建许多namespace，于是那些原本是linux的全局资源，就变成了namespace范围内的“全局”资源，而且不同namespace的资源相互不可见，彼此透明。 Linux namespace 可以隔离的资源有：uts_ns（内存、版本等底层信息）、ipc_ns（所有与进程通信的信息）、 mnt_ns（当前装载的文件系统）、 pid_ns（有关进程id的信息）、 user_ns（资源配额的信息）、 net_ns（网络信息）。 一个设备（Linux Device）只能位于一个namespace中，不同namespace中的设备可以利用veth pair进行桥接。 veth pair Virtual Ethernet Pair简称veth pair,是一个成对的端口,所有从这对端口一端进入的数据包都将从另一端出来,反之也是一样. Bridge 在Linux的语境中，Bridge和Switch是一个概念。Bridge是一个虚拟网络设备，所以具有网络设备的特征，可以配置IP、MAC地址等；Bridge是一个虚拟交换机，和物理交换机有类似的功能。对于普通的网络设备来说，只有两端，从一端进来的数据会从另一端出去，如物理网卡从外面网络中收到的数据会转发给内核协议栈，而从协议栈过来的数据会转发到外面的物理网络中。 而Bridge不同，Bridge有多个端口，数据可以从任何端口进来，进来之后从哪个口出去和物理交换机的原理差不多，要看mac地址。 "},"ufw.html":{"url":"ufw.html","title":"防火墙-iptables","keywords":"","body":"iptables 其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的\"安全框架\"中，这个\"安全框架\"才是真正的防火墙，这个框架的名字叫 netfilter 才是防火墙真正的安全框架（framework），netfilter位于内核空间 iptables其实是一个命令行工具，位于用户空间，我们用这个工具操作真正的框架。 netfilter/iptables（下文中简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。 Netfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能： 网络地址转换(Network Address Translate) 数据包内容修改 以及数据包过滤的防火墙功能 虽然我们使用service iptables start启动iptables\"服务\"，但是其实准确的来说，iptables并没有一个守护进程，所以并不能算是真正意义上的服务，而应该算是内核提供的功能。 iptables是按照规则来办事的，规则其实就是网络管理员预定义的条件，规则一般的定义为 如果数据包头符合这样的条件，就这样处理这个数据包 。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。 "},"ufw/ufw.html":{"url":"ufw/ufw.html","title":"UFW","keywords":"","body":"UFW是iptables的一个防火墙配置工具，UFW是管理 iptables 防火墙规则，其主要目的就是让管理 iptables 更加轻松容易。 在ubunut中默认安装当未开启 sudo ufw status verbose 防火墙策略是构建用户自定义规则的基础，在绝大多数情况下，初始的 UFW 默认策略就是一个很好的起点。 默认情况下，UFW 将阻止所有传入连接并允许所有传出连接。也就是说，除非打开特定端口，否则任何尝试访问服务器的人都无法连接，但服务器上运行的应用程序和服务却能够对外访问。 UFW 默认策略在 /etc/default/ufw 文件中进行定义，可以使用 sudo ufw default 命令对策略进行更改 #查询防火墙参数 sudo ufw show Commands: enable 启用防火墙 disable 禁用防火墙 default ARG set default policy logging LEVEL set logging to LEVEL allow ARGS add allow rule deny ARGS add deny rule reject ARGS add reject rule limit ARGS add limit rule delete RULE|NUM delete RULE insert NUM RULE insert RULE at NUM route RULE add route RULE route delete RULE|NUM delete route RULE route insert NUM RULE insert route RULE at NUM reload reload firewall reset reset firewall status show firewall status status numbered show firewall status as numbered list of RULES status verbose show verbose firewall status show ARG show firewall report version display version information 应用配置命令: app list 显示所有添加应用查询信息 app info PROFILE show information on PROFILE app update PROFILE update PROFILE app default ARG set default application policy #如：当前服务器添加规则的应用程序 sudo ufw app list 可用应用程序： CUPS Nginx Full Nginx HTTP Nginx HTTPS OpenSSH Samba #查询具体应用查询的端口和协议 sudo ufw app info \"OpenSSH\" 配置: OpenSSH 标题：Secure shell server, an rshd replacement 描述： OpenSSH is a free implementation of the Secure Shell protocol. 端口: 22/tcp "},"ufw/lian.html":{"url":"ufw/lian.html","title":"链","keywords":"","body":"什么是链 当客户端访问服务器的web服务时，客户端发送报文到网卡，而tcp/ip协议栈是属于内核的一部分，所以，客户端的信息会通过内核的TCP协议传输到用户空间中的web服务中，而此时，客户端报文的目标终点为web服务所监听的套接字（IP：Port）上，当web服务需要响应客户端请求时，web服务发出的响应报文的目标终点则为客户端，这个时候，web服务所监听的IP与端口反而变成了原点，我们说过，netfilter才是真正的防火墙，它是内核的一部分，所以，如果我们想要防火墙能够达到\"防火\"的目的，则需要在内核中设置关卡，所有进出的报文都要通过这些关卡，经过检查后，符合放行条件的才能放行，符合阻拦条件的则需要被阻止，于是，就出现了input关卡和output关卡，而这些关卡在iptables中不被称为\"关卡\",而被称为\"链\" "},"yong-hu.html":{"url":"yong-hu.html","title":"用户","keywords":"","body":"在Linux系统中用UID 来标识用户,用户是能够登录并使用Linux的用户，用户组是用户的分组,用GID标识，分为3种用户 root 用户 : Linux系统的超级管理员 , 可以操作任何文件和命令 , 拥有最高的权限 , UID 为 0 ; 虚拟用户 : 这类用户不具有登录系统的能力 , 但是是系统运行不可缺少的用户 , 例如 bin , daemon , ftp , mail 等 , 这些用户是系统自身拥有的 , UID 为 1~499 ; 普通真实用户 : 这类用户可以登录系统 , 但是只能操作自己的家目录 , 可以自行添加 , UID 为 500~60000 ; graph TD; 用户-->ROOT; 用户-->虚拟用户; 用户-->普通用户; 用户 用户名以及环境信息存放在/etc/passwd文件中,每一行是一个用户信息以 “:”分割不同信息元素 #用户名称:密码:UID:GID:用户信息说明:home目录:默认的Shell root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin ... x密码,历史原因现在不用，密码是在 /etc/shadow文件中了,所以这里固定写x 密码 文件在/etc/shadow中，文件中每行是一个用户密码信息 , 每行用 : 分割形成9个列 ; 以下是各个列的说明 : root:!:17983:0:99999:7::: daemon:*:17737:0:99999:7::: bin:*:17737:0:99999:7::: sys:*:17737:0:99999:7::: sync:*:17737:0:99999:7::: 是用户名 , 用户名与 /etc/passwd 文件中的用户名对应 是密码 ; 密码是经过加密过的 , 系统不同计算规则不同 ; 是最后一次修改密码的日期 , 这里是 16982 , 意思是从 1970-01-01 那天之后 16982 天的日期 ; 是密码不可更新的天数 , 就是在设置密码后 , N天之内不能再次修改 , 防止频繁修改密码 , 如果是 0 , 就是随时可以修改密码 ; 是密码必须修改的天数 , 就是在设置密码后 , N天后必须修改密码 , 不然会变成过期状态 ;这里是一堆九 , 大约是 273 年 ; 是密码更改必须修改前多少天发出警告 , 这里是7天 ; 是密码过期后 N 天内还可以使用 , 不过过期后使用时会强制要去修改密码 , 如果在过期N天后还没有修改密码 , 那账号就不能再使用了 ; 是账号失效时间 , 指定日期之后 , 就无法再使用了 ; 是预留的列 , 暂时没用 ; 用户组 用户组信息保存在 /etc/group文件中 , 另外 /etc/gshadow文件存放的是用户组密码相关信息 root:x:0: daemon:x:1: bin:x:2: sys:x:3: adm:x:4:syslog,baihui 第一列为组名称第二列为组密码 , 组密码已经移动到 /etc/gshadow 文件中了 , 所以这个固定是 x ;第三列是 GID , 是用户组的唯一 ID , /etc/passwd 用户信息中的第四个字段就对应于这里的 GID ;第四列是这个用户组下的用户名称 , 多个用户名以逗号分割 , 如果想将某个用户添加到一个组中 , 就在目标组这一行 , 添加上这个用户名 ; /etc/gshadow用户组密码信息 root:*:: daemon:*:: bin:*:: sys:*:: adm:*::syslog,baihui 第一列为组名称 ;第二列是密码 ; 密码是经过加密过的 , 系统不同计算规则不同 ;第三列是用户组管理员的用户名 ;第四列是组内用户 , 多个用户用逗号分隔 ; useradd ##建立用户时的，建立用户时，读取/etc/login.defs文件内容确定规则 useradd -u 8888 branden ##指定用户uid useradd -g 21 branden ##指定用户初始组id “21用户组必须存在” useradd -G 21 branden ##指定用户符加组id “21用户组必须存在” useradd -c “hello“ branden ##指定用户的说明 useradd -d /home/lee branden ##指定用户的家目录 useradd -s /bin/sh branden ##指定用户默认shell （-s /sbin/nologin 不能登陆系统用户表达） groupadd ##建立用户组 groupadd -g 888 ##建立用户组并指定用户组的id groupdel ##删除用户组 例如：添加当前用户到指定的组 cat /etc/group|grep 'docker' docker:x:999: #把用户追加到某些组中，仅与-G选项一起使用 sudo usermod -aG docker ${USER} cat /etc/group|grep 'docker' docker:x:999:baihui "},"yong-hu/pu-tong-yong-hu.html":{"url":"yong-hu/pu-tong-yong-hu.html","title":"普通用户(500~60000)","keywords":"","body":""},"yong-hu/chao-ji-yong-623728-0.html":{"url":"yong-hu/chao-ji-yong-623728-0.html","title":"超级用户(0)","keywords":"","body":""},"te-shu-zhang-hao.html":{"url":"te-shu-zhang-hao.html","title":"虚拟用户(1~499)","keywords":"","body":" nobody（权限最小的默认账号） Windows系统在安装后会自动建立一些用户帐户，在Linux系统中同样有一些用户帐户是在系统安装后就有的，就像Windows系统中的内置帐户一样。 它们是用来完成特定任务的，比如nobody和ftp等，我们访问 www.111cn.net的网页程序时，官网的服务器就是让客户以 nobody 身份登录的(相当于Windows系统中的匿名帐户);我们匿名访问ftp时，会用到用户ftp或nobody。 首先，nobody是一个普通用户，非特权用户。 使用nobody用户名的'目的'是，使任何人都可以登录系统，但是其 UID 和 GID 不提供任何特权，即该uid和gid只能访问人人皆可读写的文件。 其次，许多系统中都按惯例地默认创建一个nobody，尽量'限制它的权限至最小'，当服务器向外服务时，可能会让client以nobody的身份登录。 nobody就是一个普通账户，因为默认登录shell是 '/sbin/nologin'，所以这个用户是无法直接登录系统的，也就是黑客很难通过漏洞连接到你的服务器来做破坏。此外这个用户的权限也给配置的很低。因此有比较高的安全性。一切都只给最低权限。这就是nobody存在的意义。 例如：搭建nfs服务的目录,该目录任何客服端都可以读写 #用户以及用户组 sudo chown nobody:nogroup ../wd nfs服务和共享目录的权限 www-data "},"te-shu-zhang-hao/zhi-xing-ming-ling.html":{"url":"te-shu-zhang-hao/zhi-xing-ming-ling.html","title":"执行命令","keywords":"","body":"使用虚拟账号执行命令: sudo -u www-data ./shell 权限以及路径,默认会到该账号下的目录中找到依赖的文件 "},"yong-hu/cao-zuo-yong-hu-xin-xi-ming-ling.html":{"url":"yong-hu/cao-zuo-yong-hu-xin-xi-ming-ling.html","title":"操作用户信息命令","keywords":"","body":"useradd 添加用户 userdel 删除用户 usermod 修改用户的属性 passwd 为用户设置密码 "},"ming-ling.html":{"url":"ming-ling.html","title":"命令","keywords":"","body":"命令区域归整 "},"watch.html":{"url":"watch.html","title":"watch","keywords":"","body":"watch 是一个周期性的执行程序，可以周期性的监测一个命令的运行结果。 参数 命令 - n 需要执行的命令 -d 会高亮显示变化的区域。而-d = cumulative 选项会把变动过的地方都会高亮显示出来 -t 会关闭watch 命令在顶部的时间间隔命令 #每隔一秒高亮显示网络链接数的变化情况 watch -n 1 -d netstat -ant #每隔一秒高亮显示打开80端口的进程情况 watch -n 1 -d 'lsof -i:80' 后面接的命令若带有管道符，需要加“将命令区域归整” "},"iftop.html":{"url":"iftop.html","title":"iftop","keywords":"","body":"iftop是类似于top的实时流量监控工具 iftop可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等，详细的将会在后面的使用参数中说明 界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。 中间的这两个左右箭头，表示的是流量的方向。 TX：发送流量 RX：接收流量 TOTAL：总流量 Cumm：运行iftop到目前时间的总流量 peak：流量峰值 rates：分别表示过去 2s 10s 40s 的平均流量 2、iftop相关参数 常用的参数 -i设定监测的网卡，如：# iftop -i eth1 -B 以bytes为单位显示流量(默认是bits)，如：# iftop -B -n使host信息默认直接都显示IP，如：# iftop -n -N使端口信息默认直接都显示端口号，如: # iftop -N -F显示特定网段的进出流量，如# iftop -F 10.10.1.0/24或# iftop -F 10.10.1.0/255.255.255.0 -h（display this message），帮助，显示参数信息 -p使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息; -b使流量图形条默认就显示; -f这个暂时还不太会用，过滤计算包用的; -P使host信息及端口信息默认就都显示; -m设置界面最上边的刻度的最大值，刻度分五个大段显示，例：# iftop -m 100M "},"lsof.html":{"url":"lsof.html","title":"lsof","keywords":"","body":"lsof是一个列出当前系统上进程打开文件的工具 #列出所有打开的文件: lsof #备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位 #看谁正在使用某个文件 lsof /filepath/file #递归查看某个目录的文件信息 lsof +D /filepath/filepath2/ # 使用了+D，对应目录下的所有子目录和文件都会被列出 #比使用+D选项，遍历查看某个目录的所有文件信息 的方法 lsof | grep ‘/filepath/filepath2/’ # 列出某个用户打开的文件信息 lsof -u username #-u 选项，u其实是user的缩写 # 列出某个程序所打开的文件信息 lsof -c mysql # -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成lsof | grep mysql,但是第一种方法明显比第二种方法要少打几个字符了 # 列出多个程序多打开的文件信息 lsof -c mysql -c apache # 列出某个用户以及某个程序所打开的文件信息 lsof -u test -c mysql #列出除了某个用户外的被打开的文件信息 lsof -u ^root #：^这个符号在用户名之前，将会把是root用户打开的进程不让显示 # 通过某个进程号显示该进行打开的文件 lsof -p 1 # 列出多个进程号对应的文件信息 lsof -p 123,456,789 # 列出除了某个进程号，其他进程号所打开的文件信息 lsof -p ^1 # 列出所有的网络连接 lsof -i #列出所有tcp 网络连接信息 lsof -i tcp # 列出所有udp网络连接信息 lsof -i udp # 列出谁在使用某个端口 lsof -i :3306 # 列出谁在使用某个特定的udp端口 lsof -i udp:55 #特定的tcp端口 lsof -i tcp:80 # 列出某个用户的所有活跃的网络端口 lsof -a -u test -i # 列出所有网络文件系统 lsof -N #域名socket文件 lsof -u #某个用户组所打开的文件信息 lsof -g 5555 # 根据文件描述列出对应的文件信息 lsof -d description(like 2) # 根据文件描述范围列出文件信息 lsof -d 2-3 "},"tar.html":{"url":"tar.html","title":"压缩和解压","keywords":"","body":"tar 主参数-c: 压缩-x: 解压-t：查看内容-r：向压缩归档文件末尾追加文件-u：更新原压缩包中的文件 -f: 使用档案名字,这个参数是最后一个参数，后面只能接档案名 附参数-z：有gzip属性的-j：有bz2属性的-Z：有compress属性的-v：显示所有过程-O：将文件解开到标准输出 主参数必须设置 #将当前目录中所有jpg文件打包成tar或者tar.gz tar -cvf jpg.tar *.jpg tar -czf jpg.tar.gz *.jpg #解压tar和tar.gz 包 tar -xvf file.tar tar -xzvf file.tar.gz unzip "},"usermod.html":{"url":"usermod.html","title":"usermod","keywords":"","body":"usermod 命令修改系统帐户文件来反映通过命令行指定的变化 "},"yuan-cheng-kao-bei.html":{"url":"yuan-cheng-kao-bei.html","title":"远程同步","keywords":"","body":""},"rsync.html":{"url":"rsync.html","title":"rsync","keywords":"","body":"rsync是可以实现增量备份的工具。配合任务计划，rsync能实现定时或间隔同步，配合inotify或sersync，可以实现触发式的实时同步 rsync同步过程中由两部分模式组成: 决定哪些文件需要同步的检查模式以及文件同步时的同步模式。 检查模式 按照指定规则来检查哪些文件需要被同步，例如哪些文件是明确被排除不传输的。默认情况下，rsync使用\"quick check\"算法快速检查源文件和目标文件的大小、mtime(修改时间)是否一致，如果不一致则需要传输。当然，也可以通过在rsync命令行中指定某些选项来改变quick check的检查模式，比如\"--size-only\"选项表示\"quick check\"将仅检查文件大小不同的文件作为待传输文件。rsync支持非常多的选项，其中检查模式的自定义性是非常有弹性的。 同步模式 是指在文件确定要被同步后，在同步过程发生之前要做哪些额外工作。例如上文所说的是否要先删除源主机上没有但目标主机上有的文件，是否要先备份已存在的目标文件，是否要追踪链接文件等额外操作。rsync也提供非常多的选项使得同步模式变得更具弹性。 rsync有三种工作方式： 本地文件系统上实现同步。命令行语法格式为上述\"Local\"段的格式 本地主机使用远程shell和远程主机通信。命令行语法格式为上述\"Access via remote shell\"段的格式 本地主机通过网络套接字连接远程主机上的rsync daemon。命令行语法格式为上述\"Access via rsync daemon\"段的格式 Local: rsync [OPTION...] 原... [目标] Access via remote shell: Pull: rsync [OPTION...] [USER@]HOST:原... [目标] Push: rsync [OPTION...] SRC... [USER@]HOST:目标 Access via rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST # rsync -a /etc /tmp # rsync -a /etc/ /tmp 源路径如果是一个目录的话，带上尾随斜线和不带尾随斜线是不一样的，不带尾随斜线表示的是整个目录包括目录本身，带上尾随斜线表示的是目录中的文件，不包括目录本身 "},"rsync/can-shu.html":{"url":"rsync/can-shu.html","title":"参数","keywords":"","body":"-v：显示rsync过程中详细信息。可以使用\"-vvvv\"获取更详细信息。 -P：显示文件传输的进度信息。(实际上\"-P\"=\"--partial --progress\"，其中的\"--progress\"才是显示进度信息的)。 -n --dry-run ：仅测试传输，而不实际传输。常和\"-vvvv\"配合使用来查看rsync是如何工作的。 -a --archive ：归档模式，表示递归传输并保持文件属性。等同于\"-rtopgDl\"。 -r --recursive：递归到目录中去。 -t --times：保持mtime属性。强烈建议任何时候都加上\"-t\"，否则目标文件mtime会设置为系统时间，导致下次更新 ：检查出mtime不同从而导致增量传输无效。 -o --owner：保持owner属性(属主)。 -g --group：保持group属性(属组)。 -p --perms：保持perms属性(权限，不包括特殊权限)。 -D ：是\"--device --specials\"选项的组合，即也拷贝设备文件和特殊文件。 -l --links：如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象。 -z ：传输时进行压缩提高效率。 -R --relative：使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性。用法见下文示例。 --size-only ：默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。 -u --update ：仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会影响删除行为。 -d --dirs ：以不递归的方式拷贝目录本身。默认递归时，如果源为\"dir1/file1\"，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1。 --max-size ：限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：\"--max-size=1.5m\") --min-size ：限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。 --exclude ：指定排除规则来排除不需要传输的文件。 --delete ：以SRC为主，对DEST进行同步。多则删之，少则补之。注意\"--delete\"是在接收端执行的，所以它是在 ：exclude/include规则生效之后才执行的。 -b --backup ：对目标上已存在的文件做一个备份，备份的文件名后默认使用\"~\"做后缀。 --backup-dir：指定备份文件的保存路径。不指定时默认和待备份文件保存在同一目录下。 -e ：指定所要使用的远程shell程序，默认为ssh。 --port ：连接daemon时使用的端口号，默认为873端口。 --password-file：daemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell认证的密码，而是rsync模块认证的密码。 -W --whole-file：rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。 --existing ：要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。 --ignore-existing：要求只更新目标端不存在的文件。和\"--existing\"结合使用有特殊功能，见下文示例。 --remove-source-files：要求删除源端已经成功传输的文件。 "},"scp.html":{"url":"scp.html","title":"scp","keywords":"","body":"scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 如：远程复制到本地 scp baihui@192.168.1.5://Volumes/SD/mysqls/3306/mysql_data.tar . "},"scp/can-shu.html":{"url":"scp/can-shu.html","title":"参数","keywords":"","body":"scp [参数] [原路径] [目标路径] -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条。 -r 递归复制整个目录。 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。 -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。 -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。 -l limit 限定用户所能使用的带宽，以Kbit/s为单位。 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式， -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 "},"dd.html":{"url":"dd.html","title":"dd","keywords":"","body":""},"tcpdump.html":{"url":"tcpdump.html","title":"tcpdump","keywords":"","body":"根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。 #监视指定ip所有数据包 sudo tcpdump -vv host 27.189.125.154 09:41:40.473486 IP (tos 0x0, ttl 64, id 57008, offset 0, flags [DF], proto TCP (6), length 634) y450.https > 27.189.125.154.49587: Flags [P.], cksum 0x5d74 (incorrect -> 0x8a67), seq 54865:55447, ack 2450, win 1452, options [nop,nop,TS val 4061261394 ecr 748861875], length 582 09:41:40.476553 IP (tos 0x0, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 52) 27.189.125.154.49587 > y450.https: Flags [.], cksum 0xe14d (correct), seq 2450, ack 55447, win 2038, options [nop,nop,TS val 748861931 ecr 4061261394], length 0 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。 "},"tcpdump/a.html":{"url":"tcpdump/a.html","title":"a","keywords":"","body":"linux下抓包工具tcpdump详解 本文转自：http://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html 简介 用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。 实用命令实例 默认启动 普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包。 监视指定网络接口的数据包 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。　 监视指定主机的数据包 打印所有进入或离开sundown的数据包. 也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 tcpdump host 210.27.48.1 打印helios 与 hot 或者与 ace 之间通信的数据包 tcpdump host helios and ( hot or ace ) 截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 ) 打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包. tcpdump ip host ace and not helios 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： tcpdump ip host 210.27.48.1 and ! 210.27.48.2 截获主机hostname发送的所有数据 tcpdump -i eth0 src host hostname 监视所有送到主机hostname的数据包 tcpdump -i eth0 dst host hostname 监视指定主机和端口的数据包 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令 tcpdump tcp port 23 and host 210.27.48.1 对本机的udp 123 端口进行监视 123 为ntp的服务端口 监视指定网络的数据包 打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为'Berkeley网络'的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包) 打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析) tcpdump 'gateway snup and (port ftp or ftp-data)' 打印所有源地址或目标地址是本地主机的IP数据包 (如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字) tcpdump ip and not net localnet 监视指定协议的数据包 打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字)) tcpdump 'tcp[tcpflags] & (tcp-syn|tcp-fin) != 0 and not src and dst net localnet' 打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习) tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)>2)) != 0)' (nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&0xf) 成字节数需要乘以4,　即左移2.　(tcp[12]&0xf0)>>4 表示tcp头的长度, 此域的单位也是32bit,　换算成比特数为 ((tcp[12]&0xf0) >> 4)　>2).　((ip[2:2] - ((ip[0]&0xf)>2)) != 0　表示: 整个ip数据包的长度减去ip头的长度,再减去 tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的'Payload Length' 与 'tcp头的长度'的差值, 并且其中表达方式'ip[]'需换成'ip6[]'.) 打印长度超过576字节, 并且网关地址是snup的IP数据包 tcpdump 'gateway snup and ip[2:2] > 576' 打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报 tcpdump 'ether[0] & 1 = 0 and ip[16] >= 224' 打印除'echo request'或者'echo reply'类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 . (nt: 'echo reuqest' 与 'echo reply' 这两种类型的ICMP数据包通常由ping程序产生)) tcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply' tcpdump 与wireshark Wireshark(以前是ethereal)是Windows下非常简单易用的抓包工具。但在Linux下很难找到一个好用的图形化抓包工具。 还好有Tcpdump。我们可以用Tcpdump + Wireshark 的完美组合实现：在 Linux 里抓包，然后在Windows 里分析包。 tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap (1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型 (2)-i eth1 : 只抓经过接口eth1的包 (3)-t : 不显示时间戳 (4)-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包 (5)-c 100 : 只抓取100个数据包 (6)dst port ! 22 : 不抓取目标端口是22的数据包 (7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24 (8)-w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析 使用tcpdump抓取HTTP包 tcpdump -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854 0x4745 为\"GET\"前两个字母\"GE\",0x4854 为\"HTTP\"前两个字母\"HT\"。 tcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序(如Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。 输出信息含义 首先我们注意一下，基本上tcpdump总的的输出格式为：系统时间 来源主机.端口 > 目标主机.端口 数据包参数 tcpdump 的输出格式与协议有关.以下简要描述了大部分常用的格式及相关例子. 链路层头 对于FDDI网络, '-e' 使tcpdump打印出指定数据包的'frame control' 域, 源和目的地址, 以及包的长度.(frame control域 控制对包中其他域的解析). 一般的包(比如那些IP datagrams)都是带有'async'(异步标志)的数据包，并且有取值0到7的优先级; 比如 'async4'就代表此包为异步数据包，并且优先级别为4. 通常认为,这些包们会内含一个 LLC包(逻辑链路控制包); 这时,如果此包 不是一个ISO datagram或所谓的SNAP包，其LLC头部将会被打印(nt:应该是指此包内含的 LLC包的包头). 对于Token Ring网络(令牌环网络), '-e' 使tcpdump打印出指定数据包的'frame control'和'access control'域, 以及源和目的地址, 外加包的长度. 与FDDI网络类似, 此数据包通常内含LLC数据包. 不管 是否有'-e'选项.对于此网络上的'source-routed'类型数据包(nt: 意译为:源地址被追踪的数据包,具体含义未知,需补充), 其包的源路由信息总会被打印. 对于802.11网络(WLAN,即wireless local area network), '-e' 使tcpdump打印出指定数据包的'frame control域, 包头中包含的所有地址, 以及包的长度.与FDDI网络类似, 此数据包通常内含LLC数据包. (注意: 以下的描述会假设你熟悉SLIP压缩算法 (nt:SLIP为Serial Line Internet Protocol.), 这个算法可以在 RFC-1144中找到相关的蛛丝马迹.) 对于SLIP网络(nt:SLIP links, 可理解为一个网络, 即通过串行线路建立的连接, 而一个简单的连接也可看成一个网络), 数据包的'direction indicator'('方向指示标志')(\"I\"表示入, \"O\"表示出), 类型以及压缩信息将会被打印. 包类型会被首先打印. 类型分为ip, utcp以及ctcp(nt:未知, 需补充). 对于ip包,连接信息将不被打印(nt:SLIP连接上,ip包的连接信息可能无用或没有定义. reconfirm).对于TCP数据包, 连接标识紧接着类型表示被打印. 如果此包被压缩, 其被编码过的头部将被打印. 此时对于特殊的压缩包,会如下显示: S+n 或者 SA+n, 其中n代表包的(顺序号或(顺序号和应答号))增加或减少的数目(nt | rt:S,SA拗口, 需再译). 对于非特殊的压缩包,0个或更多的'改变'将会被打印.'改变'被打印时格式如下: '标志'+/-/=n 包数据的长度 压缩的头部长度. 其中'标志'可以取以下值: U(代表紧急指针), W(指缓冲窗口), A(应答), S(序列号), I(包ID),而增量表达'=n'表示被赋予新的值, +/-表示增加或减少. 比如, 以下显示了对一个外发压缩TCP数据包的打印, 这个数据包隐含一个连接标识(connection identifier); 应答号增加了6, 顺序号增加了49, 包ID号增加了6; 包数据长度为3字节(octect), 压缩头部为6字节.(nt:如此看来这应该不是一个特殊的压缩数据包). ARP/RARP 数据包 tcpdump对Arp/rarp包的输出信息中会包含请求类型及该请求对应的参数. 显示格式简洁明了. 以下是从主机rtsg到主机csam的'rlogin' (远程登录)过程开始阶段的数据包样例: arp who-has csam tell rtsg arp reply csam is-at CSAM 第一行表示:rtsg发送了一个arp数据包(nt:向全网段发送,arp数据包）以询问csam的以太网地址 Csam（nt:可从下文看出来, 是Csam）以她自己的以太网地址做了回应(在这个例子中, 以太网地址以大写的名字标识, 而internet 地址(即ip地址)以全部的小写名字标识). 如果使用tcpdump -n, 可以清晰看到以太网以及ip地址而不是名字标识: arp who-has 128.3.254.6 tell 128.3.254.68 arp reply 128.3.254.6 is-at 02:07:01:00:01:c4 如果我们使用tcpdump -e, 则可以清晰的看到第一个数据包是全网广播的, 而第二个数据包是点对点的: RTSG Broadcast 0806 64: arp who-has csam tell rtsg CSAM RTSG 0806 64: arp reply csam is-at CSAM 第一个数据包表明:以arp包的源以太地址是RTSG, 目标地址是全以太网段, type域的值为16进制0806(表示ETHER_ARP(nt:arp包的类型标识)), 包的总长度为64字节. TCP 数据包 (注意:以下将会假定你对 RFC-793所描述的TCP熟悉. 如果不熟, 以下描述以及tcpdump程序可能对你帮助不大.(nt:警告可忽略, 只需继续看, 不熟悉的地方可回头再看.). 通常tcpdump对tcp数据包的显示格式如下: src > dst: flags data-seqno ack window urgent options src 和 dst 是源和目的IP地址以及相应的端口. flags 标志由S(SYN), F(FIN), P(PUSH, R(RST), W(ECN CWT(nt | rep:未知, 需补充))或者 E(ECN-Echo(nt | rep:未知,　需补充))组成, 单独一个'.'表示没有flags标识. 数据段顺序号(Data-seqno)描述了此包中数据所对应序列号空间中的一个位置(nt:整个数据被分段, 每段有一个顺序号, 所有的顺序号构成一个序列号空间)(可参考以下例子). Ack 描述的是同一个连接,同一个方向,下一个本端应该接收的 (对方应该发送的)数据片段的顺序号. Window是本端可用的数据接收缓冲区的大小(也是对方发送数据时需根据这个大小来组织数据). Urg(urgent) 表示数据包中有紧急的数据. options 描述了tcp的一些选项, 这些选项都用尖括号来表示(如 ). src, dst 和 flags 这三个域总是会被显示. 其他域的显示与否依赖于tcp协议头里的信息. 这是一个从trsg到csam的一个rlogin应用登录的开始阶段. rtsg.1023 > csam.login: S 768512:768512(0) win 4096 csam.login > rtsg.1023: S 947648:947648(0) ack 768513 win 4096 rtsg.1023 > csam.login: . ack 1 win 4096 rtsg.1023 > csam.login: P 1:2(1) ack 1 win 4096 csam.login > rtsg.1023: . ack 2 win 4096 rtsg.1023 > csam.login: P 2:21(19) ack 1 win 4096 csam.login > rtsg.1023: P 1:2(1) ack 21 win 4077 csam.login > rtsg.1023: P 2:3(1) ack 21 win 4077 urg 1 csam.login > rtsg.1023: P 3:4(1) ack 21 win 4077 urg 1 第一行表示有一个数据包从rtsg主机的tcp端口1023发送到了csam主机的tcp端口login上(nt:udp协议的端口和tcp协议的端 口是分别的两个空间, 虽然取值范围一致). S表示设置了SYN标志. 包的顺序号是768512, 并且没有包含数据.(表示格式 为:'first:last(nbytes)', 其含义是'此包中数据的顺序号从first开始直到last结束，不包括last. 并且总共包含nbytes的 用户数据'.) 没有捎带应答(nt:从下文来看，第二行才是有捎带应答的数据包), 可用的接受窗口的大小为4096bytes, 并且请求端(rtsg) 的最大可接受的数据段大小是1024字节(nt:这个信息作为请求发向应答端csam, 以便双方进一步的协商). Csam 向rtsg 回复了基本相同的SYN数据包, 其区别只是多了一个' piggy-backed ack'(nt:捎带回的ack应答, 针对rtsg的SYN数据包). rtsg 同样针对csam的SYN数据包回复了一ACK数据包作为应答. '.'的含义就是此包中没有标志被设置. 由于此应答包中不含有数据, 所以 包中也没有数据段序列号. 提醒! 此ACK数据包的顺序号只是一个小整数1. 有如下解释:tcpdump对于一个tcp连接上的会话, 只打印会话两端的 初始数据包的序列号,其后相应数据包只打印出与初始包序列号的差异.即初始序列号之后的序列号,　可被看作此会话上当前所传数据片段在整个 要传输的数据中的'相对字节'位置(nt:双方的第一个位置都是1, 即'相对字节'的开始编号).　'-Ｓ'将覆盖这个功能,　 使数据包的原始顺序号被打印出来. 第六行的含义为:rtsg 向 csam发送了19字节的数据(字节的编号为2到20，传送方向为rtsg到csam). 包中设置了PUSH标志. 在第7行, csam 喊到， 她已经从rtsg中收到了21以下的字节, 但不包括21编号的字节. 这些字节存放在csam的socket的接收缓冲中, 相应地, csam的接收缓冲窗口大小会减少19字节(nt:可以从第5行和第7行win属性值的变化看出来). csam在第7行这个包中也向rtsg发送了一个 字节. 在第8行和第9行, csam 继续向rtsg 分别发送了两个只包含一个字节的数据包, 并且这个数据包带PUSH标志. 如果所抓到的tcp包(nt:即这里的snapshot)太小了，以至tcpdump无法完整得到其头部数据, 这时, tcpdump会尽量解析这个不完整的头, 并把剩下不能解析的部分显示为'[|tcp]'. 如果头部含有虚假的属性信息(比如其长度属性其实比头部实际长度长或短), tcpdump会为该头部 显示'[bad opt]'. 如果头部的长度告诉我们某些选项(nt | rt:从下文来看， 指tcp包的头部中针对ip包的一些选项, 回头再翻)会在此包中, 而真正的IP(数据包的长度又不够容纳这些选项, tcpdump会显示'[bad hdr length]'. 抓取带有特殊标志的的TCP包(如SYN-ACK标志, URG-ACK标志等). 在TCP的头部中, 有8比特(bit)用作控制位区域, 其取值为: CWR | ECE | URG | ACK | PSH | RST | SYN | FIN (nt | rt:从表达方式上可推断:这8个位是用或的方式来组合的, 可回头再翻) 现假设我们想要监控建立一个TCP连接整个过程中所产生的数据包. 可回忆如下:TCP使用3次握手协议来建立一个新的连接; 其与此三次握手 连接顺序对应，并带有相应TCP控制标志的数据包如下: 1) 连接发起方(nt:Caller)发送SYN标志的数据包 2) 接收方(nt:Recipient)用带有SYN和ACK标志的数据包进行回应 3) 发起方收到接收方回应后再发送带有ACK标志的数据包进行回应 0 15 31 | source port | destination port | | sequence number | | acknowledgment number | | HL | rsvd |C|E|U|A|P|R|S|F| window size | | TCP checksum | urgent pointer | 一个TCP头部,在不包含选项数据的情况下通常占用20个字节(nt | rt:options 理解为选项数据，需回译). 第一行包含0到3编号的字节, 第二行包含编号4-7的字节. 如果编号从0开始算, TCP控制标志位于13字节(nt:第四行左半部分). 0 7 15 23 31 HL rsvd C E U A P R S F window size ---------------- --------------- --------------- ---------------- 13th octet 让我们仔细看看编号13的字节: C E U A P R S F --------------- 7 5 3 0 这里有我们感兴趣的控制标志位. 从右往左这些位被依次编号为0到7, 从而 PSH位在3号, 而URG位在5号. 提醒一下自己, 我们只是要得到包含SYN标志的数据包. 让我们看看在一个包的包头中, 如果SYN位被设置, 到底 在13号字节发生了什么: C E U A P R S F 0 0 0 0 0 0 1 0 --------------- 7 6 5 4 3 2 1 0 在控制段的数据中, 只有比特1(bit number 1)被置位. 假设编号为13的字节是一个8位的无符号字符型,并且按照网络字节号排序(nt:对于一个字节来说，网络字节序等同于主机字节序), 其二进制值 如下所示: 00000010 并且其10进制值为: 02^7 + 02^6 + 02^5 + 02^4 + 02^3 + 02^2 + 12^1 + 02^0 = 2(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更 清楚些, 即把原来表达中的指数7 6 ... 0挪到了下面来表达) 接近目标了, 因为我们已经知道, 如果数据包头部中的SYN被置位, 那么头部中的第13个字节的值为2(nt: 按照网络序, 即大头方式, 最重要的字节 在前面(在前面,即该字节实际内存地址比较小, 最重要的字节,指数学表示中数的高位, 如356中的3) ). 表达为tcpdump能理解的关系式就是: tcp[13] 2 从而我们可以把此关系式当作tcpdump的过滤条件, 目标就是监控只含有SYN标志的数据包: tcpdump -i xl0 tcp[13] 2 (nt: xl0 指网络接口, 如eth0) 这个表达式是说\"让TCP数据包的第13个字节拥有值2吧\", 这也是我们想要的结果. 现在, 假设我们需要抓取带SYN标志的数据包, 而忽略它是否包含其他标志.(nt:只要带SYN就是我们想要的). 让我们来看看当一个含有 SYN-ACK的数据包(nt:SYN 和 ACK 标志都有), 来到时发生了什么: |C|E|U|A|P|R|S|F| |---------------| |0 0 0 1 0 0 1 0| |---------------| |7 6 5 4 3 2 1 0| 13号字节的1号和4号位被置位, 其二进制的值为: 00010010 转换成十进制就是: 02^7 + 02^6 + 02^5 + 12^4 + 02^3 + 02^2 + 12^1 + 02 = 18(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更 清楚些, 即把原来表达中的指数7 6 ... 0挪到了下面来表达) 现在, 却不能只用'tcp[13] 18'作为tcpdump的过滤表达式, 因为这将导致只选择含有SYN-ACK标志的数据包, 其他的都被丢弃. 提醒一下自己, 我们的目标是: 只要包的SYN标志被设置就行, 其他的标志我们不理会. 为了达到我们的目标, 我们需要把13号字节的二进制值与其他的一个数做AND操作(nt:逻辑与)来得到SYN比特位的值. 目标是:只要SYN 被设置 就行, 于是我们就把她与上13号字节的SYN值(nt: 00000010). 00010010 SYN-ACK 00000010 SYN AND 00000010 (we want SYN) AND 00000010 (we want SYN) = 00000010 = 00000010 我们可以发现, 不管包的ACK或其他标志是否被设置, 以上的AND操作都会给我们相同的值, 其10进制表达就是2(2进制表达就是00000010). 从而我们知道, 对于带有SYN标志的数据包, 以下的表达式的结果总是真(true): ( ( value of octet 13 ) AND ( 2 ) ) ( 2 ) (nt: value of octet 13, 即13号字节的值) 灵感随之而来, 我们于是得到了如下的tcpdump 的过滤表达式 tcpdump -i xl0 'tcp[13] & 2 2' 注意, 单引号或反斜杆(nt: 这里用的是单引号)不能省略, 这可以防止shell对&的解释或替换. UDP 数据包 UDP 数据包的显示格式，可通过rwho这个具体应用所产生的数据包来说明: actinide.who > broadcast.who: udp 84 其含义为:actinide主机上的端口who向broadcast主机上的端口who发送了一个udp数据包(nt: actinide和broadcast都是指Internet地址). 这个数据包承载的用户数据为84个字节. 一些UDP服务可从数据包的源或目的端口来识别，也可从所显示的更高层协议信息来识别. 比如, Domain Name service requests(DNS 请求, 在RFC-1034/1035中), 和Sun RPC calls to NFS(对NFS服务器所发起的远程调用(nt: 即Sun RPC)，在RFC-1050中有对远程调用的描述). UDP 名称服务请求 (注意:以下的描述假设你对Domain Service protoco(nt:在RFC-103中有所描述), 否则你会发现以下描述就是天书(nt:希腊文天书, 不必理会, 吓吓你的, 接着看就行)) 名称服务请求有如下的格式: src > dst: id op? flags qtype qclass name (len) (nt: 从下文来看, 格式应该是src > dst: id op flags qtype qclass? name (len)) 比如有一个实际显示为: h2opolo.1538 > helios.domain: 3+ A? ucbvax.berkeley.edu. (37) 主机h2opolo 向helios 上运行的名称服务器查询ucbvax.berkeley.edu 的地址记录(nt: qtype等于A). 此查询本身的id号为'3'. 符号 '+'意味着递归查询标志被设置(nt: dns服务器可向更高层dns服务器查询本服务器不包含的地址记录). 这个最终通过IP包发送的查询请求 数据长度为37字节, 其中不包括UDP和IP协议的头数据. 因为此查询操作为默认值(nt | rt: normal one的理解), op字段被省略. 如果op字段没被省略, 会被显示在'3' 和'+'之间. 同样, qclass也是默认值, C_IN, 从而也没被显示, 如果没被忽略, 她会被显示在'A'之后. 异常检查会在方括中显示出附加的域:　如果一个查询同时包含一个回应(nt: 可理解为, 对之前其他一个请求的回应), 并且此回应包含权威或附加记录段,　 ancount, nscout, arcount(nt: 具体字段含义需补充) 将被显示为'[na]', '[nn]', '[nau]', 其中n代表合适的计数. 如果包中以下 回应位(比如AA位, RA位, rcode位), 或者字节2或3中任何一个'必须为0'的位被置位(nt: 设置为1), '[b2&3]=x' 将被显示, 其中x表示 头部字节2与字节3进行与操作后的值. UDP 名称服务应答 对名称服务应答的数据包，tcpdump会有如下的显示格式 src > dst: id op rcode flags a/n/au type class data (len) 比如具体显示如下: helios.domain > h2opolo.1538: 3 3/3/7 A 128.32.137.3 (273) helios.domain > h2opolo.1537: 2 NXDomain* 0/1/0 (97) 第一行表示: helios 对h2opolo 所发送的3号查询请求回应了3条回答记录(nt | rt: answer records), 3条名称服务器记录, 以及7条附加的记录. 第一个回答记录(nt: 3个回答记录中的第一个)类型为A(nt: 表示地址), 其数据为internet地址128.32.137.3. 此回应UDP数据包, 包含273字节的数据(不包含UPD和IP的头部数据). op字段和rcode字段被忽略(nt: op的实际值为Query, rcode, 即 response code的实际值为NoError), 同样被忽略的字段还有class 字段(nt | rt: 其值为C_IN, 这也是A类型记录默认取值) 第二行表示: helios 对h2opolo 所发送的2号查询请求做了回应. 回应中, rcode编码为NXDomain(nt: 表示不存在的域)), 没有回答记录, 但包含一个名称服务器记录, 不包含权威服务器记录(nt | ck: 从上文来看, 此处的authority records 就是上文中对应的additional records). '*'表示权威服务器回答标志被设置(nt: 从而additional records就表示的是authority records). 由于没有回答记录, type, class, data字段都被忽略. flag字段还有可能出现其他一些字符, 比如'-'(nt: 表示可递归地查询, 即RA 标志没有被设置), '|'(nt: 表示被截断的消息, 即TC 标志 被置位). 如果应答(nt | ct: 可理解为, 包含名称服务应答的UDP数据包, tcpdump知道这类数据包该怎样解析其数据)的'question'段一个条 目(entry)都不包含(nt: 每个条目的含义, 需补充),'[nq]' 会被打印出来. 要注意的是:名称服务器的请求和应答数据量比较大, 而默认的68字节的抓取长度(nt: snaplen, 可理解为tcpdump的一个设置选项)可能不足以抓取 数据包的全部内容. 如果你真的需要仔细查看名称服务器的负载, 可以通过tcpdump 的-s 选项来扩大snaplen值. SMB/CIFS 解码 tcpdump 已可以对SMB/CIFS/NBT相关应用的数据包内容进行解码(nt: 分别为'Server Message Block Common', 'Internet File System' '在TCP/IP上实现的网络协议NETBIOS的简称'. 这几个服务通常使用UDP的137/138以及TCP的139端口). 原来的对IPX和NetBEUI SMB数据包的 解码能力依然可以被使用(nt: NetBEUI为NETBIOS的增强版本). tcpdump默认只按照最简约模式对相应数据包进行解码, 如果我们想要详尽的解码信息可以使用其-v 启动选现. 要注意的是, -v 会产生非常详细的信息, 比如对单一的一个SMB数据包, 将产生一屏幕或更多的信息, 所以此选项, 确有需要才使用. 关于SMB数据包格式的信息, 以及每个域的含义可以参看www.cifs.org 或者samba.org 镜像站点的pub/samba/specs/ 目录. linux 上的SMB 补丁 (nt | rt: patch)由 Andrew Tridgell (tridge@samba.org)提供. NFS 请求和回应 tcpdump对Sun NFS(网络文件系统)请求和回应的UDP数据包有如下格式的打印输出: src.xid > dst.nfs: len op args src.nfs > dst.xid: reply stat len op results 以下是一组具体的输出数据 sushi.6709 > wrl.nfs: 112 readlink fh 21,24/10.73165 wrl.nfs > sushi.6709: reply ok 40 readlink \"../var\" sushi.201b > wrl.nfs: 144 lookup fh 9,74/4096.6878 \"xcolors\" wrl.nfs > sushi.201b: reply ok 128 lookup fh 9,74/4134.3150 第一行输出表明: 主机sushi向主机wrl发送了一个'交换请求'(nt: transaction), 此请求的id为6709(注意, 主机名字后是交换 请求id号, 而不是源端口号). 此请求数据为112字节, 其中不包括UDP和IP头部的长度. 操作类型为readlink(nt: 即此操作为读符号链接操作), 操作参数为fh 21,24/10.73165(nt: 可按实际运行环境, 解析如下, fd 表示描述的为文件句柄, 21,24 表示此句柄所对应设 备的主/从设备号对, 10表示此句柄所对应的i节点编号(nt:每个文件都会在操作系统中对应一个i节点, 限于unix类系统中), 73165是一个编号(nt: 可理解为标识此请求的一个随机数, 具体含义需补充)). 第二行中, wrl 做了'ok'的回应, 并且在results 字段中返回了sushi想要读的符号连接的真实目录(nt: 即sushi要求读的符号连接其实是一个目录). 第三行表明: sushi 再次请求 wrl 在'fh 9,74/4096.6878'所描述的目录中查找'xcolors'文件. 需要注意的是, 每行所显示的数据含义依赖于其中op字段的 类型(nt: 不同op 所对应args 含义不相同), 其格式遵循NFS 协议, 追求简洁明了. 如果tcpdump 的-v选项(详细打印选项) 被设置, 附加的信息将被显示. 比如: sushi.1372a > wrl.nfs: 148 read fh 21,11/12.195 8192 bytes @ 24576 wrl.nfs > sushi.1372a: reply ok 1472 read REG 100664 ids 417/0 sz 29388 (-v 选项一般还会打印出IP头部的TTL, ID， length, 以及fragmentation 域, 但在此例中, 都略过了(nt: 可理解为,简洁起见, 做了删减)) 在第一行, sushi 请求wrl 从文件 21,11/12.195(nt: 格式在上面有描述)中, 自偏移24576字节处开始, 读取8192字节数据. Wrl 回应读取成功; 由于第二行只是回应请求的开头片段, 所以只包含1472字节(其他的数据将在接着的reply片段中到来, 但这些数据包不会再有NFS 头, 甚至UDP头信息也为空(nt: 源和目的应该要有), 这将导致这些片段不能满足过滤条件, 从而没有被打印). -v 选项除了显示文件数据信息, 还会显示 附加显示文件属性信息: file type(文件类型, ''REG'' 表示普通文件), file mode(文件存取模式, 8进制表示的), uid 和gid(nt: 文件属主和 组属主), file size (文件大小). 如果-v 标志被多次重复给出(nt: 如-vv)， tcpdump会显示更加详细的信息. 必须要注意的是, NFS 请求包中数据比较多, 如果tcpdump 的snaplen(nt: 抓取长度) 取太短将不能显示其详细信息. 可使用 '-s 192'来增加snaplen, 这可用以监测NFS应用的网络负载(nt: traffic). NFS 的回应包并不严格的紧随之前相应的请求包(nt: RPC operation). 从而, tcpdump 会跟踪最近收到的一系列请求包, 再通过其 交换序号(nt: transaction ID)与相应请求包相匹配. 这可能产生一个问题， 如果回应包来得太迟, 超出tcpdump 对相应请求包的跟踪范围, 该回应包将不能被分析. AFS 请求和回应 AFS(nt: Andrew 文件系统, Transarc , 未知, 需补充)请求和回应有如下的答应 src.sport > dst.dport: rx packet-type src.sport > dst.dport: rx packet-type service call call-name args src.sport > dst.dport: rx packet-type service reply call-name args elvis.7001 > pike.afsfs: rx data fs call rename old fid 536876964/1/1 \".newsrc.new\" new fid 536876964/1/1 \".newsrc\" pike.afsfs > elvis.7001: rx data fs reply rename 在第一行, 主机elvis 向pike 发送了一个RX数据包. 这是一个对于文件服务的请求数据包(nt: RX data packet, 发送数据包 , 可理解为发送包过去, 从而请求对方的服务), 这也是一个RPC 调用的开始(nt: RPC, remote procedure call). 此RPC 请求pike 执行rename(nt: 重命名) 操作, 并指定了相关的参数: 原目录描述符为536876964/1/1, 原文件名为 '.newsrc.new', 新目录描述符为536876964/1/1, 新文件名为 '.newsrc'. 主机pike 对此rename操作的RPC请求作了回应(回应表示rename操作成功, 因为回应的是包含数据内容的包而不是异常包). 一般来说, 所有的'AFS RPC'请求被显示时, 会被冠以一个名字(nt: 即decode, 解码), 这个名字往往就是RPC请求的操作名. 并且, 这些RPC请求的部分参数在显示时, 也会被冠以一个名字(nt | rt: 即decode, 解码, 一般来说也是取名也很直接, 比如, 一个interesting 参数, 显示的时候就会直接是'interesting', 含义拗口, 需再翻). 这种显示格式的设计初衷为'一看就懂', 但对于不熟悉AFS 和 RX 工作原理的人可能不是很 有用(nt: 还是不用管, 书面吓吓你的, 往下看就行). 如果 -v(详细)标志被重复给出(nt: 如-vv), tcpdump 会打印出确认包(nt: 可理解为, 与应答包有区别的包)以及附加头部信息 (nt: 可理解为, 所有包, 而不仅仅是确认包的附加头部信息), 比如, RX call ID(请求包中'请求调用'的ID), call number('请求调用'的编号), sequence number(nt: 包顺序号), serial number(nt | rt: 可理解为与包中数据相关的另一个顺信号, 具体含义需补充), 请求包的标识. (nt: 接下来一段为重复描述, 所以略去了), 此外确认包中的MTU协商信息也会被打印出来(nt: 确认包为相对于请求包的确认包, Maximum Transmission Unit, 最大传输单元). 如果 -v 选项被重复了三次(nt: 如-vvv), 那么AFS应用类型数据包的'安全索引'('security index')以及'服务索引'('service id')将会 被打印. 对于表示异常的数据包(nt: abort packet, 可理解为, 此包就是用来通知接受者某种异常已发生), tcpdump 会打印出错误号(error codes). 但对于Ubik beacon packets(nt: Ubik 灯塔指示包, Ubik可理解为特殊的通信协议, beacon packets, 灯塔数据包, 可理解为指明通信中 关键信息的一些数据包), 错误号不会被打印, 因为对于Ubik 协议, 异常数据包不是表示错误, 相反却是表示一种肯定应答(nt: 即, yes vote). AFS 请求数据量大, 参数也多, 所以要求tcpdump的 snaplen 比较大, 一般可通过启动tcpdump时设置选项'-s 256' 来增大snaplen, 以 监测AFS 应用通信负载. AFS 回应包并不显示标识RPC 属于何种远程调用. 从而, tcpdump 会跟踪最近一段时间内的请求包, 并通过call number(调用编号), service ID (服务索引) 来匹配收到的回应包. 如果回应包不是针对最近一段时间内的请求包, tcpdump将无法解析该包. KIP AppleTalk协议 (nt | rt: DDP in UDP可理解为, DDP, The AppleTalk Data Delivery Protocol, 相当于支持KIP AppleTalk协议栈的网络层协议, 而DDP 本身又是通过UDP来传输的, 即在UDP 上实现的用于其他网络的网络层，KIP AppleTalk是苹果公司开发的整套网络协议栈). AppleTalk DDP 数据包被封装在UDP数据包中, 其解封装(nt: 相当于解码)和相应信息的转储也遵循DDP 包规则. (nt:encapsulate, 封装, 相当于编码, de-encapsulate, 解封装, 相当于解码, dump, 转储, 通常就是指对其信息进行打印). /etc/atalk.names 文件中包含了AppleTalk 网络和节点的数字标识到名称的对应关系. 其文件格式通常如下所示: number name 1.254 ether 16.1 icsd-net 1.254.110 ace 头两行表示有两个AppleTalk 网络. 第三行给出了特定网络上的主机(一个主机会用3个字节来标识, 而一个网络的标识通常只有两个字节, 这也是两者标识的主要区别)(nt: 1.254.110 可理解为ether网络上的ace主机). 标识与其对应的名字之间必须要用空白分开. 除了以上内容, /etc/atalk.names中还包含空行以及注释行(以'#'开始的行). AppleTalk 完整网络地址将以如下格式显示: net.host.port 以下为一段具体显示: 144.1.209.2 > icsd-net.112.220 office.2 > icsd-net.112.220 jssmag.149.235 > icsd-net.2 (如果/etc/atalk.names 文件不存在, 或者没有相应AppleTalk 主机/网络的条目, 数据包的网络地址将以数字形式显示). 在第一行中, 网络144.1上的节点209通过2端口,向网络icsd-net上监听在220端口的112节点发送了一个NBP应用数据包 (nt | rt: NBP, name binding protocol, 名称绑定协议, 从数据来看, NBP服务器会在端口2提供此服务. 'DDP port 2' 可理解为'DDP 对应传输层的端口2', DDP本身没有端口的概念, 这点未确定, 需补充). 第二行与第一行类似, 只是源的全部地址可用'office'进行标识. 第三行表示: jssmag网络上的149节点通过235向icsd-net网络上的所有节点的2端口(NBP端口)发送了数据包.(需要注意的是, 在AppleTalk 网络中如果地址中没有节点, 则表示广播地址, 从而节点标识和网络标识最好在/etc/atalk.names有所区别. nt: 否则一个标识x.port 无法确定x是指一个网络上所有主机的port口还是指定主机x的port口). tcpdump 可解析NBP (名称绑定协议) and ATP (AppleTalk传输协议)数据包, 对于其他应用层的协议, 只会打印出相应协议名字( 如果此协议没有注册一个通用名字, 只会打印其协议号)以及数据包的大小. NBP 数据包会按照如下格式显示: icsd-net.112.220 > jssmag.2: nbp-lkup 190: \"=:LaserWriter@\" jssmag.209.2 > icsd-net.112.220: nbp-reply 190: \"RM1140:LaserWriter@\" 250 techpit.2 > icsd-net.112.220: nbp-reply 190: \"techpit:LaserWriter@*\" 186 第一行表示: 网络icsd-net 中的节点112 通过220端口向网络jssmag 中所有节点的端口2发送了对'LaserWriter'的名称查询请求(nt: 此处名称可理解为一个资源的名称, 比如打印机). 此查询请求的序列号为190. 第二行表示: 网络jssmag 中的节点209 通过2端口向icsd-net.112节点的端口220进行了回应: 我有'LaserWriter'资源, 其资源名称 为'RM1140', 并且在端口250上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号. 第三行也是对第一行请求的回应: 节点techpit 通过2端口向icsd-net.112节点的端口220进行了回应:我有'LaserWriter'资源, 其资源名称 为'techpit', 并且在端口186上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号. ATP 数据包的显示格式如下: jssmag.209.165 > helios.132: atp-req 12266 0xae030001 helios.132 > jssmag.209.165: atp-resp 12266:0 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp 12266:1 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp 12266:2 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp 12266:3 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp 12266:5 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp 12266:6 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp12266:7 (512) 0xae040000 jssmag.209.165 > helios.132: atp-req 12266 0xae030001 helios.132 > jssmag.209.165: atp-resp 12266:3 (512) 0xae040000 helios.132 > jssmag.209.165: atp-resp 12266:5 (512) 0xae040000 jssmag.209.165 > helios.132: atp-rel 12266 0xae030001 jssmag.209.133 > helios.132: atp-req 12267 0xae030002 第一行表示节点 Jssmag.209 向节点helios 发送了一个会话编号为12266的请求包, 请求helios 回应8个数据包(这8个数据包的顺序号为0-7(nt: 顺序号与会话编号不同, 后者为一次完整传输的编号, 前者为该传输中每个数据包的编号. transaction, 会话, 通常也被叫做传输)). 行尾的16进制数字表示 该请求包中'userdata'域的值(nt: 从下文来看, 这并没有把所有用户数据都打印出来 ). Helios 回应了8个512字节的数据包. 跟在会话编号(nt: 12266)后的数字表示该数据包在该会话中的顺序号. 括号中的数字表示该数据包中数据的大小, 这不包括atp 的头部. 在顺序号为7数据包(第8行)外带了一个'*'号, 表示该数据包的EOM 标志被设置了.(nt: EOM, End Of Media, 可理解为, 表示一次会话的数据回应完毕). 接下来的第9行表示, Jssmag.209 又向helios 提出了请求: 顺序号为3以及5的数据包请重新传送. Helios 收到这个 请求后重新发送了这个两个数据包, jssmag.209 再次收到这两个数据包之后, 主动结束(release)了此会话. 在最后一行, jssmag.209 向helios 发送了开始下一次会话的请求包. 请求包中的'*'表示该包的XO 标志没有被设置. (nt: XO, exactly once, 可理解为在该会话中, 数据包在接受方只被精确地处理一次, 就算对方重复传送了该数据包, 接收方也只会处理一次, 这需要用到特别设计的数据包接收和处理机制). IP 数据包破碎 (nt: 指把一个IP数据包分成多个IP数据包) 碎片IP数据包(nt: 即一个大的IP数据包破碎后生成的小IP数据包)有如下两种显示格式. (frag id:size@offset+) (frag id:size@offset) (第一种格式表示, 此碎片之后还有后续碎片. 第二种格式表示, 此碎片为最后一个碎片.) id 表示破碎编号(nt: 从下文来看, 会为每个要破碎的大IP包分配一个破碎编号, 以便区分每个小碎片是否由同一数据包破碎而来). size 表示此碎片的大小 , 不包含碎片头部数据. offset表示此碎片所含数据在原始整个IP包中的偏移((nt: 从下文来看, 一个IP数据包是作为一个整体被破碎的, 包括头和数据, 而不只是数据被分割). 每个碎片都会使tcpdump产生相应的输出打印. 第一个碎片包含了高层协议的头数据(nt:从下文来看, 被破碎IP数据包中相应tcp头以及 IP头都放在了第一个碎片中 ), 从而tcpdump会针对第一个碎片显示这些信息, 并接着显示此碎片本身的信息. 其后的一些碎片并不包含 高层协议头信息, 从而只会在显示源和目的之后显示碎片本身的信息. 以下有一个例子: 这是一个从arizona.edu 到lbl-rtsg.arpa 途经CSNET网络(nt: CSNET connection 可理解为建立在CSNET 网络上的连接)的ftp应用通信片段: arizona.ftp-data > rtsg.1170: . 1024:1332(308) ack 1 win 4096 (frag 595a:328@0+) arizona > rtsg: (frag 595a:204@328) rtsg.1170 > arizona.ftp-data: . ack 1536 win 2560 有几点值得注意: 第一, 第二行的打印中, 地址后面没有端口号. 这是因为TCP协议信息都放到了第一个碎片中, 当显示第二个碎片时, 我们无法知道此碎片所对应TCP包的顺序号. 第二, 从第一行的信息中, 可以发现arizona需要向rtsg发送308字节的用户数据, 而事实是, 相应IP包经破碎后会总共产生512字节 数据(第一个碎片包含308字节的数据, 第二个碎片包含204个字节的数据, 这超过了308字节). 如果你在查找数据包的顺序号空间中的 一些空洞(nt: hole,空洞, 指数据包之间的顺序号没有上下衔接上), 512这个数据就足够使你迷茫一阵(nt: 其实只要关注308就行, 不必关注破碎后的数据总量). 一个数据包(nt | rt: 指IP数据包)如果带有非IP破碎标志, 则显示时会在最后显示'(DF)'.(nt: 意味着此IP包没有被破碎过). 时间戳 tcpdump的所有输出打印行中都会默认包含时间戳信息. 时间戳信息的显示格式如下 hh:mm:ss.frac　(nt: 小时:分钟:秒.(nt: frac未知, 需补充)) 此时间戳的精度与内核时间精度一致,　反映的是内核第一次看到对应数据包的时间(nt: saw, 即可对该数据包进行操作).　 而数据包从物理线路传递到内核的时间, 以及内核花费在此包上的中断处理时间都没有算进来. 命令使用 tcpdump采用命令行方式，它的命令格式为： tcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ] [ -C file_size ] [ -F file ] [ -i interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -Z user ] [ expression ] tcpdump的简单选项介绍 -A 以ASCII码方式显示每一个数据包(不会显示数据包中链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据(nt: 即Handy for capturing web pages). -c count tcpdump将在接受到count个数据包后退出. -C file-size (nt: 此选项用于配合-w file 选项使用) 该选项使得tcpdump 在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576) -d 以容易阅读的形式,在标准输出上打印出编排过的包匹配码, 随后tcpdump停止.(nt | rt: human readable, 容易阅读的,通常是指以ascii码来打印一些信息. compiled, 编排过的. packet-matching code, 包匹配码,含义未知, 需补充) -dd 以C语言的形式打印出包匹配码. -ddd 以十进制数的形式打印出包匹配码(会在包匹配码之前有一个附加的'count'前缀). -D 打印系统中所有tcpdump可以在其上进行抓包的网络接口. 每一个接口会打印出数字编号, 相应的接口名字, 以及可能的一个网络接口描述. 其中网络接口名字和数字编号可以用在tcpdump 的-i flag 选项(nt: 把名字或数字代替flag), 来指定要在其上抓包的网络接口. 此选项在不支持接口列表命令的系统上很有用(nt: 比如, Windows 系统, 或缺乏 ifconfig -a 的UNIX系统); 接口的数字编号在windows 2000 或其后的系统中很有用, 因为这些系统上的接口名字比较复杂, 而不易使用. 如果tcpdump编译时所依赖的libpcap库太老,-D 选项不会被支持, 因为其中缺乏 pcap_findalldevs()函数. -e 每行的打印输出中将包括数据包的数据链路层头部信息 -E spi@ipaddr algo:secret,... 可通过spi@ipaddr algo:secret 来解密IPsec ESP包(nt | rt:IPsec Encapsulating Security Payload,IPsec 封装安全负载, IPsec可理解为, 一整套对ip数据包的加密协议, ESP 为整个IP 数据包或其中上层协议部分被加密后的数据,前者的工作模式称为隧道模式; 后者的工作模式称为传输模式 . 工作原理, 另需补充). 需要注意的是, 在终端启动tcpdump 时, 可以为IPv4 ESP packets 设置密钥(secret）. 可用于加密的算法包括des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, 或者没有(none).默认的是des-cbc(nt: des, Data Encryption Standard, 数据加密标准, 加密算法未知, 另需补充).secret 为用于ESP 的密钥, 使用ASCII 字符串方式表达. 如果以 0x 开头, 该密钥将以16进制方式读入. 该选项中ESP 的定义遵循RFC2406, 而不是 RFC1827. 并且, 此选项只是用来调试的, 不推荐以真实密钥(secret)来使用该选项, 因为这样不安全: 在命令行中输入的secret 可以被其他人通过ps 等命令查看到. 除了以上的语法格式(nt: 指spi@ipaddr algo:secret), 还可以在后面添加一个语法输入文件名字供tcpdump 使用(nt：即把spi@ipaddr algo:secret,... 中...换成一个语法文件名). 此文件在接受到第一个ESP　包时会打开此文件, 所以最好此时把赋予tcpdump 的一些特权取消(nt: 可理解为, 这样防范之后, 当该文件为恶意编写时,不至于造成过大损害). -f 显示外部的IPv4 地址时(nt: foreign IPv4 addresses, 可理解为, 非本机ip地址), 采用数字方式而不是名字.(此选项是用来对付Sun公司的NIS服务器的缺陷(nt: NIS, 网络信息服务, tcpdump 显示外部地址的名字时会用到她提供的名称服务): 此NIS服务器在查询非本地地址名字时,常常会陷入无尽的查询循环). 由于对外部(foreign)IPv4地址的测试需要用到本地网络接口(nt: tcpdump 抓包时用到的接口)及其IPv4 地址和网络掩码. 如果此地址或网络掩码不可用, 或者此接口根本就没有设置相应网络地址和网络掩码(nt: linux 下的 'any' 网络接口就不需要设置地址和掩码, 不过此'any'接口可以收到系统中所有接口的数据包), 该选项不能正常工作. -F file 使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略. -i interface 指定tcpdump 需要监听的接口. 如果没有指定, tcpdump 会从系统接口列表中搜寻编号最小的已配置好的接口(不包括 loopback 接口).一但找到第一个符合条件的接口, 搜寻马上结束. 在采用2.2版本或之后版本内核的Linux 操作系统上, 'any' 这个虚拟网络接口可被用来接收所有网络接口上的数据包(nt: 这会包括目的是该网络接口的, 也包括目的不是该网络接口的). 需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包. 如果 -D 标志被指定, tcpdump会打印系统中的接口编号，而该编号就可用于此处的interface 参数. -l 对标准输出进行行缓冲(nt: 使标准输出设备遇到一个换行符就马上把这行的内容打印出来).在需要同时观察抓包打印以及保存抓包记录的时候很有用. 比如, 可通过以下命令组合来达到此目的: tcpdump -l | tee dat'' 或者tcpdump -l > dat & tail -f dat''.(nt: 前者使用tee来把tcpdump 的输出同时放到文件dat和标准输出中, 而后者通过重定向操作'>', 把tcpdump的输出放到dat 文件中, 同时通过tail把dat文件中的内容放到标准输出中) -L 列出指定网络接口所支持的数据链路层的类型后退出.(nt: 指定接口通过-i 来指定) -m module 通过module 指定的file 装载SMI MIB 模块(nt: SMI，Structure of Management Information, 管理信息结构MIB, Management Information Base, 管理信息库. 可理解为, 这两者用于SNMP(Simple Network Management Protoco)协议数据包的抓取. 具体SNMP 的工作原理未知, 另需补充). 此选项可多次使用, 从而为tcpdump 装载不同的MIB 模块. -M secret 如果TCP 数据包(TCP segments)有TCP-MD5选项(在RFC 2385有相关描述), 则为其摘要的验证指定一个公共的密钥secret. -n 不对地址(比如, 主机地址, 端口号)进行数字表示到名字表示的转换. -N 不打印出host 的域名部分. 比如, 如果设置了此选现, tcpdump 将会打印'nic' 而不是 'nic.ddn.mil'. -O 不启用进行包匹配时所用的优化代码. 当怀疑某些bug是由优化代码引起的, 此选项将很有用. -p 一般情况下, 把网络接口设置为非'混杂'模式. 但必须注意 , 在特殊情况下此网络接口还是会以'混杂'模式来工作； 从而, '-p' 的设与不设, 不能当做以下选现的代名词:'ether host {local-hw-add}' 或 'ether broadcast'(nt: 前者表示只匹配以太网地址为host 的包, 后者表示匹配以太网地址为广播地址的数据包). -q 快速(也许用'安静'更好?)打印输出. 即打印很少的协议相关信息, 从而输出行都比较简短. -R 设定tcpdump 对 ESP/AH 数据包的解析按照 RFC1825而不是RFC1829(nt: AH, 认证头, ESP， 安全负载封装, 这两者会用在IP包的安全传输机制中). 如果此选项被设置, tcpdump 将不会打印出'禁止中继'域(nt: relay prevention field). 另外,由于ESP/AH规范中没有规定ESP/AH数据包必须拥有协议版本号域,所以tcpdump不能从收到的ESP/AH数据包中推导出协议版本号. -r file 从文件file 中读取包数据. 如果file 字段为 '-' 符号, 则tcpdump 会从标准输入中读取包数据. -S 打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号.(nt: 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距,比如, 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2. 而如果此时-S 选项被设置, 对于后来接收到的第2个, 第3个数据包会打印出其绝对顺序号:232324, 232325). -s snaplen 设置tcpdump的数据包抓取长度为snaplen, 如果不设置默认将会是68字节(而支持网络接口分接头(nt: NIT, 上文已有描述,可搜索'网络接口分接头'关键字找到那里)的SunOS系列操作系统中默认的也是最小值是96).68字节对于IP, ICMP(nt: Internet Control Message Protocol,因特网控制报文协议), TCP 以及 UDP 协议的报文已足够, 但对于名称服务(nt: 可理解为dns, nis等服务), NFS服务相关的数据包会产生包截短. 如果产生包截短这种情况, tcpdump的相应打印输出行中会出现''[|proto]''的标志（proto 实际会显示为被截短的数据包的相关协议层次). 需要注意的是, 采用长的抓取长度(nt: snaplen比较大), 会增加包的处理时间, 并且会减少tcpdump 可缓存的数据包的数量， 从而会导致数据包的丢失. 所以, 在能抓取我们想要的包的前提下, 抓取长度越小越好.把snaplen 设置为0 意味着让tcpdump自动选择合适的长度来抓取数据包. -T type 强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包. 目前已知的type 可取的协议为: aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用), cnfp (Cisco NetFlow protocol), rpc(Remote Procedure Call), rtp (Real-Time Applications protocol), rtcp (Real-Time Applications con-trol protocol), snmp (Simple Network Management Protocol), tftp (Trivial File Transfer Protocol, 碎文件协议), vat (Visual Audio Tool, 可用于在internet 上进行电 视电话会议的应用层协议), 以及wb (distributed White Board, 可用于网络会议的应用层协议). -t 在每行输出中不打印时间戳 -tt 不对每行输出的时间进行格式处理(nt: 这种格式一眼可能看不出其含义, 如时间戳打印成1261798315) -ttt tcpdump 输出时, 每两行打印之间会延迟一个段时间(以毫秒为单位) -tttt 在每行打印的时间戳之前添加日期的打印 -u 打印出未加密的NFS 句柄(nt: handle可理解为NFS 中使用的文件句柄, 这将包括文件夹和文件夹中的文件) -U 使得当tcpdump在使用-w 选项时, 其文件写入与包的保存同步.(nt: 即, 当每个数据包被保存时, 它将及时被写入文件中,而不是等文件的输出缓冲已满时才真正写入此文件) -U 标志在老版本的libcap库(nt: tcpdump 所依赖的报文捕获库)上不起作用, 因为其中缺乏pcap_cump_flush()函数. -v 当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和. -vv 产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码. -vvv 产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面, 其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充). -w 把包数据直接写入文件而不进行分析和打印输出. 这些包数据可在随后通过-r 选项来重新读入并进行分析和打印. -W filecount 此选项与-C 选项配合使用, 这将限制可打开的文件数目, 并且当文件数据超过这里设置的限制时, 依次循环替代之前的文件, 这相当于一个拥有filecount 个文件的文件缓冲池. 同时, 该选项会使得每个文件名的开头会出现足够多并用来占位的0, 这可以方便这些文件被正确的排序. -x 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据(但不包括连接层的头部).总共打印的数据大小不会超过整个数据包的大小与snaplen 中的最小值. 必须要注意的是, 如果高层协议数据没有snaplen 这么长,并且数据链路层(比如, Ethernet层)有填充数据, 则这些填充数据也会被打印.(nt: so for link layers that pad, 未能衔接理解和翻译, 需补充 ) -xx tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据, 其中包括数据链路层的头部. -X 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据(但不包括连接层的头部).这对于分析一些新协议的数据包很方便. -XX 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据, 其中包括数据链路层的头部.这对于分析一些新协议的数据包很方便. -y datalinktype 设置tcpdump 只捕获数据链路层协议类型是datalinktype的数据包 -Z user 使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID(nt: tcpdump 此处可理解为tcpdump 运行之后对应的进程) 此选项也可在编译的时候被设置为默认打开.(nt: 此时user 的取值未知, 需补充) tcpdump条件表达式 该表达式用于决定哪些数据包将被打印. 如果不给定条件表达式, 网络上所有被捕获的包都会被打印,否则, 只有满足条件表达式的数据包被打印.(nt: all packets, 可理解为, 所有被指定接口捕获的数据包). 表达式由一个或多个'表达元'组成(nt: primitive, 表达元, 可理解为组成表达式的基本元素). 一个表达元通常由一个或多个修饰符(qualifiers)后跟一个名字或数字表示的id组成(nt: 即, 'qualifiers id').有三种不同类型的修饰符:type, dir以及 proto. type 修饰符指定id 所代表的对象类型, id可以是名字也可以是数字. 可选的对象类型有: host, net, port 以及portrange(nt: host 表明id表示主机, net 表明id是网络, port 表明id是端而portrange 表明id 是一个端口范围). 如, 'host foo', 'net 128.3', 'port 20', 'portrange 6000-6008'(nt: 分别表示主机 foo,网络 128.3, 端口 20, 端口范围 6000-6008). 如果不指定type 修饰符, id默认的修饰符为host. dir 修饰符描述id 所对应的传输方向, 即发往id 还是从id 接收（nt: 而id 到底指什么需要看其前面的type 修饰符）.可取的方向为: src, dst, src 或 dst, src并且dst.(nt:分别表示, id是传输源, id是传输目的, id是传输源或者传输目的, id是传输源并且是传输目的). 例如, 'src foo','dst net 128.3', 'src or dst port ftp-data'.(nt: 分别表示符合条件的数据包中, 源主机是foo, 目的网络是128.3, 源或目的端口为 ftp-data).如果不指定dir修饰符, id 默认的修饰符为src 或 dst.对于链路层的协议,比如SLIP(nt: Serial Line InternetProtocol, 串联线路网际网络协议), 以及linux下指定'any' 设备, 并指定'cooked'(nt | rt: cooked 含义未知, 需补充) 抓取类型, 或其他设备类型,可以用'inbound' 和 'outbount' 修饰符来指定想要的传输方向. proto 修饰符描述id 所属的协议. 可选的协议有: ether, fddi, tr, wlan, ip, ip6, arp, rarp, decnet, tcp以及 upd.(nt | rt: ether, fddi, tr, 具体含义未知, 需补充. 可理解为物理以太网传输协议, 光纤分布数据网传输协议,以及用于路由跟踪的协议. wlan, 无线局域网协议; ip,ip6 即通常的TCP/IP协议栈中所使用的ipv4以及ipv6网络层协议;arp, rarp 即地址解析协议,反向地址解析协议; decnet, Digital Equipment Corporation开发的, 最早用于PDP-11 机器互联的网络协议; tcp and udp, 即通常TCP/IP协议栈中的两个传输层协议). 例如, `ether src foo', `arp net 128.3', `tcp port 21', `udp portrange 7000-7009'分别表示 '从以太网地址foo 来的数据包','发往或来自128.3网络的arp协议数据包', '发送或接收端口为21的tcp协议数据包', '发送或接收端口范围为7000-7009的udp协议数据包'. 如果不指定proto 修饰符, 则默认为与相应type匹配的修饰符. 例如, 'src foo' 含义是 '(ip or arp or rarp) src foo' (nt: 即, 来自主机foo的ip/arp/rarp协议数据包, 默认type为host),`net bar' 含义是`(ip or arp or rarp) net bar'(nt: 即, 来自或发往bar网络的ip/arp/rarp协议数据包),`port 53' 含义是 `(tcp or udp) port 53'(nt: 即, 发送或接收端口为53的tcp/udp协议数据包).(nt: 由于tcpdump 直接通过数据链路层的 BSD 数据包过滤器或 DLPI(datalink provider interface, 数据链层提供者接口)来直接获得网络数据包, 其可抓取的数据包可涵盖上层的各种协议, 包括arp, rarp, icmp(因特网控制报文协议),ip, ip6, tcp, udp, sctp(流控制传输协议). 对于修饰符后跟id 的格式,可理解为, type id 是对包最基本的过滤条件: 即对包相关的主机, 网络, 端口的限制;dir 表示对包的传送方向的限制; proto表示对包相关的协议限制) 'fddi'(nt: Fiber Distributed Data Interface) 实际上与'ether' 含义一样: tcpdump 会把他们当作一种''指定网络接口上的数据链路层协议''. 如同ehter网(以太网), FDDI 的头部通常也会有源, 目的, 以及包类型, 从而可以像ether网数据包一样对这些域进行过滤. 此外, FDDI 头部还有其他的域, 但不能被放到表达式中用来过滤 同样, 'tr' 和 'wlan' 也和 'ether' 含义一致, 上一段对fddi 的描述同样适用于tr(Token Ring) 和wlan(802.11 wireless LAN)的头部. 对于802.11 协议数据包的头部, 目的域称为DA, 源域称为 SA;而其中的 BSSID, RA, TA 域(nt | rt: 具体含义需补充)不会被检测(nt: 不能被用于包过虑表达式中). 除以上所描述的表达元('primitive')， 还有其他形式的表达元, 并且与上述表达元格式不同. 比如: gateway, broadcast, less, greater以及算术表达式(nt: 其中每一个都算一种新的表达元). 下面将会对这些表达元进行说明. 表达元之间还可以通过关键字and, or 以及 not 进行连接, 从而可组成比较复杂的条件表达式. 比如,`host foo and not port ftp and not port ftp-data'(nt: 其过滤条件可理解为, 数据包的主机为foo,并且端口不是ftp(端口21) 和ftp-data(端口20, 常用端口和名字的对应可在linux 系统中的/etc/service 文件中找到)). 为了表示方便, 同样的修饰符可以被省略, 如'tcp dst port ftp or ftp-data or domain' 与以下的表达式含义相同'tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain'.(nt: 其过滤条件可理解为,包的协议为tcp, 目的端口为ftp 或 ftp-data 或 domain(端口53) ). 借助括号以及相应操作符,可把表达元组合在一起使用(由于括号是shell的特殊字符, 所以在shell脚本或终端中使用时必须对括号进行转义, 即'(' 与')'需要分别表达成'(' 与 ')'). 有效的操作符有: 否定操作 (!' 或not') 与操作(&&' 或and') 或操作(||' 或or') 否定操作符的优先级别最高. 与操作和或操作优先级别相同, 并且二者的结合顺序是从左到右. 要注意的是, 表达'与操作'时, 需要显式写出'and'操作符, 而不只是把前后表达元并列放置(nt: 二者中间的'and' 操作符不可省略). 如果一个标识符前没有关键字, 则表达式的解析过程中最近用过的关键字(往往也是从左往右距离标识符最近的关键字)将被使用.比如, not host vs and ace 是以下表达的精简: not host vs and host ace 而不是not (host vs or ace).(nt: 前两者表示, 所需数据包不是来自或发往host vs, 而是来自或发往ace.而后者表示数据包只要不是来自或发往vs或ac都符合要求) 整个条件表达式可以被当作一个单独的字符串参数也可以被当作空格分割的多个参数传入tcpdump, 后者更方便些. 通常, 如果表达式中包含元字符(nt: 如正则表达式中的'*', '.'以及shell中的'('等字符)， 最好还是使用单独字符串的方式传入. 这时,整个表达式需要被单引号括起来. 多参数的传入方式中, 所有参数最终还是被空格串联在一起, 作为一个字符串被解析. 附录:tcpdump的表达元 (nt: True 在以下的描述中含义为: 相应条件表达式中只含有以下所列的一个特定表达元, 此时表达式为真, 即条件得到满足) dst host host 如果IPv4/v6 数据包的目的域是host, 则与此对应的条件表达式为真.host 可以是一个ip地址, 也可以是一个主机名. src host host 如果IPv4/v6 数据包的源域是host, 则与此对应的条件表达式为真. host 可以是一个ip地址, 也可以是一个主机名. host host 如果IPv4/v6数据包的源或目的地址是 host, 则与此对应的条件表达式为真.以上的几个host 表达式之前可以添加以下关键字:ip, arp, rarp, 以及 ip6.比如: ip host host 也可以表达为: ether proto \\ip and host host(nt: 这种表达方式在下面有说明, 其中ip之前需要有\\来转义,因为ip 对tcpdump 来说已经是一个关键字了.) 如果host 是一个拥有多个IP 的主机, 那么任何一个地址都会用于包的匹配(nt: 即发向host 的数据包的目的地址可以是这几个IP中的任何一个, 从host 接收的数据包的源地址也可以是这几个IP中的任何一个). ether dst ehost 如果数据包(nt: 指tcpdump 可抓取的数据包, 包括ip 数据包, tcp数据包)的以太网目标地址是ehost,则与此对应的条件表达式为真. Ehost 可以是/etc/ethers 文件中的名字或一个数字地址(nt: 可通过 man ethers 看到对/etc/ethers 文件的描述, 样例中用的是数字地址) ether src ehost 如果数据包的以太网源地址是ehost, 则与此对应的条件表达式为真. ether host ehost 如果数据包的以太网源地址或目标地址是ehost, 则与此对应的条件表达式为真. gateway host 如果数据包的网关地址是host, 则与此对应的条件表达式为真. 需要注意的是, 这里的网关地址是指以太网地址, 而不是IP 地址(nt | rt: I.e., 例如, 可理解为'注意'.the Ethernet source or destination address, 以太网源和目标地址, 可理解为, 指代上句中的'网关地址' ).host 必须是名字而不是数字, 并且必须在机器的'主机名-ip地址'以及'主机名-以太地址'两大映射关系中 有其条目(前一映射关系可通过/etc/hosts文件, DNS 或 NIS得到, 而后一映射关系可通过/etc/ethers 文件得到. nt: /etc/ethers并不一定存在 , 可通过man ethers 看到其数据格式, 如何创建该文件, 未知,需补充).也就是说host 的含义是 ether host ehost 而不是 host host, 并且ehost必须是名字而不是数字. 目前, 该选项在支持IPv6地址格式的配置环境中不起作用(nt: configuration, 配置环境, 可理解为,通信双方的网络配置). dst net net 如果数据包的目标地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真. net 可以是从网络数据库文件/etc/networks 中的名字, 也可以是一个数字形式的网络编号. 一个数字IPv4 网络编号将以点分四元组(比如, 192.168.1.0), 或点分三元组(比如, 192.168.1 ), 或点分二元组(比如, 172.16), 或单一单元组(比如, 10)来表达; 对应于这四种情况的网络掩码分别是:四元组:255.255.255.255(这也意味着对net 的匹配如同对主机地址(host)的匹配:地址的四个部分都用到了),三元组:255.255.255.0, 二元组:255.255.0.0, 一元组:255.0.0.0. 对于IPv6 的地址格式, 网络编号必须全部写出来(8个部分必须全部写出来); 相应网络掩码为: ff:ff:ff:ff:ff:ff:ff:ff, 所以IPv6 的网络匹配是真正的'host'方式的匹配(nt | rt | rc:地址的8个部分都会用到,是否不属于网络的字节填写0, 需接下来补充), 但同时需要一个网络掩码长度参数来具体指定前面多少字节为网络掩码(nt: 可通过下面的net net/len 来指定) src net net 如果数据包的源地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真. net net 如果数据包的源或目的地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真. net net mask netmask 如果数据包的源或目的地址(IPv4或IPv6格式)的网络掩码与netmask 匹配, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt: 比如 src net net mask 255.255.255.0).该选项对于ipv6 网络地址无效. net net/len 如果数据包的源或目的地址(IPv4或IPv6格式)的网络编号字段的比特数与len相同, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt | rt | tt: src net net/24, 表示需要匹配源地址的网络编号有24位的数据包). dst port port 如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口为port, 则与此对应的条件表达式为真.port 可以是一个数字也可以是一个名字(相应名字可以在/etc/services 中找到该名字, 也可以通过man tcp 和man udp来得到相关描述信息 ). 如果使用名字, 则该名字对应的端口号和相应使用的协议都会被检查. 如果只是使用一个数字端口号,则只有相应端口号被检查(比如, dst port 513 将会使tcpdump抓取tcp协议的login 服务和udp协议的who 服务数据包, 而port domain 将会使tcpdump 抓取tcp协议的domain 服务数据包, 以及udp 协议的domain 数据包)(nt | rt: ambiguous name is used 不可理解, 需补充). src port port 如果数据包的源端口为port, 则与此对应的条件表达式为真. port port 如果数据包的源或目的端口为port, 则与此对应的条件表达式为真. dst portrange port1-port2 如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口属于port1到port2这个端口范围(包括port1, port2), 则与此对应的条件表达式为真. tcpdump 对port1 和port2 解析与对port 的解析一致(nt:在dst port port 选项的描述中有说明). src portrange port1-port2 如果数据包的源端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真. portrange port1-port2 如果数据包的源端口或目的端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真. 以上关于port 的选项都可以在其前面添加关键字:tcp 或者udp, 比如: tcp src port port 这将使tcpdump 只抓取源端口是port 的tcp数据包. less length 如果数据包的长度比length 小或等于length, 则与此对应的条件表达式为真. 这与'len greater length 如果数据包的长度比length 大或等于length, 则与此对应的条件表达式为真. 这与'len >= length' 的含义一致. ip proto protocol 如果数据包为ipv4数据包并且其协议类型为protocol, 则与此对应的条件表达式为真. Protocol 可以是一个数字也可以是名字, 比如:icmp6, igmp, igrp(nt: Interior Gateway Routing Protocol,内部网关路由协议), pim(Protocol Independent Multicast, 独立组播协议, 应用于组播路由器),ah, esp(nt: ah, 认证头, esp 安全负载封装, 这两者会用在IP包的安全传输机制中 ), vrrp(Virtual Router Redundancy Protocol, 虚拟路由器冗余协议), udp, or tcp. 由于tcp , udp 以及icmp是tcpdump 的关键字,所以在这些协议名字之前必须要用\\来进行转义(如果在C-shell 中需要用\\来进行转义). 注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来(nt: 实际上只会打印指定协议的一些头部信息, 比如可以用tcpdump -i eth0 'ip proto \\tcp and host 192.168.3.144', 则只打印主机192.168.3.144 发出或接收的数据包中tcp 协议头所包含的信息) ip6 proto protocol 如果数据包为ipv6数据包并且其协议类型为protocol, 则与此对应的条件表达式为真. 注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来 ip6 protochain protocol 如果数据包为ipv6数据包并且其协议链中包含类型为protocol协议头, 则与此对应的条件表达式为真. 比如, ip6 protochain 6 将匹配其协议头链中拥有TCP 协议头的IPv6数据包.此数据包的IPv6头和TCP头之间可能还会包含验证头, 路由头, 或者逐跳寻径选项头. 由此所触发的相应BPF(Berkeley Packets Filter, 可理解为, 在数据链路层提供数据包过滤的一种机制)代码比较繁琐, 并且BPF优化代码也未能照顾到此部分, 从而此选项所触发的包匹配可能会比较慢. ip protochain protocol 与ip6 protochain protocol 含义相同, 但这用在IPv4数据包. ether broadcast 如果数据包是以太网广播数据包, 则与此对应的条件表达式为真. ether 关键字是可选的. ip broadcast 如果数据包是IPv4广播数据包, 则与此对应的条件表达式为真. 这将使tcpdump 检查广播地址是否符合全0和全1的一些约定,并查找网络接口的网络掩码(网络接口为当时在其上抓包的网络接口). 如果抓包所在网络接口的网络掩码不合法, 或者此接口根本就没有设置相应网络地址和网络， 亦或是在linux下的'any'网络接口上抓包(此'any'接口可以收到系统中不止一个接口的数据包(nt: 实际上, 可理解为系统中所有可用的接口)),网络掩码的检查不能正常进行. ether multicast 如果数据包是一个以太网多点广播数据包(nt: 多点广播, 可理解为把消息同时传递给一组目的地址, 而不是网络中所有地址,后者为可称为广播(broadcast)), 则与此对应的条件表达式为真. 关键字ether 可以省略. 此选项的含义与以下条件表达式含义一致:`ether[0] & 1 != 0'(nt: 可理解为, 以太网数据包中第0个字节的最低位是1, 这意味这是一个多点广播数据包). ip multicast 如果数据包是ipv4多点广播数据包, 则与此对应的条件表达式为真. ip6 multicast 如果数据包是ipv6多点广播数据包, 则与此对应的条件表达式为真. ether proto protocol 如果数据包属于以下以太协议类型, 则与此对应的条件表达式为真. 协议(protocol)字段, 可以是数字或以下所列出了名字: ip, ip6, arp, rarp, atalk(AppleTalk网络协议), aarp(nt: AppleTalk Address Resolution Protocol, AppleTalk网络的地址解析协议), decnet(nt: 一个由DEC公司所提供的网络协议栈), sca(nt: 未知, 需补充), lat(Local Area Transport, 区域传输协议, 由DEC公司开发的以太网主机互联协议), mopdl, moprc, iso(nt: 未知, 需补充), stp(Spanning tree protocol, 生成树协议, 可用于防止网络中产生链接循环), ipx（nt: Internetwork Packet Exchange, Novell 网络中使用的网络层协议）, 或者 netbeui(nt: NetBIOS Extended User Interface，可理解为, 网络基本输入输出系统接口扩展). protocol字段可以是一个数字或以下协议名之一:ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat, mopdl, moprc, iso, stp, ipx, 或者netbeui. 必须要注意的是标识符也是关键字, 从而必须通过'\\'来进行转义. (SNAP：子网接入协议 （SubNetwork Access Protocol）) 在光纤分布式数据网络接口(其表达元形式可以是'fddi protocol arp'), 令牌环网(其表达元形式可以是'tr protocol arp'), 以及IEEE 802.11 无线局域网(其表达元形式可以是'wlan protocol arp')中, protocol 标识符来自802.2 逻辑链路控制层头, 在FDDI, Token Ring 或 802.1头中会包含此逻辑链路控制层头. 当以这些网络上的相应的协议标识为过滤条件时, tcpdump只是检查LLC头部中以0x000000为组成单元标识符(OUI, 0x000000 标识一个内部以太网)的一段'SNAP格式结构'中的protocol ID 域, 而不会管包中是否有一段OUI为0x000000的'SNAP格式 结构'(nt: SNAP, SubNetwork Access Protocol,子网接入协议 ). 以下例外: iso tcpdump 会检查LLC头部中的DSAP域(Destination service Access Point, 目标服务接入点)和 SSAP域(源服务接入点).(nt: iso 协议未知, 需补充) stp 以及 netbeui tcpdump 将会检查LLC 头部中的目标服务接入点(Destination service Access Point); atalk tcpdump 将会检查LLC 头部中以0x080007 为OUI标识的'SNAP格式结构', 并会检查AppleTalk etype域. (nt: AppleTalk etype 是否位于SNAP格式结构中, 未知, 需补充). 此外, 在以太网中, 对于ether proto protocol 选项, tcpdump 会为 protocol 所指定的协议检查 以太网类型域(the Ethernet type field), 但以下这些协议除外: iso, stp, and netbeui tcpdump 将会检查802.3 物理帧以及LLC 头(这两种检查与FDDI, TR, 802.11网络中的相应检查一致); (nt: 802.3, 理解为IEEE 802.3, 其为一系列IEEE 标准的集合. 此集合定义了有线以太网络中的物理层以及数据 链路层的媒体接入控制子层. stp 在上文已有描述) atalk tcpdump 将会检查以太网物理帧中的AppleTalk etype 域 ,　同时也会检查数据包中LLC头部中的'SNAP格式结构' (这两种检查与FDDI, TR, 802.11网络中的相应检查一致) aarp tcpdump 将会检查AppleTalk ARP etype 域, 此域或存在于以太网物理帧中, 或存在于LLC(由802.2 所定义)的 'SNAP格式结构'中, 当为后者时, 该'SNAP格式结构'的OUI标识为0x000000; (nt: 802.2, 可理解为, IEEE802.2, 其中定义了逻辑链路控制层(LLC), 该层对应于OSI 网络模型中数据链路层的上层部分. LLC 层为使用数据链路层的用户提供了一个统一的接口(通常用户是网络层). LLC层以下是媒体接入控制层(nt: MAC层, 对应于数据链路层的下层部分).该层的实现以及工作方式会根据不同物理传输媒介的不同而有所区别(比如, 以太网, 令牌环网, 光纤分布数据接口(nt: 实际可理解为一种光纤网络), 无线局域网(802.11), 等等.) ipx tcpdump 将会检查物理以太帧中的IPX etype域, LLC头中的IPX DSAP域，无LLC头并对IPX进行了封装的802.3帧, 以及LLC 头部'SNAP格式结构'中的IPX etype 域(nt | rt: SNAP frame, 可理解为, LLC 头中的'SNAP格式结构'. 该含义属初步理解阶段, 需补充). decnet src host 如果数据包中DECNET源地址为host, 则与此对应的条件表达式为真. (nt:decnet, 由Digital Equipment Corporation 开发, 最早用于PDP-11 机器互联的网络协议) decnet dst host 如果数据包中DECNET目的地址为host, 则与此对应的条件表达式为真. (nt: decnet 在上文已有说明) decnet host host 如果数据包中DECNET目的地址或DECNET源地址为host, 则与此对应的条件表达式为真. (nt: decnet 在上文已有说明) ifname interface 如果数据包已被标记为从指定的网络接口中接收的, 则与此对应的条件表达式为真. (此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) on interface 与 ifname interface 含义一致. rnr num 如果数据包已被标记为匹配PF的规则, 则与此对应的条件表达式为真. (此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) rulenum num 与 rulenum num 含义一致. reason code 如果数据包已被标记为包含PF的匹配结果代码, 则与此对应的条件表达式为真.有效的结果代码有: match, bad-offset, fragment, short, normalize, 以及memory. (此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) rset name 如果数据包已被标记为匹配指定的规则集, 则与此对应的条件表达式为真. (此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) ruleset name 与 rset name 含义一致. srnr num 如果数据包已被标记为匹配指定的规则集中的特定规则(nt: specified PF rule number, 特定规则编号, 即特定规则), 则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为 OpenBSD中的防火墙程序)) subrulenum num 与 srnr 含义一致. action act 如果包被记录时PF会执行act指定的动作, 则与此对应的条件表达式为真. 有效的动作有: pass, block. (此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) ip, ip6, arp, rarp, atalk, aarp, decnet, iso, stp, ipx, netbeui 与以下表达元含义一致: ether proto p p是以上协议中的一个. lat, moprc, mopdl 与以下表达元含义一致: ether proto p p是以上协议中的一个. 必须要注意的是tcpdump目前还不能分析这些协议. vlan [vlan_id] 如果数据包为IEEE802.1Q VLAN 数据包, 则与此对应的条件表达式为真. (nt: IEEE802.1Q VLAN, 即IEEE802.1Q 虚拟网络协议, 此协议用于不同网络的之间的互联). 如果[vlan_id] 被指定, 则只有数据包含有指定的虚拟网络id(vlan_id), 则与此对应的条件表达式为真. 要注意的是, 对于VLAN数据包, 在表达式中遇到的第一个vlan关键字会改变表达式中接下来关键字所对应数据包中数据的 开始位置(即解码偏移). 在VLAN网络体系中过滤数据包时, vlan [vlan_id]表达式可以被多次使用. 关键字vlan每出现一次都会增加 4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移). 例如: vlan 100 && vlan 200 表示: 过滤封装在VLAN100中的VLAN200网络上的数据包 再例如: vlan && vlan 300 && ip 表示: 过滤封装在VLAN300 网络中的IPv4数据包, 而VLAN300网络又被更外层的VLAN封装 mpls [label_num] 如果数据包为MPLS数据包, 则与此对应的条件表达式为真. (nt: MPLS, Multi-Protocol Label Switch, 多协议标签交换, 一种在开放的通信网上利用标签引导数据传输的技术). 如果[label_num] 被指定, 则只有数据包含有指定的标签id(label_num), 则与此对应的条件表达式为真. 要注意的是, 对于内含MPLS信息的IP数据包(即MPLS数据包), 在表达式中遇到的第一个MPLS关键字会改变表达式中接下来关键字所对应数据包中数据的 开始位置(即解码偏移). 在MPLS网络体系中过滤数据包时, mpls [label_num]表达式可以被多次使用. 关键字mpls每出现一次都会增加 4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移). 例如: mpls 100000 && mpls 1024 表示: 过滤外层标签为100000 而层标签为1024的数据包 再如: mpls && mpls 1024 && host 192.9.200.1 表示: 过滤发往或来自192.9.200.1的数据包, 该数据包的内层标签为1024, 且拥有一个外层标签. pppoed 如果数据包为PPP-over-Ethernet的服务器探寻数据包(nt: Discovery packet, 其ethernet type 为0x8863),则与此对应的条件表达式为真. (nt: PPP-over-Ethernet, 点对点以太网承载协议, 其点对点的连接建立分为Discovery阶段(地址发现) 和 PPPoE 会话建立阶段 , discovery 数据包就是第一阶段发出来的包. ethernet type 是以太帧里的一个字段，用来指明应用于帧数据字段的协议) pppoes 如果数据包为PPP-over-Ethernet会话数据包(nt: ethernet type 为0x8864, PPP-over-Ethernet在上文已有说明, 可搜索 关键字'PPP-over-Ethernet'找到其描述), 则与此对应的条件表达式为真. 要注意的是, 对于PPP-over-Ethernet会话数据包, 在表达式中遇到的第一个pppoes关键字会改变表达式中接下来关键字所对应数据包中数据的 开始位置(即解码偏移). 例如: pppoes && ip 表示: 过滤嵌入在PPPoE数据包中的ipv4数据包 tcp, udp, icmp 与以下表达元含义一致: ip proto p or ip6 proto p 其中p 是以上协议之一(含义分别为: 如果数据包为ipv4或ipv6数据包并且其协议类型为 tcp,udp, 或icmp则与此对 应的条件表达式为真) iso proto protocol 如果数据包的协议类型为iso-osi协议栈中protocol协议, 则与此对应的条件表达式为真.(nt: [初解]iso-osi 网络模型中每 层的具体协议与tcp/ip相应层采用的协议不同. iso-osi各层中的具体协议另需补充 ) protocol 可以是一个数字编号, 或以下名字中之一: clnp, esis, or isis. (nt: clnp, Connectionless Network Protocol, 这是OSI网络模型中网络层协议 , esis, isis 未知, 需补充) clnp, esis, isis 是以下表达的缩写 iso proto p 其中p 是以上协议之一 l1, l2, iih, lsp, snp, csnp, psnp 为IS-IS PDU 类型 的缩写. (nt: IS-IS PDU, Intermediate system to intermediate system Protocol Data Unit, 中间系统到 中间系统的协议数据单元. OSI(Open Systems Interconnection)网络由终端系统, 中间系统构成. 终端系统指路由器, 而终端系统指用户设备. 路由器形成的本地组称之为'区域'（Area）和多个区域组成一个'域'（Domain）. IS-IS 提供域内或区域内的路由. l1, l2, iih, lsp, snp, csnp, psnp 表示PDU的类型, 具体含义另需补充) vpi n 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包, 并且其虚拟路径标识为n, 则与此对应的条件表达式为真. (nt: ATM, Asychronous Transfer Mode, 实际上可理解为由ITU-T(国际电信联盟电信标准化部门)提出的一个与 TCP/IP中IP层功能等同的一系列协议, 具体协议层次另需补充) vci n 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包, 并且其虚拟通道标识为n, 则与此对应的条件表达式为真. (nt: ATM, 在上文已有描述) lane 如果数据包为ATM LANE 数据包, 则与此对应的条件表达式为真. 要注意的是, 如果是模拟以太网的LANE数据包或者 LANE逻辑单元控制包, 表达式中第一个lane关键字会改变表达式中随后条件的测试. 如果没有 指定lane关键字, 条件测试将按照数据包中内含LLC(逻辑链路层)的ATM包来进行. llc 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包,　并且内含LLC则与此对应的条件表达式为真 oamf4s 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是Segment OAM F4 信元(VPI=0 并且 VCI=3), 则与此对应的条件表达式为真. (nt: OAM, Operation Administration and Maintenance, 操作管理和维护,可理解为:ATM网络中用于网络 管理所产生的ATM信元的分类方式. ATM网络中传输单位为信元, 要传输的数据终究会被分割成固定长度(53字节)的信元, (初理解: 一条物理线路可被复用, 形成虚拟路径(virtual path). 而一条虚拟路径再次被复用, 形成虚拟信道(virtual channel)). 通信双方的编址方式为:虚拟路径编号(VPI)/虚拟信道编号(VCI)). OAM F4 flow 信元又可分为segment 类和end-to-end 类, 其区别未知, 需补充.) oamf4e 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是 end-to-end OAM F4 信元(VPI=0 并且 VCI=4), 则与此对应的条件表达式为真. (nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索'oamf4s'来定位) oamf4 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真. (nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索'oamf4s'来定位) oam 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真. (nt: 此选项与oamf4重复, 需确认) metac 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是来自'元信令线路'(nt: VPI=0 并且 VCI=1, '元信令线路', meta signaling circuit, 具体含义未知, 需补充), 则与此对应的条件表达式为真. bcc 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是来自'广播信令线路'(nt: VPI=0 并且 VCI=2, '广播信令线路', broadcast signaling circuit, 具体含义未知, 需补充), 则与此对应的条件表达式为真. sc 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是来自'信令线路'(nt: VPI=0 并且 VCI=5, '信令线路', signaling circuit, 具体含义未知, 需补充), 则与此对应的条件表达式为真. ilmic 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是来自'ILMI线路'(nt: VPI=0 并且 VCI=16, 'ILMI', Interim Local Management Interface , 可理解为 基于SNMP(简易网络管理协议)的用于网络管理的接口) 则与此对应的条件表达式为真. connectmsg 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是来自'信令线路'并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect, Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真. (nt: Q.2931 为ITU(国际电信联盟)制定的信令协议. 其中规定了在宽带综合业务数字网络的用户接口层建立, 维护, 取消 网络连接的相关步骤.) metaconnect 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包 并且是来自'元信令线路'并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect, Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真. expr relop expr 如果relop 两侧的操作数(expr)满足relop 指定的关系, 则与此对应的条件表达式为真. relop 可以是以下关系操作符之一: >, >), 长度操作符, 以及对特定数据包中数据的引用操作符. 要注意的是, 所有的比较操作都默认操作数是无符号的, 例如, 0x80000000 和 0xffffffff 都是大于0的(nt: 对于有符号的比较, 按照补码规则, 0xffffffff 会小于0). 如果要引用数据包中的数据, 可采用以下表达方式: proto [expr : size] proto 的取值可以是以下取值之一:ether, fddi, tr, wlan, ppp, slip, link, ip, arp, rarp, tcp, udp, icmp, ip6 或者 radio. 这指明了该引用操作所对应的协议层.(ether, fddi, wlan, tr, ppp, slip and link 对应于数据链路层, radio 对应于802.11(wlan,无线局域网)某些数据包中的附带的 \"radio\"头(nt: 其中描述了波特率, 数据加密等信息)). 要注意的是, tcp, udp 等上层协议目前只能应用于网络层采用为IPv4或IPv6协议的网络(此限制会在tcpdump未来版本中 进行修改). 对于指定协议的所需数据, 其在包数据中的偏移字节由expr 来指定. 以上表达中size 是可选的, 用来指明我们关注那部分数据段的长度(nt:通常这段数据 是数据包的一个域)， 其长度可以是1, 2, 或4个字节. 如果不给定size, 默认是1个字节. 长度操作符的关键字为len, 这代码整个数据包的长度. 例如, 'ether[0] & 1 != 0' 将会使tcpdump 抓取所有多点广播数据包.(nt: ether[0]字节的最低位为1表示 数据包目的地址是多点广播地址). 'ip[0] & 0xf != 5' 对应抓取所有带有选项的 IPv4数据包. 'ip[6:2] & 0x1fff = 0'对应抓取没被破碎的IPv4数据包或者 其片段编号为0的已破碎的IPv4数据包. 这种数据检查方式也适用于tcp和udp数据的引用, 即, tcp[0]对应于TCP 头中第一个字节, 而不是对应任何一个中间的字节. 一些偏移以及域的取值除了可以用数字也可用名字来表达. 以下为可用的一些域(协议头中的域)的名字: icmptype (指ICMP 协议头 中type域), icmpcode (指ICMP 协议头code 域), 以及tcpflags(指TCP协议头的flags 域) 以下为ICMP 协议头中type 域的可用取值: icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert, icmp-routersolicit, icmp-timx-ceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply, icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply. 以下为TCP 协议头中flags 域的可用取值:tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg. "},"htpasswd.html":{"url":"htpasswd.html","title":"htpasswd","keywords":"","body":"htpasswd命令创建用户和修改密码 语法:htpasswd(选项)(参数) 选项: -c：创建一个加密文件； -n：不更新加密文件，只将加密后的用户名密码显示在屏幕上； -m：默认采用MD5算法对密码进行加密； -d：采用CRYPT算法对密码进行加密； -p：不对密码进行进行加密，即明文密码； -s：采用SHA算法对密码进行加密； -b：在命令行中一并输入用户名和密码而不是根据提示输入密码； -D：删除指定的用户。 参数 用户：要创建或者更新密码的用户名； 密码：用户的新密码。 添加用户 htpasswd -bc ~/htpasswd.user admin 123456 在home目录下生成一个 htpasswd.user 文件，用户名admin，密码：123456，默认采用MD5加密方式。 "},"ding-shi-qi.html":{"url":"ding-shi-qi.html","title":"定时器","keywords":"","body":""},"ding-shi-qi/crontab.html":{"url":"ding-shi-qi/crontab.html","title":"crontab","keywords":"","body":"a cron job #一份计划工作 crontab参数： -u：帮助其他用户建立或移除工作排程 -l：查阅crontab的工作内容 -r：移除所有的crontab的工作内容 -e：编辑crontab文件 每项任务有六个字段： *　　*　　*　　*　　*　　* 分钟　　小时　　日期　　月份　　周　　指令 0-59　　0-23　　1-31　　1-12　　0-7　指令 #0和7都代表星期日 例如: 每个星期三下午14：30 执行ls 30 14 * * 3 ls /home/ 在crontab文件中如何输入需要执行的命令和时间。该文件中每行都包括六个域，其中前五个域是指定命令被执行的时间，最后一个域是要被执行的命令 ,可以通过编辑/etc/crontab文件 合法值 00-59 00-23 01-31 01-12 0-6 \\(0 is sunday\\) commands（代表要执行的脚本） 第1列表示分钟1～59 每分钟用*或者 */1表示 第2列表示小时1～23（0表示0点） 第3列表示日期1～31 第4列表示月份1～12 第5列标识号星期0～6（0表示星期天） 第6列要运行的命令 在crontab文件中如何输入需要执行的命令和时间。该文件中每行都包括六个域，其中前五个域是指定命令被执行的时间，最后一个域是要被执行的命令。 除了数字特殊的符号如下: * 代表所有的取值范围内的数字 5 * * * * 指定每小时的第5分钟执行一次ls命令 #第二个小时取值范围是时间* 表示每个单位 \"/\" 代表每的意思,\"/5\"表示每5个单位 \"-\" 代表从某个数字到某个数字 \",\" 分开几个离散的数字 如:每晚的21:30重启apache。 30 21 * * * /usr/local/etc/rc.d/lighttpd restart 和 每两个小时执行 0 */2 * * * /usr/local/etc/rc.d/lighttpd restart 或者 晚上11点到早上8点之间每两个小时，以及8点在执行一次 0 23-7/2，8 * * * /usr/local/etc/rc.d/lighttpd restart 可以安装指定时间或者时间间隔执行 5 * * * * 指定每小时的第5分钟执行一次ls命令 30 5 * * * ls 指定每天的 5:30 执行ls命令 30 7 8 * * ls 指定每月8号的7：30分执行ls命令 30 5 8 6 * ls 指定每年的6月8日5：30执行ls命令 查看执行情况看日志 ,ubunut 中默认未打开,修改rsyslog文件 tail -f /var/log/cron.log 新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\\%Y\\%m\\%d’。 定时器中设置-写绝对路径 #给www-data用户添加定时任务 sudo crotab -u www-data -e 10 9 * * * /usr/sbin/rtcwake -v -m disk -s 280 "},"swap.html":{"url":"swap.html","title":"SWAP","keywords":"","body":"mkswap：格式化普通分区文件为交换分区文件 #建立swap的文件系统 mkswap /root/swapfile swapon：启用交换分区文件 #启用swap文件 swapon /root/swapfile swapon 卸载 swapon /root/swapfile "},"swap/diao-zheng-da-xiao.html":{"url":"swap/diao-zheng-da-xiao.html","title":"调整大小","keywords":"","body":" free -m 查询当前swap空间大小 建立一个分区文件，采用dd命令比如 dd if=/dev/zero of=/home/swap bs=1024 count=204800 分区变成swap分区 sbin/mkswap /home/swap 使用这个swap分区。使其成为有效状态 /sbin/swapon /home/swap free -m 已经调整了 现在再用free -m命令查看一下内存和swap分区大小，就发现增加了512M的空间了。不过当计算机重启了以后，发现swap还是原来那么大，新的swap没有自动启动，还要手动启动。那我们需要修改/etc/fstab文件，增加如下一行 /home/swap swap swap defaults 0 0 "},"fail2ban.html":{"url":"fail2ban.html","title":"Fail2ban","keywords":"","body":"Fail2ban 能够监控系统日志，匹配日志中的错误信息（使用正则表达式），执行相应的屏蔽动作（支持多种，一般为调用 iptables ），是一款很实用、强大的软件。 攻击者不断尝试穷举 SSH 、SMTP 、FTP 密码等，只要达到预设值，fail2ban 就会调用防火墙屏蔽此 IP ，并且可以发送邮件通知系统管理员。 功能、特性: 1、支持大量服务：sshd 、apache 、qmail 等 2、支持多作动作：iptables 、tcp-wrapper 、shorewall 、mail notifications 等 3、logpath 选项中支持通配符 4、需要 Gamin 支持（Gamin 用于监控文件和目录是否更改） 5、如果需要邮件通知，则系统事先要确保能够正常发送邮件 "},"ubunut.html":{"url":"ubunut.html","title":"ubunut","keywords":"","body":"aaaaaasssaasasasaasasas "},"ubunut/sheng-ji-ming-ling.html":{"url":"ubunut/sheng-ji-ming-ling.html","title":"升级命令","keywords":"","body":"apt-get update apt-get upgrade apt-get full-upgrade apt-get dist-upgrade apt-get 的官方手册： update 从服务器更新可用的软件包列表。 upgrade 根据列表，更新已安装的软件包。 upgrade 不会删除在列表中已经没有的软件包，也不会安装有依赖需求但尚未安装的软件包。 full-upgrade 根据列表，更新已安装的软件包。 full-upgrade 可能会为了解决软件包冲突而删除一些已安装的软件包。 dist-upgrade 根据列表，更新已安装的软件包。 dist-upgrade 可能会为了解决软件包冲突而删除一些已安装的软件包，也可能会为了解决软件包依赖问题安装新的软件包。 "},"ubunut/cronri-zhi.html":{"url":"ubunut/cronri-zhi.html","title":"cron日志","keywords":"","body":" 指定日志文件 #修改rsyslog文件,将 rsyslog 文件中的 #cron.* 前的 # 删掉； /etc/rsyslog.d/50-default.conf #重启rsyslog服务： service rsyslog restart #重启cron服务： service cron restart #查看日志文件： tail -f /var/log/cron.log 或者使用grep过滤系统日志中包含 grep cron /var/log/syslog "},"ubunut/systemctl.html":{"url":"ubunut/systemctl.html","title":"服务管理","keywords":"","body":"1.启动nginx服务 systemctl start nginx.service 2.设置开机自启动 systemctl enable nginx.service 3.停止开机自启动 systemctl disable nginx.service 4.查看服务当前状态 systemctl status nginx.service 5.重新启动某服务 systemctl restart nginx.service 6.停止服务 systemctl stop nginx.service sudo systemctl -help systemctl [OPTIONS...] {COMMAND} ... Query or send control commands to the systemd manager. -h --help Show this help "},"ubunut/kai-ji.html":{"url":"ubunut/kai-ji.html","title":"开机","keywords":"","body":"一般正常的启动文件主要分成三部分 [Unit] 段: 启动顺序与依赖关系 [Service] 段: 启动行为,如何启动，启动类型 [Install] 段: 定义如何安装这个配置文件，即怎样做到开机启动 可以看出，/etc/rc.local 的启动顺序是在网络后面，但是显然它少了 Install 段，也就没有定义如何做到开机启动，所以显然这样配置是无效的。 因此我们就需要在后面帮他加上 [Install] 段: [Install] WantedBy=multi-user.target Alias=rc-local.service 这里需要注意一下，ubuntu-18.04 默认是没有 /etc/rc.local 这个文件的，需要自己创建 sudo touch /etc/rc.local 然后把你需要启动脚本写入 /etc/rc.local ，我们不妨写一些测试的脚本放在里面，以便验证脚本是否生效. echo \"this just a test\" > /usr/local/text.log 做完这一步，还需要最后一步 前面我们说 systemd 默认读取 /etc/systemd/system 下的配置文件, 所以还需要在 /etc/systemd/system 目录下创建软链接 ln -s /lib/systemd/system/rc.local.service /etc/systemd/system/ OK, 接下来，重启系统，然后看看 /usr/local/text.log 文件是否存在就知道开机脚本是否生效了。 如： bh@y450:~$ sudo cat /etc/rc.local #!/bin/bash #su bh -c \"/home/bh/tomcats/8081/bin/startup.sh &\" exit 0 "},"vim.html":{"url":"vim.html","title":"vim","keywords":"","body":"正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空 插入模式（按i键进入） 左下角显示--INSERT-- 可视模式（） 左下角显示--VISUAL-- "},"vim/ti-huan.html":{"url":"vim/ti-huan.html","title":"替换字符","keywords":"","body":"利用 :s 命令可以实现字符串的替换。具体的用法包括 :s/str1/str2/ 用字符串 str2 替换行中首次出现的字符串 str1 :s/str1/str2/g 用字符串 str2 替换行中所有出现的字符串 str1 :.,$ s/str1/str2/g 用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1 :1,$ s/str1/str2/g 用字符串 str2 替换正文中所有出现的字符串 str1 :g/str1/s//str2/g 功能同上 g 放在命令末尾: (一行) 表示对搜索字符串的每次出现进行替换；不加 g表示只对搜索字符串的首次出现进行替换； g 放在命令开头:(一行) 表示对正文中所有包含搜索字符串的行进行替换操作 "},"vim/cha-zhao-cao-zuo.html":{"url":"vim/cha-zhao-cao-zuo.html","title":"查找操作","keywords":"","body":"/text　　查找text，按n健查找下一个，按N健查找前一个。 ?text　　查找text，反向查找，按n健查找下一个，按N健查找前一个。 vim中有一些特殊字符在查找时需要转义　　.*[]^%/?~$ :set ignorecase　　忽略大小写的查找 :set noignorecase　　不忽略大小写的查找 查找很长的词，如果一个词很长，键入麻烦，可以将光标移动到该词上，按*或#键即可以该单词进行搜索，相当于/搜索。而#命令相当于?搜索。 :set hlsearch　　高亮搜索结果，所有结果都高亮显示，而不是只显示一个匹配。 :set nohlsearch　　关闭高亮搜索显示 :nohlsearch　　关闭当前的高亮显示，如果再次搜索或者按下n或N键，则会再次高亮。 :set incsearch　　逐步搜索模式，对当前键入的字符进行搜索而不必等待键入完成。 :set wrapscan　　重新搜索，在搜索到文件头或尾时，返回继续搜索，默认开启。 "},"vim/yi-dong-guang-biao.html":{"url":"vim/yi-dong-guang-biao.html","title":"移动光标","keywords":"","body":"h 左移一个字符 l 右移一个字符，这个命令很少用，一般用w代替。 k 上移一个字符 j 下移一个字符 以上四个命令可以配合数字使用，比如20j就是向下移动20行，5h就是向左移动5个字符，在Vim中，很多命令都可以配合数字使用，比如删除10个字符10x，在当前位置后插入3个！，3a！这里的Esc是必须的，否则命令不生效。 w 向前移动一个单词（光标停在单词首部），如果已到行尾，则转至下一行行首。此命令快，可以代替l命令。 b 向后移动一个单词 2b 向后移动2个单词 e，同w，只不过是光标停在单词尾部 ge，同b，光标停在单词尾部。 ^ 移动到本行第一个非空白字符上。 0（数字0）移动到本行第一个字符上， 移动到本行第一个字符。同0健。 $ 移动到行尾 3$ 移动到下面3行的行尾 gg 移动到文件头。 = [[ G（shift + g） 移动到文件尾。 = ]] f（find）命令也可以用于移动，fx将找到光标后第一个为x的字符，3fd将找到第三个为d的字符。 F 同f，反向查找。 跳到指定行，冒号+行号，回车，比如跳到240行就是 :240回车。另一个方法是行号+G，比如230G跳到230行。 Ctrl + e 向下滚动一行 Ctrl + y 向上滚动一行 Ctrl + d 向下滚动半屏 Ctrl + u 向上滚动半屏 Ctrl + f 向下滚动一屏 Ctrl + b 向上滚动一屏 "},"vim/che-xiao.html":{"url":"vim/che-xiao.html","title":"撤销操作","keywords":"","body":"u 撤销（Undo） U 撤销对整行的操作 Ctrl + r 重做（Redo），即撤销的撤销。 "},"vim/shan-chu.html":{"url":"vim/shan-chu.html","title":"删除操作","keywords":"","body":"x 删除当前字符 3x 删除当前光标开始向后三个字符 X 删除当前字符的前一个字符。X=dh dl 删除当前字符， dl=x dh 删除前一个字符 dd 删除当前行 dj 删除上一行 dk 删除下一行 10d 删除当前行开始的10行。 D 删除当前字符至行尾。D=d$ d$ 删除当前字符之后的所有字符（本行） kdgg 删除当前行之前所有行（不包括当前行） jdG（jd shift + g） 删除当前行之后所有行（不包括当前行） :1,10d 删除1-10行 :11,$d 删除11行及以后所有的行 :1,$d 删除所有行 J(shift + j)　　删除两行之间的空行，实际上是合并两行。 "},"kao-bei-he-nian-tie.html":{"url":"kao-bei-he-nian-tie.html","title":"拷贝和粘贴","keywords":"","body":"yy 拷贝当前行 nyy 拷贝当前后开始的n行，比如2yy拷贝当前行及其下一行。 p 在当前光标后粘贴,如果之前使用了yy命令来复制一行，那么就在当前行的下一行粘贴。 shift+p 在当前行前粘贴 :1,10 co 20 将1-10行插入到第20行之后。 :1,$ co $ 将整个文件复制一份并添加到文件尾部。 正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按y即可复制 ddp交换当前行和其下一行 xp交换当前字符和其后一个字符 "},"vim/jian-qie-cao-zuo.html":{"url":"vim/jian-qie-cao-zuo.html","title":"剪切操作","keywords":"","body":"正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按d即可剪切 ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴 :1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。 :1, 10 m 20 将第1-10行移动到第20行之后。 "},"vim/cha-ru-cao-zuo.html":{"url":"vim/cha-ru-cao-zuo.html","title":"插入操作","keywords":"","body":"i 在当前位置生前插入 I 在当前行首插入 a 在当前位置后插入 A 在当前行尾插入 o 在当前行之后插入一行 O 在当前行之前插入一行 "},"nginx.html":{"url":"nginx.html","title":"nginx","keywords":"","body":"是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务 "},"nginx/mo-kuai.html":{"url":"nginx/mo-kuai.html","title":"模块","keywords":"","body":"Nginx代码都是以模块的形式组织的，包括核心模块和功能模块。针对不同的应用场合选用不同的功能模块，如果要选用不同的功能模块，必须对Nginx做重新配置和编译。并且每个模块实现的功能各不相同，但是根据模块的主要功能性质，大体可以将它们分为四个类别。 handlers：协同完成客户端请求的处理、产生响应数据 ngx_http_rewrite_module模块，用于处理客户端请求的地址重写。 ngx_http_static_module模块，负责处理客户端的静态页面请求。 ngx_http_log_module模块，负责记录请求访问日志。 filters：对handlers产生的响应数据做各种过滤处理（增／删／改） ngx_http_not_modified_filter_modu 待响应数据进行过滤检测，如果通过时间戳判断出前后两次请求的响应数据没有发生任何实质改变，那么可以直接响应“304NotModified”状态标识，让客户端使用本地缓存即可，而原本待发送的响应数据将被清除掉 upstream：如果存在后端真实服务器，Nginx可利用upstream模块充当反向代理（ReverseProxy）的角色，对客户端发起的请求只负责进行转发（当然也包括对后端真实服务器响应数据的回转）， ngx_http_proxy_module就为标准的upstream模块。 loadbalance：在Nginx充当中间代理角色时，由于后端真实服务器往往多于一个，对于某一次客户端的请求，如何选择对应的后端真实服务器来进行处理，有类似于ngx_http_upstream_ip_hash_module这样的loadbalance模块来实现不同的负载均衡算法。 "},"nginx/pei-zhi-wen-jian/pei-zhi-wen-jian.html":{"url":"nginx/pei-zhi-wen-jian/pei-zhi-wen-jian.html","title":"配置文件","keywords":"","body":"配置文件是Nginx的核心，它与Nginx的模块化架构是一个互相依存的整体，决定了Nginx的进程数量、运行日志、虚拟主机、反向代理和邮件代理、各种请求处理逻辑、优化调整等方方面面，众多的模块都要依赖配置文件里的指令才能正常工作。Nginx在启动时将会读取配置文件，根据配置指令调用不同的模块处理，设置它们的运行参数。 "},"nginx/pei-zhi-wen-jian.html":{"url":"nginx/pei-zhi-wen-jian.html","title":"配置项","keywords":"","body":"Nginx配置文件是由多个配置项组成的，每一个配置项都有一个项目名和对应的项目值，项目名又称为指令（Directive），而项目值可能是简单的字符串（以分号结尾），也可能是由简单字符串和多个配置项组合而成配置块的复合结构（以大括号‘}’结尾）。 每一项配置Nginx都会提供对应的代码做它的解析转换工作，如果配置文件内出现了Nginx无法解析的配置项，那么Nginx将报错并直接退出程序。 配置项归纳为两种：简单配置项和复杂配置项 graph LR A[nginx.cnof] --> B(mian配置项) B --> E(项目名-项目值) B --> Ea(http块配置项) Ea --> G(简单配置项) Ea --> F(复杂配置项) 简单配置项 user www-data; worker_processes auto; pid /run/nginx.pid; 复杂配置项 events { worker_connections 768; } #或者 location ^~/book { auth_basic \"User Authentication\"; auth_basic_user_file /home/bh/ata/htppass/pass.db; index index.html; alias /home/bh/ata/book/html/; } 项目名称:location 项目值: ^~/book 和括号内的简单配置项 两者配置项的区别 对于复杂配置项而言，Nginx并不做具体的解析与赋值操作，一般只是申请对应的内容空间、切换解析状态，然后递归调用解析函数，将复杂配置中包含的简单配置项信息转换为Nginx内控制变量的值。 预定义的配置上下文主要包括main、http、server、location4种（还有其他几种，比如event、upstream、if、mail等） "},"nginx/pei-zhi-wen-jian/pei-zhi-9879-ji-cheng.html":{"url":"nginx/pei-zhi-wen-jian/pei-zhi-9879-ji-cheng.html","title":"继承","keywords":"","body":"对于用户在某个层次没有设置的配置选项，那么它的值应该来自上一层，也就是所谓的配置信息的继承，如果其上一层没有该配置选项，那么就使用默认值。 listen指令就只能用在server上下文，所以如果某个server没有配置listen选项，那么将使用它的默认值，因为其无法从http或main上下文里继承过来。 alias /home/bh/ata/book/html/; location ^~/book { auth_basic \"User Authentication\"; auth_basic_user_file /home/bh/ata/htppass/pass.db; index index.html; #不继承上层 alias /home/bh/ata/book/html/; } "},"nginx/jin-cheng-pei-zhi.html":{"url":"nginx/jin-cheng-pei-zhi.html","title":"进程配置","keywords":"","body":"进程配置指令不属于任何配置块，只能在全局域（main）里配置。 #设置Nginx能够启动的worker进程的数量 worker_processes 1|auto; 通常当worker数与服务器的CPU核心数相等时可以获得最佳的性能，这时每一个worker都会工作在一个独立的CPU核心上，完全消除CPU调度的成本。worker_processes的默认值是1。如果不清楚服务器的CPU核心数量，那么可以设置为auto参数，Nginx会尝试探测数量并设置。 #是否启用Nginx的进程池机制 master_process on|off; 是否启用Nginx的进程池机制，默认值是on。如果设置为off，那么Nginx不会建立master进程，只会用一个worker进程处理请求，worker_processes指令也会失效，并发处理能力大大下降。 "},"nginx/ri-zhi-pei-zhi.html":{"url":"nginx/ri-zhi-pei-zhi.html","title":"日志配置","keywords":"","body":"在Nginx里运行日志分为两种配置项，可以在其它配置项中定义 access_log 记录HTTP访问请求的。 error_log 记录服务器错误信息的。 #错误日志 error_log file|stderr level; #请求日志 access_log file|stderr level; file | stderr 定义文件或者或者使用标准错误输出stderr level (debug|info|notice|warn|error|crit|alert|emerg) 只有高于这个级别的日志才会记录下来，默认值是error或者info sever{ #日志格式化 log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for ' '\"$upstream_addr\" \"$upstream_status\" \"$upstream_response_time\" \"$request_time\"'; access_log /var/log/nginx/access.log access; access_log /var/log/nginx/access_log.log location ^~/book { #当前配置项只记录warn级别的 access_log /home/bh/ata/book/logs/access_log.log warn; alias /home/bh/ata/book/html/; } location = /robots.txt { allow all; log_not_found off; #关闭当前项的日志输出 access_log off; } } "},"nginx/mo-kuai/httpmo-kuai.html":{"url":"nginx/mo-kuai/httpmo-kuai.html","title":"http配置","keywords":"","body":"Nginx使用http配置项配置HTTP相关的功能如下： cache fastcgi gzip server location proxy upstream http{ #上游服务器 upstream proxy_aa { } include proxy_bb.cnf; #虚拟主机 server { #目录 location / { } } server { } } include 引入其它配置项 "},"nginx/mo-kuai/httpmo-kuai/server.html":{"url":"nginx/mo-kuai/httpmo-kuai/server.html","title":"server-虚拟主机","keywords":"","body":"在http块内使用server指令定义一个虚拟主机，它必须是一个配置块，在块内部再使其他用指令来确定虚拟主机的端口、域名等参数，然后Nginx就可以对外提供Web服务。 listen port; listen指令设置虚拟主机监听的端口，默认是80。 实际上listen指令还有很多参数，可以设置IP地址、UNIXDomainSocket、SSL、backlog、rcvbuf/sndbuf等 server_name name...; server_name指令设置虚拟主机对外提供服务的主机名称，允许使用通配符和“~”开头的正则表达式。 例如 “www.nginx.org”、“.image.nginx.org”，默认值是空 当Nginx处理请求时将会检查HTTP头部的Host域选择与server_name匹配的server块提供服务，从而达到在一个Nginx里实现多个虚拟主机的目的。 如果根据listen指令无法得到最佳匹配,将会开始解析server_name指令.nginx会检查请求中的\"Host\"头,这个值包含了客户端实际试图请求的域名或者ip地址.nginx会根据这个值去匹配server_name指令,匹配规则如下: nginx会尝试寻找一个和sever_name和Host值完全匹配的server块,如果找到多个精确匹配,则会使用第一个匹配的server块 如果没有找到精确匹配的server块,则nginx尝试找到server_name带有开头的server块,如果找到多个,则选择最长匹配的server块 如果没有找到使用开头的server块,则会寻找以结尾的server块,同样,如果有多个匹配, 选择最长匹配 如果没有找到使用匹配的server块,则会寻找使用正则表达式(以~开头)定义server_name的server块,如果找到多个匹配,会使用第一个匹配 如果没有找到正则表达式匹配的server块,则nginx将会选择一个匹配listen字段的default server块.每一个ip和端口组合都可以配置一个且只能配置一个默认的default_server块,如果没有的话,则会选择可用列表中的第一个server(此时的选择是随机的,顺序不固定) 如果以上都没有匹配,则使用default_server.如果没有指定default_server,则会选择第一个可用的server.我们可以指定对于没有匹配的host值时,返回错误到客户端.可以用来防止别人把垃圾流量转到你的网站。如下： server { listen 80 default_server; server_name _; return 444; } 通过返回444这个nginx的非标准错误码让nginx断开与浏览器的连接 keepalive_timeouttimeout; 设置keepalive的超时时间，默认是75s。它通常有利于客户端复用HTTP长连接，提高服务器的性能。如果希望服务器发送完数据后能够主动断连，就可以把它设置为0。 "},"nginx/mo-kuai/httpmo-kuai/server/location.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/location.html","title":"location-虚拟目录","keywords":"","body":"location相当于虚拟主机上的虚拟目录，Nginx在成功匹配虚拟主机进入server块后，会继续查找匹配URI的location块，它是Nginx处理的终点站，决定了请求应该如何处理。 location使用配置文件里的uri参数匹配HTTP请求行里的URI（除去域名），默认是前缀匹配，也支持正则表达式 #语法 location [ = | ~ | ~* | ^~ ] uri { ... } 使用如下前缀来做进一步的匹配限定： =：URI必须完全匹配； ~：大小写敏感匹配； ~*：大小写不敏感匹配； ^~：匹配前半部分即可； @：用于内部子请求，外部无法访问 如：https://www.aa.com/books.html #完全匹配 root /home/bh/ata/book/html/; location = books.html { index baihui.html ; } #匹配前半部分 location = ^~/book { index baihui.html ; alias /home/bh/ata/book/html/; } 2019/05/09 20:45:46 [error] 5601#5601: *2068 open() \"/home/bh/ata/book/html/s.html\" failed (2: No such file or directory), client: 27.189.126.202, server: www.aa.com, request: \"GET /books.html HTTP/2.0\", host: \"www.aa.com\" url=/books.html 虚拟目录location = books.html 不能匹配 /books.html != books.html 虚拟目录location = ^~/book 能匹配 /books.html前部分包含/book 匹配成功以后url=/book 资源=s.html,nginx 会到/home/bh/ata/book/html/目下找s.html文件 由于/home/bh/ata/book/html/没有s.html文件所以错误 匹配顺序如图 sequenceDiagram participant http participant servers participant locations http->>servers: www.aa.com servers->>locations: /books.html locations->>http:返回结果 "},"nginx/mo-kuai/httpmo-kuai/server/location/pi-pei-shun-xu.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/location/pi-pei-shun-xu.html","title":"匹配顺序","keywords":"","body":"匹配分两种：正则location和普通location 正则location “~”和“~*”：“~”表示区分大小写；“~*”表示不区分大小写 普通location: 除了上面其余全是(包括没有前缀) “=”，“^~”，“@” “^~”中的“^”表示非，“~”表示正则，意思为不要继续匹配正则“^~”依然遵守“最大前缀”匹配 #匹配www.xx.com/ location = / { [ configuration A ] } #匹配xxx.com/index.html location / { [ configuration B ] } #匹配xxx.com/documents[/** | /] location /documents/ { [ configuration C ] } # ^不使用正则,普通前缀匹配 # 匹配xxx.com/documents/images[/** | /] location ^~ /images/ { [ configuration D ] } # 使用正则 # xxx.com/a.[gif|jpg|jpeg] location ~* \\.(gif|jpg|jpeg)$ { [ configuration E ] } 匹配顺序总结为以下两点： 匹配的顺序是先匹配普通字符串，然后再匹配正则表达式。另外普通字符串匹配顺序是根据配置中字符长度从长到短，也就是说使用普通字符串配置的location顺序是无关紧要的，nginx会根据配置的长短来进行匹配，但是需要注意的是正则表达式按照配置文件里的顺序测试。找到第一个匹配的正则表达式将停止搜索。 一般情况下，匹配成功了普通字符串location后还会进行正则表达式location匹配。有两种方法改变这种行为，其一就是使用“=”前缀，这时执行的是严格匹配，并且匹配成功后立即停止其他匹配，同时处理这个请求；另外一种就是使用“^~”前缀，如果把这个前缀用于一个常规字符串那么告诉nginx 如果路径匹配那么不测试正则表达式。 "},"nginx/mo-kuai/httpmo-kuai/server/location/zheng-ze-biao-da-shi.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/location/zheng-ze-biao-da-shi.html","title":"正则表达式","keywords":"","body":"什么是正则表达式 正则表达式，又称规则表达式。（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式通常被用来检索、替换那些符合某个模式(规则)的文本。 许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由Unix中的工具软件（例如sed和grep）普及开的。正则表达式通常缩写成“regex”，单数有regexp、regex，复数有regexps、regexes、regexen。 正则表达式由一些普通字符和一些元字符（metacharacters）组成。普通字符包括大小写的字母和数字，而元字符则具有特殊的含义，我们下面会给予解释。 在最简单的情况下，一个正则表达式看上去就是一个普通的查找串。例如，正则表达式\"testing\"中没有包含任何元字符，它可以匹配\"testing\"和\"testing123\"等字符串，但是不能匹配\"Testing\"。 要想真正的用好正则表达式，正确的理解元字符是最重要的事情。下表列出了所有的元字符和对它们的一个简短的描述。 元字符 描述 \\ 将下一个字符标记符、或一个向后引用、或一个八进制转义符。例如，“\\n”匹配\\n。“\\n”匹配换行符。序列“\\”匹配“\\”而“(”则匹配“(”。即相当于多种编程语言中都有的“转义字符”的概念。 ^ 匹配输入字行首。如果设置了RegExp对象的Multiline属性，^也匹配“\\n”或“\\r”之后的位置。 $ 匹配输入行尾。如果设置了RegExp对象的Multiline属性，$也匹配“\\n”或“\\r”之前的位置。 * 匹配前面的子表达式任意次。例如，zo能匹配“z”，也能匹配“zo”以及“zoo”。等价于{0,}。 + 匹配前面的子表达式一次或多次(大于等于1次）。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。 ? 匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”。?等价于{0,1}。 if ( $server_name ~ ((|www.|)([if ( $ser| #过滤主域名 if ( $server_name ~ ((www.|)([\\S\\s]*)) ) { set $domain $3; } #设定初始值 set $temp 0; #判断是否为支付域名 if ( $host ~* (pay|zf) ) { set $temp \"${temp}1\"; } #判断是否是手机端 if ($http_user_agent ~* (mobile|nokia|iphone|ipad|android|samsung|htc|blackberry)) { set $temp \"${temp}2\"; } #判断是否跳转 if ( $temp = \"02\" ) { rewrite ^(.*) https://app.$domain permanent; } 首先，我们是需要取得主域名部分，那就少不了使用正则去匹配，假如说以www.baidu.com这条域名为例，我们看到的第一个就是www.这个字段，但是还会存在一种情况就是用户可能会直接输入baidu.com这样子去访问，所以我们这里是用(www.|)去进行匹配，再然后匹配点这个字段，而下面的$3是表示取第三个括号里的值，最后复值给$a这个变量，接下来就是通过$http_user_agent这个内置变量去进行判断用户是使用什么方式访问，然后在进行重定向操作。 这个案例的需求是这样子的,我们提交一些表单内容后url地址会显示除部分参数，比如http://baidu.com/index.php?user=admin&pass=123,而我们需要将url重写为http://baidu.com/index rewrite ^/(\\w+)/(\\w+)/z(\\d+) /$1/$2/$3/$arg_x/$arg_y? permanent; rewrite ^/(\\w+)/(\\w+)/(\\d+)/(\\d+)/(\\d+) /$1/$2/$3/$4_$5.png permanent; 脚本逻辑分析： 首先我们想想想url的演变，http://baidu.com/index.php?user=admin&pass=123 => http://baidu.com/index.php/user/admin/pass/123 => http://baidu.com/index,然后我们根据演变进行一步一步的操作，nginx rewrite正则匹配不会匹配问号后的参数，因此需要使用$arg_{参数名}来保留参数，且匹配规则要以问号结尾；最后匹配一些其他项替换就完成重写了 "},"nginx/mo-kuai/httpmo-kuai/cache.html":{"url":"nginx/mo-kuai/httpmo-kuai/cache.html","title":"cache","keywords":"","body":""},"nginx/mo-kuai/httpmo-kuai/fastcgi.html":{"url":"nginx/mo-kuai/httpmo-kuai/fastcgi.html","title":"fastcgi","keywords":"","body":""},"nginx/mo-kuai/httpmo-kuai/gzip.html":{"url":"nginx/mo-kuai/httpmo-kuai/gzip.html","title":"gzip","keywords":"","body":""},"nginx/mo-kuai/httpmo-kuai/proxy.html":{"url":"nginx/mo-kuai/httpmo-kuai/proxy.html","title":"proxy_pass","keywords":"","body":"反向代理指的是以代理服务器接收用户的的访问请求，代理用户向内部服务器重新发起请求，最后把内部服务器的响应信息返回给用户。这样，代理服务器对外就表现为一台服务器，而访问内部服务器的客户端用的就是代理服务器，而不是真实网站访问用户 server{ listen 80; server_name www.baihui.com; location / { #代理 proxy_pass http://192.168.1.8; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } "},"nginx/mo-kuai/httpmo-kuai/upstream.html":{"url":"nginx/mo-kuai/httpmo-kuai/upstream.html","title":"upstream","keywords":"","body":"ngx_http_upstream_module模块支持的代理方式有proxy_pass,fastcgi_pass等. upstream模块允许nginx定义一组或多组节点服务器组，使用时通过proxy_pass代理把网站的请求发送到定义好的对应的节点组中。 upstream baihui { server 192.168.30.5:80 weight=5; server 192.168.30.6:81 weight=10; server 192.168.30.7:82 weight=15; } upstream php-handler { server unix:/run/php/php7.2-fpm.sock; } "},"nginx/mo-kuai/httpmo-kuai/fastcgipass.html":{"url":"nginx/mo-kuai/httpmo-kuai/fastcgipass.html","title":"fastcgi_pass","keywords":"","body":""},"nginx/mo-kuai/httpmo-kuai/server/rewrite.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite.html","title":"rewrite","keywords":"","body":"Rewrite主要的功能就是实现URL的重写，Nginx的Rewrite规则采用PCRE（PerlCompatibleRegularExpressions）Perl兼容正则表达式的语法进行规则匹配， Rewrite功能须要编译安装PCRE库 Nginx Rewrite规则相关指令有if、rewrite、set、return、break等，其中rewrite是最关键的指令 "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/if.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/if.html","title":"if","keywords":"","body":"if指令语法：if(条件){...} 使用环境：server,location if指令不支持嵌套，不支持多个条件&&和Ⅱ处理。 以下信息可以被指定为条件： 变量名，错误的值包括：空字符串＂＂，或者任何以0开始的字符串； 变量比较可以使用“=”（表示等于）和“!=”（表示不等于）运算符； 正则表达式模式匹配可以使用“~*”和“~”符号； “~”符号表示区分大小写字母的匹配； “~*”符号表示不区分大小写字母的匹配（例如firefox与FireFox是匹配的）； “!~”和“!~*”符号的作用刚好和“~”、“!~*”相反，表示不匹配； “f”和“!f”用来判断文件是否存在； “d”和“!d”用来判断目录是否存在； “e”和“!e”用来判断文件或目录是否存在； “x”和“!x”用来判断文件是否可执行。 if ($http_user_agent ~ MSIE ){ rewrite ^(.*)$ /msie/$1 break ; } "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite.html","title":"rewrite","keywords":"","body":"rewrite指令执行顺序 执行server块的rewrite指令(这里的块指的是server关键字后{}包围的区域，其它xx块类似) 执行location匹配 执行选定的location中的rewrite指令 如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件,如果循环超过10次，则返回500 Internal Server Error错误。 rewrite的语法: rewrite regex URL [flag]; rewrite是关键字，regex是正则表达式，URL是要替代的内容，[flag]是标记位的意思，它有以下几种值： last: 相当于Apache的[L]标记，表示完成rewrite break: 停止执行当前虚拟主机的后续rewrite指令集 redirect: 返回302临时重定向，地址栏会显示跳转后的地址 permanent: 返回301永久重定向，地址栏会显示跳转后的地址 因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了 last一般写在server和if中，而break一般使用在location中last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 regex 字符 描述 \\ 将后面接着的字符标记为一个特殊字符或一个原义字符或一个向后引用。如“\\n”匹配一个换行符，而“$”则匹配“$” ^ 匹配输入字符串的起始位置 如：^/listings/ 从url /listings 开始 $ 匹配输入字符串的结束位置 * 匹配前面的字符零次或多次。如“ol*”能匹配“o”及“ol”、“oll” + 匹配前面的字符一次或多次。如“ol+”能匹配“ol”及“oll”、“oll”，但不能匹配“o” ? 匹配前面的字符零次或一次，例如“do(es)?”能匹配“do”或者“does”，\"?\"等效于\"{0,1}\" . 匹配除“\\n”之外的任何单个字符，若要匹配包括“\\n”在内的任意字符，请使用诸如“[.\\n]”之类的模式。 (pattern) 匹配括号内pattern并可以在后面获取对应的匹配，常用$0...$9属性获取小括号中的匹配内容，要匹配圆括号字符需要(Content) # .well-known/carddav 请求永久重定向到/remote.php/dav rewrite /.well-known/carddav /remote.php/dav permanent; rewrite /.well-known/caldav /remote.php/dav permanent; #等价上面的 location = /.well-known/carddav { return 301 $scheme://$host/remote.php/dav; } location = /.well-known/caldav { return 301 $scheme://$host/remote.php/dav; } #http://mysite.com/listings/123 重写 http://mysite.com/listing.html?listing=123 rewrite ^/listings/(.*)$ /listing.html?listing=$1 last; # http://mysite.com/images/bla_500x400.jpg 重写 http://mysite.com/resizer/bla.jpg?width=500&height=400 rewrite ^/images/(.*)_(\\d+)x(\\d+)\\.(png|jpg|gif)$ /resizer/$1.$4?width=$2&height=$3? last; #xxx.com/book/aaa/cc 或者xxx.com/book/aaa 重写 /up/aaa location @40x { rewrite ^/book/(.*)/(.*)$ /up/$1 last; } 以上配置 rewrite [permanent | last ]后还会继续匹配location目录 "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite/last.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite/last.html","title":"last","keywords":"","body":"last：表示完成rewrite； "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite/break.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite/break.html","title":"break","keywords":"","body":"break: 本条规则匹配完成后，终止匹配，不再匹配后面的规则； "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite/redirect.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/rewrite/redirect.html","title":"redirect","keywords":"","body":"redirect 返回302临时重定向，浏览器地址栏会显示跳转后的URL地 location ^~/book { #rewriteA 浏览器地址会改变 if ( !-f $request_filename){ rewrite ^/book/(.*)$ /book/baihui.html?a=$1 redirect; } #rewriteB 浏览器地址不会改变 if ( !-f $request_filename){ rewrite ^/book/(.*)$ /book/baihui.html?a=$1 last; } index baihui.html ; alias /var/www/aaa/bbb/; } "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/set.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/set.html","title":"set","keywords":"","body":""},"nginx/mo-kuai/httpmo-kuai/server/rewrite/break.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/break.html","title":"break","keywords":"","body":"使用环境： server,location,if 该指令的作用是完成当前的规则集，不再处理rewrite指令 "},"nginx/mo-kuai/httpmo-kuai/server/rewrite/return.html":{"url":"nginx/mo-kuai/httpmo-kuai/server/rewrite/return.html","title":"return","keywords":"","body":"使用环境： server,location,if 该指令用于结束规则的执行并返回状态码给客户端。 状态码可以使用这些值： 204，400，402～406，408，410，411，413，416及500～504。 此外，非标准状态码444将以不发送任何Header头的方式结束连接 "},"nginx/mo-kuai/httpmo-kuai/errorpage.html":{"url":"nginx/mo-kuai/httpmo-kuai/errorpage.html","title":"error_page","keywords":"","body":"error_page 语法：error_page code[code...][=|=answercode]uri 默认值：no使用 环境：http，server，location，ifinlocation该指令用于设置如果出现指定的HTTP错误状态码，则返回给客户端显示的对应URI地址。 如下：如果遇到404错误状态码（客户端请求的页面不存在），则显示指定的/404.html文件内容给客户端。 error_page 404 /404.html; 404.html文件大小不能超过512字节，否则InternetExplorer浏览器会默认为其错误页面，而不是指定的/404.html页面。 "},"nginx/eventsshi-jian.html":{"url":"nginx/eventsshi-jian.html","title":"events事件","keywords":"","body":"events配置块很简单，里面只有一个worker_connections指令，确定每个worker进程可以处理的最大连接数 "},"nginx/fu-zai-jun-heng.html":{"url":"nginx/fu-zai-jun-heng.html","title":"负载均衡","keywords":"","body":"Nginx仅仅是作为Nginx Proxy反向代理的使用的，但是因为这个反向代理功能表现的效果是负载均衡机器的效果，因此nginx负载均衡是特殊的反向代理。 实现Nginx负载均衡的主要模块 ngx_http_proxy_module proxy代理模块，用于把请求发送给服务器节点或upstream服务器池 ngx_http_upstream_module 负载均衡模块，可以实现网站的负载均衡功能及节点的健康检查 upstream：创建节点服务器组的关键字，必须有； blog：节点服务器组的名字，必须有，可自定义名字； server：关键字，后面可加IP或者域名或者IP:端口，不指定端口默认80； weight：权重，数值越大被分配的请求越多。默认为1 设置节点服务器的状态值除了weight之外，还有： max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误. fail_timeout：max_fails次失败后，暂停的时间。 down：表示当前的节点服务器不参与负载，标志机器永远不可用，可配合iP_hash使用 backup：其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 "},"nginx/fang-wen-kong-zhi.html":{"url":"nginx/fang-wen-kong-zhi.html","title":"访问控制","keywords":"","body":""},"nginx/fang-wen-kong-zhi/jin-zhi-ip.html":{"url":"nginx/fang-wen-kong-zhi/jin-zhi-ip.html","title":"禁止ip","keywords":"","body":"通过模块ngx_http_access_module的deny指令实现。 server { listen 80; listen [::]:80; server_name baihui.com; #禁止所有客户端访问当前站点 deny 192.168.1.9; location / { root html; index index.html; #禁止客服端访问当前目录 deny 192.168.1.8; #允许其他ip访问除了8 allow 192.168.1.0/24; } location /aa/ { root html; index index.html; } } Nginx在执行规则匹配时是从上往下进行的，并且在匹配成功后就不再往下继续匹配 192.168.1.8客户端访问站点根目录时就会收到403Forbidden的错误信息,但是可以访问/aaa/ 目录 "},"nginx/fang-wen-kong-zhi/mi-ma-ren-zheng.html":{"url":"nginx/fang-wen-kong-zhi/mi-ma-ren-zheng.html","title":"密码认证","keywords":"","body":"Nginx通过模块ngx_http_auth_basic_module提供对客户端进行密码认证访问的功能，该模块默认被加入编译。 模块ngx_http_auth_basic_module使用的是HTTP协议的WWWAuthenticate〔4〕响应头来实现密码认证， htpasswd创建密码实例文件 #用命令htpasswd 创建密码实例文件 htpasswd -c home/bh/ata/htppass/pass.db baihui 123 location ^~/book { auth_basic \"User Authentication\"; auth_basic_user_file /home/bh/ata/htppass/pass.db; index index.html; alias /home/bh/ata/book/html/; } "},"nginx/quan-ju-bian-liang.html":{"url":"nginx/quan-ju-bian-liang.html","title":"全局变量","keywords":"","body":"Nginx中有很多的全局变量，可以通过$变量名来使用。全局变量： 变量 说明 $args 请求中的参数，如www.123.com/1.php?a=1&b=2的$args就是a=1&b=2 $content_length HTTP请求信息里的”Content-Length” $conten_type HTTP请求信息里的”Content-Type” $document_root nginx虚拟主机配置文件中的root参数对应的值 $document_uri 当前请求中不包含指令的URI，如www.123.com/1.php?a=1&b=2的$document_uri就是1.php,不包含后面的参数 $host 主机头，也就是域名 $http_user_agent 客户端的详细信息，也就是浏览器的标识，用curl -A可以指定 $http_cookie 客户端的cookie信息 $limit_rate 如果nginx服务器使用limit_rate配置了显示网络速率，则会显示，如果没有设置， 则显示0 $remote_addr 客户端的公网ip $remote_port 客户端的port $remote_user 如果nginx有配置认证，该变量代表客户端认证的用户名 $request_body_file 做反向代理时发给后端服务器的本地资源的名称 $request_method 请求资源的方式，GET/PUT/DELETE等 $request_filename 当前请求的资源文件的路径名称，相当于是$document_root/$document_uri的组合 $request_uri 请求的链接，包括$document_uri和$args $scheme 请求的协议，如ftp,http,https $server_protocol 客户端请求资源使用的协议的版本，如HTTP/1.0，HTTP/1.1，HTTP/2.0等 $server_addr 服务器IP地址 $server_name 服务器的主机名 $server_port 服务器的端口号 $uri 和$document_uri相同 $http_referer 客户端请求时的referer，通俗讲就是该请求是通过哪个链接跳过来的，用curl -e可以指定 基于$http_user_agent的访问控制(反爬虫) user_agent可以简单理解成浏览器标识，包括一些蜘蛛爬虫都可以通过user_agent来辨识。假如观察访问日志，发现一些搜索引擎的蜘蛛对网站访问特别频繁，它们并不友好。为了减少服务器的压力，其实可以把除主流搜索引擎蜘蛛外的其他蜘蛛爬虫全部封掉。 if ($user_agent ~ 'YisouSpider|MJ12bot/v1.4.2|YoudaoBot|Tomato') { return 403; } "}}